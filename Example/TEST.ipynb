{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload    \n",
    "%autoreload 2          \n",
    "\n",
    "import os \n",
    "import sys\n",
    "from pathlib import Path # To set data downloading path\n",
    "\n",
    "# Append ghostcoder folder to path \n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import ghostcoder\n",
    "\n",
    "from ghostcoder import GhostCoder\n",
    "from ghostcoder.utils import *\n",
    "from ghostcoder.graph import create_ghostcoder_agent, create_coder_agent, create_crawler_agent, create_retriever_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89124644",
   "metadata": {},
   "source": [
    "Here we will test and illustrate each subgraph in Ghostcoder, as an important component of BIA (bioinformatics agnet), mainly functions to complete the generation and execution of bioinformatics analysis codes. It contains five subgraphs. They are filemanager, retriever, coder and webcrawler executor respectively.\n",
    "\n",
    "\n",
    "### Omics data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8466b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#──────work_dir \n",
    "#  └───data\n",
    "#    └─Input_data.whatever\n",
    "# First lets download a scRNAseq data\n",
    "import scanpy as sc\n",
    "\n",
    "from ghostcoder.config import file_config\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Ghostcoder pre-set WORK_DIR and INPUT_DATA_DIR for continues bioinformatics tasks using one input data\n",
    "\n",
    "# Download scRNAseq data\n",
    "sc.settings.datasetdir = current_dir/ file_config.INPUT_DATA_DIR # Download data into data/ folder in current dir\n",
    "sc.datasets.pbmc3k()\n",
    "\n",
    "# Create a data description file to illustrate the scRNAseq data details \n",
    "data_des = \"The data used in this basic preprocessing and clustering tutorial was collected from bone marrow mononuclear cells of healthy human donors. The samples used in this tutorial were measured using the 10X Multiome Gene Expression and Chromatin Accessability kit.\"\n",
    "\n",
    "with open('data/data_description.txt','w') as f:\n",
    "    f.write(data_des)\n",
    "    \n",
    "# Set workdir as current dir\n",
    "file_config.WORK_DIR = current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb5572",
   "metadata": {},
   "source": [
    "### Set up LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Openai API for example, you can use other LLM provider as well\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# I will recommend use Openai API, I haven't tested any APIs from other suppliers yet\n",
    "def call_chatllm_openai(api_key, api_base, model_name):\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key = api_key,\n",
    "        openai_api_base=api_base,\n",
    "        model = model_name)\n",
    "    return llm\n",
    "\n",
    "# Setup up api keys \n",
    "openai_api_key = \"\"\n",
    "openai_api_base = \"\"\n",
    "openai_chat_model = \"\" \n",
    "openai_code_model = \"\"\n",
    "\n",
    "# Here, I recommend using an LLM with stronger coding capabilities as the code model, which is set to perform code-related work in all Ghostcoder graphs. Meanwhile, it is better to use LLM with stronger reasoning ability as the chat model.\n",
    "chat_model = call_chatllm_openai(openai_api_key, openai_api_base, openai_chat_model)\n",
    "code_model = call_chatllm_openai(openai_api_key, openai_api_base, openai_code_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28add431",
   "metadata": {},
   "source": [
    "### Set up Tavily search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7aaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Tavily\n",
    "tavily_api = \"\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = tavily_api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6a85d",
   "metadata": {},
   "source": [
    "### File management and data perception by ghostcoder.filemanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fill manager will automatically set up file system and percept the input data \n",
    "# A initial file system status for a task with task_id should as follow: \n",
    "#─┬─────work_dir \n",
    "# ├─┬───data\n",
    "# │ └───Input_data.whatever\n",
    "# └─┬───task_id_1 // Work dir for every new tasks\n",
    "#   ├─┬─data  \n",
    "#   │ └─Input_data.whatever // A copy from work_dir/data/\n",
    "#   ├───figures // Where output figures will be saved\n",
    "#   └───results // Where processed data will be saved\n",
    "from ghostcoder.config import docker_config, file_config\n",
    "from ghostcoder.graph import create_filemanager_agent\n",
    "\n",
    "#  Set workdir as current dir\n",
    "current_dir = Path.cwd()\n",
    "file_config.WORK_DIR = current_dir\n",
    "\n",
    "\n",
    "# Initial graph\n",
    "file_management = create_filemanager_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "        )\n",
    "\n",
    "fm_input = {\n",
    "    \"task_id\" : \"Test\", # \n",
    "    \"docker_profile_dir\": docker_config.DOCKER_PROFILES_DIR, # use pre-set docker profiles, please read those docker images \n",
    "    \"max_iter\": 10,\n",
    "}\n",
    "\n",
    "fm_state = await file_management.ainvoke(fm_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1f54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c47e4b32",
   "metadata": {},
   "source": [
    "### Native env and Docker executor, test along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.graph import create_executor_agent\n",
    "from ghostcoder.docker import get_docker_status\n",
    "from ghostcoder.utils import get_native_env_perception\n",
    "\n",
    "# Set up environment profiles\n",
    "env_profiles = {\n",
    "    \"task_dirs\":{\n",
    "        \"task_dir\": \"Test\",\n",
    "        \"data_dir\": \"data\",\n",
    "        \"figure_dir\": \"figures\",\n",
    "        \"output_dir\": \"results\",\n",
    "    },\n",
    "    \"docker status\": get_docker_status(),\n",
    "    \"native env languages\": get_native_env_perception(),\n",
    "}\n",
    "\n",
    "# Initial agent\n",
    "agent = create_executor_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Test executor with bash python and R\n",
    "test_bash_code =\"\"\"\n",
    "ls -al\n",
    "\"\"\"\n",
    "\n",
    "test_python_code = \"\"\"\n",
    "print(\"Hello World\")\n",
    "\"\"\"\n",
    "\n",
    "test_r_code =\"\"\"\n",
    "my_str <- \"Hello World\"\n",
    "print(my_str)\n",
    "\"\"\"\n",
    "\n",
    "for codeblock in [\n",
    "    test_bash_code, \n",
    "    test_python_code, \n",
    "    test_r_code\n",
    "    ]:\n",
    "    print(\"Test code executor with\\n\",codeblock)\n",
    "\n",
    "    exe_states = await agent.ainvoke(\n",
    "        {\n",
    "            \"generated_codeblock\":codeblock,\n",
    "            \"env_profiles\": env_profiles,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Agent detected coding language as: {exe_states['language']}\\nUse docker: {exe_states['use_docker']}\")\n",
    "    if exe_states['use_docker']:\n",
    "        print(f\"With docker image{exe_states['docker_image']}\")\n",
    "    print(f\"Code execute output:\\n{exe_states['execution_results']}\\n--------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc5881",
   "metadata": {},
   "source": [
    "### Web crawler, test along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "037290a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: No content loaded.\n",
      "Attempt 2: No content loaded.\n",
      "Attempt 3: No content loaded.\n",
      "Attempt 1: No content loaded.\n",
      "Attempt 2: No content loaded.\n",
      "Attempt 3: No content loaded.\n",
      "--------\n",
      "Generated query for given context:\n",
      "R code examples for single cell trajectory analysis using Monocle3\n",
      "Monocle3 tutorial for single cell trajectory inference\n",
      "Step-by-step guide for analyzing single cell trajectories with Monocle3 in R\n",
      "Get total 5 useful web search results\n",
      "Crawled and parsed web information as follow:\n",
      "The content from Page 2 provides a detailed guide on using Monocle 3 for constructing single-cell trajectory analyses using ATAC-seq data. The process involves loading single-cell ATAC-seq datasets, performing preprocessing with the Seurat and Signac packages, and using conversion functions from SeuratWrappers to integrate with Monocle 3. Here's the key code for building trajectories with Monocle 3:\n",
      "\n",
      "```r\n",
      "library(Signac)\n",
      "library(Seurat)\n",
      "library(SeuratWrappers)\n",
      "library(monocle3)\n",
      "library(Matrix)\n",
      "library(ggplot2)\n",
      "library(patchwork)\n",
      "set.seed(1234)\n",
      "\n",
      "# Data loading and preprocessing steps\n",
      "# [The code for data loading and preprocessing]\n",
      "# Building trajectories with Monocle 3\n",
      "\n",
      "erythroid.cds <- as.cell_data_set(erythroid)\n",
      "erythroid.cds <- cluster_cells(cds = erythroid.cds, reduction_method = \"UMAP\")\n",
      "erythroid.cds <- learn_graph(erythroid.cds, use_partition = TRUE)\n",
      "\n",
      "lymphoid.cds <- as.cell_data_set(lymphoid)\n",
      "lymphoid.cds <- cluster_cells(cds = lymphoid.cds, reduction_method = \"UMAP\")\n",
      "lymphoid.cds <- learn_graph(lymphoid.cds, use_partition = TRUE)\n",
      "\n",
      "# Compute pseudotime estimates\n",
      "hsc <- readLines(\"../vignette_data/hsc_cells.txt\")\n",
      "erythroid.cds <- order_cells(erythroid.cds, reduction_method = \"UMAP\", root_cells = hsc)\n",
      "lymphoid.cds <- order_cells(lymphoid.cds, reduction_method = \"UMAP\", root_cells = hsc)\n",
      "\n",
      "# Plot trajectories\n",
      "plot_cells(\n",
      "  cds = erythroid.cds,\n",
      "  color_cells_by = \"pseudotime\",\n",
      "  show_trajectory_graph = TRUE\n",
      ")\n",
      "\n",
      "plot_cells(\n",
      "  cds = lymphoid.cds,\n",
      "  color_cells_by = \"pseudotime\",\n",
      "  show_trajectory_graph = TRUE\n",
      ")\n",
      "\n",
      "# Add pseudotime metadata to Seurat object\n",
      "bone <- AddMetaData(\n",
      "  object = bone,\n",
      "  metadata = erythroid.cds@principal_graph_aux@listData$UMAP$pseudotime,\n",
      "  col.name = \"Erythroid\"\n",
      ")\n",
      "\n",
      "bone <- AddMetaData(\n",
      "  object = bone,\n",
      "  metadata = lymphoid.cds@principal_graph_aux@listData$UMAP$pseudotime,\n",
      "  col.name = \"Lymphoid\"\n",
      ")\n",
      "FeaturePlot(bone, c(\"Erythroid\", \"Lymphoid\"), pt.size = 0.1) & scale_color_viridis_c()\n",
      "```\n",
      "\n",
      "This workflow allows for building and plotting pseudotime trajectories, using pre-selected root cells, and integrating the pseudotime data back into a Seurat object for further analysis.\n"
     ]
    }
   ],
   "source": [
    "from ghostcoder.graph import create_crawler_agent\n",
    "\n",
    "\n",
    "# Initial agent\n",
    "agent = create_crawler_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "    )\n",
    "\n",
    "# Input \n",
    "query_context = \"I'm looking for R codes for analysis single cell trajectory using monocl3\"\n",
    "\n",
    "# Invoke\n",
    "crawl_state = agent.invoke(\n",
    "    {\n",
    "        \"query_context\": query_context,\n",
    "    }\n",
    "    )\n",
    "\n",
    "# Print results\n",
    "print(\"--------\\nGenerated query for given context:\")\n",
    "for q in crawl_state['query_list']:\n",
    "    print(q)\n",
    "print(f\"Get total {len(crawl_state['useful_results'])} useful web search results\")\n",
    "print(\"Crawled and parsed web information as follow:\")\n",
    "print(crawl_state['summary'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIA-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
