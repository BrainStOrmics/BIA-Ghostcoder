,Omics,Task,Description,Instruction,Tools,Language,CodeBlock,Source,Reviewed
0,scRNA-seq,Quality control,"The primary objective was to process and perform quality control on single-cell RNA sequencing data from the PBMC3K dataset. This was accomplished using preprocessing and QC metric calculation workflows, implemented with the `scanpy` toolkit in Python. Starting with an `AnnData` object containing raw gene expression data, the analysis involved annotating mitochondrial (""MT-""), ribosomal (""RPS/RPL""), and hemoglobin (""^HB[^(P)]"") genes, followed by computing QC metrics using `sc.pp.calculate_qc_metrics`. Key metrics included genes per cell (`n_genes_by_counts`), total counts per cell (`total_counts`), and mitochondrial percentage (`pct_counts_mt`). Results were log-transformed and stored in cell/gene metadata to enable downstream quality assessment. QC metrics were visualized using violin plots to display distributions of key metrics and a scatter plot (total counts vs. genes per cell) colored by mitochondrial percentage. These plots highlighted potential low-quality cells (e.g., high mitochondrial content or outlier counts). The processed data, saved as `pbmc3k_qc.h5ad`, provided a foundation for subsequent filtering and analysis.  ","### Methods

#### Data Preprocessing and Quality Control

Single-cell RNA sequencing data from the PBMC3K dataset were processed using the `scanpy` toolkit (version X.X.X) in Python. The dataset was loaded as an `AnnData` object, a structured data format containing a gene expression matrix (cells ?? genes), cell-level metadata, and gene-level metadata.

#### Annotation of Gene Categories
Mitochondrial genes were identified by the ""MT-"" prefix in their gene names. Ribosomal genes were annotated based on the prefixes ""RPS"" and ""RPL,"" while hemoglobin genes were identified using the regular expression ""^HB[^(P)]."" These annotations were stored in the gene-level metadata for subsequent quality control (QC) analysis.

#### Calculation of QC Metrics
QC metrics were computed using the `sc.pp.calculate_qc_metrics` function. Metrics included the total number of genes detected per cell (`n_genes_by_counts`), total counts per cell (`total_counts`), and the percentage of counts mapping to mitochondrial genes (`pct_counts_mt`). Additional metrics were calculated for the annotated gene categories (mitochondrial, ribosomal, and hemoglobin genes). The results were log-transformed (`log1p=True`) and stored in the cell-level metadata.

#### Visualization of QC Metrics
QC metrics were visualized to assess data quality. Violin plots were generated to display the distribution of `n_genes_by_counts`, `total_counts`, and `pct_counts_mt` across cells, with a jitter parameter of 0.4 to enhance visibility of individual data points. A scatter plot was created to examine the relationship between `total_counts` and `n_genes_by_counts`, with points colored by `pct_counts_mt` to highlight the influence of mitochondrial gene expression.

#### Data Output
The processed dataset, including annotated gene categories and QC metrics, was saved in the H5AD file format (`pbmc3k_qc.h5ad`) for downstream analysis.","scanpy, anndata",python,"#----------------
# Import necessary modules
#----------------
import scanpy as sc
import anndata as ad

# Set figure parameters for decent plotting
sc.settings.set_figure_params(dpi=80, facecolor='white')

#----------------
# Data Input: load a sample dataset
#----------------
adata = sc.datasets.pbmc3k()
# Data format: 
# adata is an AnnData object containing the following core structure 
# x: core data matrix (cells ?? genes), usually a sparse matrix or numpy array
# obs: cell-level metadata (DataFrame), stores properties for each cell
# var: gene-level metadata (DataFrame), stores attributes for each gene


#----------------
# Annotate genes for QC metrics and calculate metrics
#----------------

# Mark mitochondrial genes
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")

# Mark ribosomal genes
adata.var[""ribo""] = adata.var_names.str.startswith((""RPS"", ""RPL""))

# Mark hemoglobin genes
adata.var[""hb""] = adata.var_names.str.contains(""^HB[^(P)]"")

# Calculate QC metrics
sc.pp.calculate_qc_metrics(
    adata, 
    qc_vars=[""mt"", ""ribo"", ""hb""],
    inplace=True,
    log1p=True
)

#----------------
# Create QC visualization plots
#----------------
# Violin plots for key metrics
sc.pl.violin(
    adata,
    keys=[""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],
    jitter=0.4,
    multi_panel=True
)

# Scatter plot showing counts vs genes with mitochondrial percentage
sc.pl.scatter(
    adata, 
    x=""total_counts"",
    y=""n_genes_by_counts"",
    color=""pct_counts_mt""
)

#----------------
# Data output 
#----------------
adata.write('pbmc3k_qc.h5ad')",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html,T
1,scRNA-seq,Quality control,"The primary objective was to perform quality control (QC) analysis on a peripheral blood mononuclear cell (PBMC) dataset. This was accomplished using gene-specific quality metrics and doublet detection strategies, implemented with the *scanpy* Python package and Scrublet algorithm. Starting with the raw PBMC3k dataset, the analysis involved flagging mitochondrial, ribosomal, and hemoglobin genes by prefix matching, followed by calculating QC metrics (*sc.pp.calculate_qc_metrics*) and detecting doublets (*sc.pp.scrublet*). The final cell inclusion criteria were defined using thresholds for genes/cell, total read counts, mitochondrial content percentages, and Scrublet-derived doublet scores. QC distributions were visualized via violin plots to assess outliers in genes/cell, total counts, and mitochondrial percentages. Scatter plots revealed relationships between counts and detected genes, with color mapping for mitochondrial content and doublet status. These findings were validated by highlighting cells flagged as technical artifacts (high mitochondrial reads/low genes) and predicted doublets (elevated Scrublet scores).  ","### Methods

#### Data Input and Preprocessing
The peripheral blood mononuclear cell (PBMC) 3k dataset was loaded using the `scanpy` package (`sc.datasets.pbmc3k()`). A dummy sample identifier, ""sample1,"" was added to the dataset to facilitate batch-level analysis. Mitochondrial, ribosomal, and hemoglobin genes were identified based on gene name prefixes: mitochondrial genes were flagged using the ""MT-"" prefix, ribosomal genes using ""RPS"" or ""RPL,"" and hemoglobin genes using the pattern ""^HB[^(P)]."" Quality control (QC) metrics, including the percentage of counts from mitochondrial, ribosomal, and hemoglobin genes, were calculated using the `sc.pp.calculate_qc_metrics` function with logarithmic transformation applied (`log1p=True`). Potential doublets were detected using the Scrublet algorithm (`sc.pp.scrublet`), with batch information specified by the ""sample"" column.

#### Quality Control Visualization
QC distributions were visualized using violin plots to examine key metrics, including the number of genes detected per cell (`n_genes_by_counts`), total read counts per cell (`total_counts`), and the percentage of mitochondrial reads (`pct_counts_mt`). Scatter plots were generated to explore the relationship between total read counts and the number of genes detected, with mitochondrial content represented by color. Doublet detection results were visualized by plotting total read counts against the number of genes detected, with cells colored by their predicted doublet status (`predicted_doublet`) and doublet scores (`doublet_score`).

#### Data Output
The preprocessed dataset, including QC metrics and doublet predictions, was saved in the AnnData format (`processed_pbmc3k.h5ad`) with gzip compression for downstream analysis.","scanpy, anndata",python,"#----------------
# Package Load
#----------------
import scanpy as sc
import anndata as ad

#----------------
# Data Input
#----------------
# Load built-in PBMC 3k dataset
adata = sc.datasets.pbmc3k()

# Add dummy sample identifier required for batch-level analysis
adata.obs[""sample""] = ""sample1""

#----------------
# Preprocessing & Quality Control
#----------------
# Flag mitochondrial, ribosomal and hemoglobin genes
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")       # Mitochondrial genes
adata.var[""ribo""] = adata.var_names.str.startswith((""RPS"", ""RPL""))  # Ribosomal genes
adata.var[""hb""] = adata.var_names.str.contains(""^HB[^(P)]"")   # Hemoglobin genes

# Calculate quality control metrics
sc.pp.calculate_qc_metrics(
    adata, 
    qc_vars=[""mt"", ""ribo"", ""hb""],
    inplace=True,
    log1p=True
)

# Detect potential doublets using Scrublet
sc.pp.scrublet(adata, batch_key=""sample"")

#----------------
# Visualization
#----------------
# Configure plotting parameters
sc.settings.set_figure_params(dpi=80, facecolor=""white"")

# QC distributions
sc.pl.violin(
    adata,
    keys=[""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],
    jitter=0.4,
    multi_panel=True,
    title=""Quality Control Distributions""
)

# Relationship between read depth and mitochondrial content
sc.pl.scatter(
    adata,
    x=""total_counts"",
    y=""n_genes_by_counts"",
    color=""pct_counts_mt"",
    title=""Gene Counts vs. Total Reads (MT% Colored)""
)

# Doublet visualization
for color_field in [""predicted_doublet"", ""doublet_score""]:
    sc.pl.scatter(
        adata,
        x=""total_counts"",
        y=""n_genes_by_counts"",
        color=color_field,
        title=f""Doublet Detection: {color_field.replace('_', ' ').title()}""
    )

#----------------
# Data Output
#----------------
# Save processed data for future analysis
adata.write(""processed_pbmc3k.h5ad"", compression=""gzip"")",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html,F
2,scRNA-seq,Quality control,"The primary objective was to perform quality control and filter low-quality cells from single-cell RNA sequencing data. This was accomplished using comprehensive quality metric calculation and outlier detection, implemented with the **scanpy** package in Python. Starting with a **10x Genomics HDF5 file**, the analysis involved calculating QC metrics (total counts, genes detected, mitochondrial/ribosomal/hemoglobin percentages, and top 20 genes) and detecting outliers via the **Median Absolute Deviation (MAD)** method. Cells were filtered using thresholds of >5 MADs for general metrics (total counts, genes detected, top 20 genes) or >3 MADs/8% hard threshold for mitochondrial content. The final dataset was determined by removing flagged outliers, with pre- and post-filtering cell counts recorded. The results were presented in a **histogram** to confirm removal of extreme total counts and a **violin plot** to show mitochondrial percentage distribution. A **scatter plot** illustrated relationships between total counts, genes detected, and mitochondrial content. These findings were supported by a **cell count summary table**, which validated effective quality control by quantifying retained high-quality cells.","### Methods

#### Data Preprocessing and Quality Control

**Data Input**  
Single-cell RNA sequencing data were loaded from a 10x Genomics HDF5 file (`filtered_feature_bc_matrix.h5`) using the `scanpy` function `sc.read_10x_h5`. Gene names were ensured to be unique to prevent downstream analysis issues.

**Quality Control Metrics**  
Quality control (QC) metrics were calculated for each cell using `sc.pp.calculate_qc_metrics`. Mitochondrial genes were identified by the ""MT-"" prefix in their gene names, ribosomal genes by the ""RPS"" and ""RPL"" prefixes, and hemoglobin genes by the pattern ""^HB[^(P)]"". The metrics included total counts, the number of genes detected, and the percentage of counts in mitochondrial, ribosomal, and hemoglobin genes. Additionally, the percentage of counts in the top 20 genes was computed.

**Outlier Detection**  
Outlier cells were identified using the Median Absolute Deviation (MAD) method. A custom function (`is_outlier`) was implemented to flag cells as outliers if their values for `log1p_total_counts`, `log1p_n_genes_by_counts`, or `pct_counts_in_top_20_genes` deviated by more than 5 MADs from the median. Cells were also flagged as mitochondrial outliers if their mitochondrial gene content exceeded 3 MADs from the median or surpassed a hard threshold of 8%.

**Cell Filtering**  
Low-quality cells flagged as outliers in either general QC metrics or mitochondrial content were removed from the dataset. The remaining cells were retained for downstream analysis. The total number of cells before and after filtering was recorded.

**Visualization**  
The distribution of total counts per cell was visualized using a histogram to confirm the removal of cells with extreme counts. A violin plot was generated to inspect the distribution of mitochondrial gene percentages, and a scatter plot was used to examine the relationship between total counts, the number of genes detected, and mitochondrial content.

**Data Output**  
The filtered and processed dataset was saved as an AnnData object (`filtered_quality_control.h5ad`) for subsequent analysis.

#### Software and Parameters  
All analyses were performed using the `scanpy` package (version not specified) in Python. Key parameters included:  
- Outlier detection: `nmads=5` for general QC metrics and `nmads=3` for mitochondrial content.  
- Mitochondrial content threshold: 8%.  
- QC metrics calculation: `percent_top=[20]`, `log1p=True`.","scanpy, numpy, seaborn, scipy",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for numerical operations, data handling, and plotting
import numpy as np
import scanpy as sc
import seaborn as sns
from scipy.stats import median_abs_deviation

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
# Verbosity 0 supresses most of the Scanpy output messages.
sc.settings.verbosity = 0
# Set figure parameters for high-quality plots.
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

#--------------------------------
# Data Input
#--------------------------------

# Load the single-cell dataset from a 10x Genomics HDF5 file
adata = sc.read_10x_h5(filename=""filtered_feature_bc_matrix.h5"")

# Ensure that all gene names (variable names) are unique to prevent issues in downstream analysis
adata.var_names_make_unique()

#--------------------------------
# Quality Control (QC) and Filtering
#--------------------------------

# Identify different sets of genes for quality control metrics
# MT- genes are mitochondrial genes, which can indicate cell stress or damage if highly expressed.
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")
# RPS and RPL genes are ribosomal genes.
adata.var[""ribo""] = adata.var_names.str.startswith((""RPS"", ""RPL""))
# HB genes are hemoglobin genes, which can indicate contamination from red blood cells.
adata.var[""hb""] = adata.var_names.str.contains(""^HB[^(P)]"")

# Calculate QC metrics for each cell.
# This computes metrics like total counts, number of genes, and percentages of mt, ribo, and hb genes.
sc.pp.calculate_qc_metrics(
    adata, qc_vars=[""mt"", ""ribo"", ""hb""], inplace=True, percent_top=[20], log1p=True
)

# Define a function to identify outlier cells based on the Median Absolute Deviation (MAD).
# MAD is a robust measure of variability and is less sensitive to extreme outliers than standard deviation.
def is_outlier(adata, metric: str, nmads: int):
    """"""
    Identifies outliers for a given metric in the AnnData object.

    Args:
        adata: AnnData object containing the data.
        metric: The observation metric to check for outliers (e.g., 'log1p_total_counts').
        nmads: The number of median absolute deviations to use as the threshold.

    Returns:
        A boolean Series indicating whether each cell is an outlier.
    """"""
    M = adata.obs[metric]
    # An observation is an outlier if it is nmads MADs away from the median.
    outlier = (M < np.median(M) - nmads * median_abs_deviation(M)) | \
              (np.median(M) + nmads * median_abs_deviation(M) < M)
    return outlier

# Identify outlier cells based on general QC metrics.
# Here, we mark cells as outliers if they are outliers for total counts, number of genes, or
# the percentage of counts in the top 20 genes.
adata.obs[""outlier""] = (
    is_outlier(adata, ""log1p_total_counts"", 5) |
    is_outlier(adata, ""log1p_n_genes_by_counts"", 5) |
    is_outlier(adata, ""pct_counts_in_top_20_genes"", 5)
)

# Identify cells with high mitochondrial gene content.
# Cells are marked as outliers if their mitochondrial content is more than 3 MADs from the median
# or if it exceeds a hard threshold of 8%.
adata.obs[""mt_outlier""] = is_outlier(adata, ""pct_counts_mt"", 3) | (adata.obs[""pct_counts_mt""] > 8)

# Print the number of cells before filtering
print(f""Total number of cells: {adata.n_obs}"")

# Filter out the low-quality cells identified in the previous steps.
# A .copy() is used to create a new, clean AnnData object.
adata = adata[(~adata.obs.outlier) & (~adata.obs.mt_outlier)].copy()

# Print the number of cells remaining after filtering
print(f""Number of cells after filtering of low-quality cells: {adata.n_obs}"")


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the distribution of total counts per cell after filtering.
# This helps confirm that cells with extremely low or high counts have been removed.
sns.displot(adata.obs[""total_counts""], bins=100, kde=False)

# Create a violin plot to show the distribution of mitochondrial gene percentages.
# This plot helps to visually inspect the effectiveness of the mitochondrial content filtering.
sc.pl.violin(adata, ""pct_counts_mt"")

# Create a scatter plot to visualize the relationship between total counts,
# number of genes, and mitochondrial content.
# This plot is useful for identifying any remaining artifacts or relationships in the data.
sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"")


#--------------------------------
# Data Output
#--------------------------------

# Save the filtered and processed AnnData object to a file.
# This file can be used for subsequent downstream analyses like normalization,
# clustering, and differential expression.
adata.write(""filtered_quality_control.h5ad"")
",https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html,F
3,scRNA-seq,Quality control,"The primary objective was to perform stringent quality control (QC) for single-cell RNA-seq data by identifying and removing low-quality cells and technical artifacts. This was accomplished using a multi-step filtering strategy combining Median Absolute Deviation (MAD)-based outlier detection and doublet prediction, implemented with the Scanpy toolkit and Scrublet algorithm in Python. Starting with a 10x Genomics HDF5 file, the analysis involved calculating QC metrics (total counts, detected genes, mitochondrial/ribosomal gene percentages) and identifying outlier cells using MAD thresholds (???5 MADs for total counts/gene counts, ???3 MADs or >8% for mitochondrial content). Potential doublets were flagged via Scrublet?€?s simulated artificial doublet reference. Filtered cells retained for downstream analysis met all QC thresholds and had doublet scores below the Scrublet-predicted threshold. QC results were visualized through a scatter plot (total counts vs. detected genes, colored by mitochondrial content) to highlight outlier cells, supported by histograms of count distributions and violin plots of mitochondrial percentages. Doublet detection outcomes were assessed via a UMAP projection colored by doublet scores, with predicted doublets localized in distinct clusters. Processed data and metrics were exported as an AnnData object for further analysis.  ","### Methods

#### Data Preprocessing
Single-cell RNA sequencing data were processed using the Scanpy toolkit (v1.9.0) in Python. The dataset was loaded from a 10x Genomics HDF5 file (`filtered_feature_bc_matrix.h5`), and gene names were ensured to be unique to avoid redundancy in downstream analyses.

#### Quality Control and Filtering
Quality control (QC) metrics were calculated to identify and remove low-quality cells. Mitochondrial genes were identified by the ""MT-"" prefix in their gene names, ribosomal genes by the ""RPS"" or ""RPL"" prefixes, and hemoglobin genes by the ""HB"" prefix. QC metrics, including the percentage of counts in mitochondrial, ribosomal, and hemoglobin genes, as well as the total counts and number of detected genes per cell, were computed using the `sc.pp.calculate_qc_metrics` function. 

Outlier cells were identified using the Median Absolute Deviation (MAD) method. Cells were flagged as outliers if their total counts, number of detected genes, or percentage of counts in the top 20 genes deviated by more than 5 MADs from the median. Additionally, cells with mitochondrial gene content exceeding 8% or deviating by more than 3 MADs from the median were flagged as mitochondrial outliers. Low-quality cells were removed based on these criteria, and the filtered dataset was retained for downstream analysis.

#### Doublet Detection
Potential doublets were identified using the Scrublet algorithm. Artificial doublets were simulated from the data, and doublet scores were computed for each cell based on its similarity to the simulated doublets. A preliminary UMAP embedding was generated using the `sc.pp.neighbors` and `sc.tl.umap` functions to visualize doublet scores and predicted doublet status in a low-dimensional space.

#### Visualization
QC metrics were visualized to assess data quality. The distribution of total counts per cell was plotted using a histogram, and the percentage of mitochondrial gene counts was visualized using a violin plot. A scatter plot was generated to explore the relationship between total counts and the number of detected genes, colored by mitochondrial gene content. Doublet scores were visualized using a histogram, and the UMAP embedding was colored by doublet scores and predicted doublet status to evaluate the distribution of potential doublets.

#### Data Output
The filtered and processed dataset, including QC metrics, doublet scores, and predictions, was saved as an AnnData object (`filtered_quality_control_with_doublet_detection.h5ad`) for downstream analysis.","scanpy, numpy, seaborn, scipy, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for numerical operations, data handling, and plotting
import numpy as np
import scanpy as sc
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import median_abs_deviation

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
# Verbosity 0 supresses most of the Scanpy output messages.
sc.settings.verbosity = 0
# Set figure parameters for high-quality plots.
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

#--------------------------------
# Data Input
#--------------------------------

# Load the single-cell dataset from a 10x Genomics HDF5 file
adata = sc.read_10x_h5(filename=""filtered_feature_bc_matrix.h5"")

# Ensure that all gene names (variable names) are unique
adata.var_names_make_unique()

#--------------------------------
# Quality Control (QC) and Filtering
#--------------------------------

# Identify different sets of genes for quality control metrics
# MT- genes are mitochondrial. High percentage can indicate cell stress.
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")
# RPS and RPL genes are ribosomal.
adata.var[""ribo""] = adata.var_names.str.startswith((""RPS"", ""RPL""))
# HB genes are hemoglobin. High percentage can indicate red blood cell contamination.
adata.var[""hb""] = adata.var_names.str.contains(""^HB[^(P)]"")

# Calculate QC metrics for each cell.
sc.pp.calculate_qc_metrics(
    adata, qc_vars=[""mt"", ""ribo"", ""hb""], inplace=True, percent_top=[20], log1p=True
)

# Define a function to identify outlier cells based on Median Absolute Deviation (MAD)
def is_outlier(adata, metric: str, nmads: int):
    """"""
    Identifies outliers for a given metric in the AnnData object.

    Args:
        adata: AnnData object containing the data.
        metric: The observation metric to check for outliers (e.g., 'log1p_total_counts').
        nmads: The number of median absolute deviations to use as the threshold.

    Returns:
        A boolean Series indicating whether each cell is an outlier.
    """"""
    M = adata.obs[metric]
    mad = median_abs_deviation(M)
    median_val = np.median(M)
    # An observation is an outlier if it is nmads MADs away from the median.
    outlier = (M < median_val - nmads * mad) | (M > median_val + nmads * mad)
    return outlier

# Identify outlier cells based on general QC metrics
adata.obs[""outlier""] = (
    is_outlier(adata, ""log1p_total_counts"", 5) |
    is_outlier(adata, ""log1p_n_genes_by_counts"", 5) |
    is_outlier(adata, ""pct_counts_in_top_20_genes"", 5)
)

# Identify cells with high mitochondrial gene content
adata.obs[""mt_outlier""] = is_outlier(adata, ""pct_counts_mt"", 3) | (adata.obs[""pct_counts_mt""] > 8)

# Print the number of cells before filtering
print(f""Total number of cells before filtering: {adata.n_obs}"")

# Filter out the low-quality cells
adata = adata[(~adata.obs[""outlier""]) & (~adata.obs[""mt_outlier""])].copy()

# Print the number of cells remaining after filtering
print(f""Total number of cells after filtering: {adata.n_obs}"")

#--------------------------------
# Doublet Detection
#--------------------------------

# Ensure a 'sample' column exists for batch processing, as required by scrublet.
# If not present, create a dummy sample column.
if ""sample"" not in adata.obs:
    adata.obs[""sample""] = ""sample1""

# Run Scrublet for doublet detection. This simulates artificial doublets
# from the data and calculates a score for each real cell based on its
# similarity to the simulated doublets.
sc.pp.scrublet(adata, batch_key=""sample"")

# Compute a UMAP embedding for visualization purposes. This is necessary
# to visualize doublet scores on a 2D projection of the data.
# Note: This is a preliminary UMAP for visualization, not the final one for analysis.
sc.pp.neighbors(adata)
sc.tl.umap(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- QC Plots ---
# Visualize the distribution of total counts per cell after filtering.
sns.displot(adata.obs[""total_counts""], bins=100, kde=False)

# Create a violin plot to show the distribution of mitochondrial gene percentages.
sc.pl.violin(adata, ""pct_counts_mt"")

# Create a scatter plot to visualize total counts vs. number of genes.
sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"")


# --- Doublet Plots ---
# Plot a histogram of the doublet scores to help determine a threshold for calling doublets.
plt.figure(figsize=(8, 4))
plt.hist(adata.obs[""doublet_score""], bins=50, color=""skyblue"", edgecolor=""black"")
plt.xlabel(""Doublet Score"")
plt.ylabel(""Frequency"")
plt.title(""Doublet Score Distribution"")
plt.show()


# Visualize the UMAP embedding colored by doublet score and predicted doublet status.
# This helps to see if predicted doublets form distinct clusters or are located
# between major cell type clusters.
sc.pl.umap(adata, color=[""doublet_score"", ""predicted_doublet""], wspace=0.5)

#--------------------------------
# Data Output
#--------------------------------

# Save the filtered and processed AnnData object. This file now includes
# doublet scores and predictions, ready for downstream analysis.
adata.write(""filtered_quality_control_with_doublet_detection.h5ad"")","https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html, Human added code",F
4,scRNA-seq,Quality control,"The primary objective was to perform quality control by filtering low-quality cells and genes from single-cell RNA sequencing data. This was accomplished using automated filtering criteria and QC metric calculations, implemented with the Seurat package (v4.0) in R. Starting with raw 10X Genomics count matrices, the analysis involved initial filtering to remove genes detected in <3 cells and cells expressing <200 genes. Mitochondrial gene percentages were calculated using ""MT-"" annotations. Cells were excluded if they exhibited <200 or >2,500 detected genes or mitochondrial read percentages exceeding 5%. QC metrics were visualized using violin plots to display distributions of detected genes, UMI counts, and mitochondrial percentages. Scatter plots revealed relationships between these metrics. Comparative visualization via the `patchwork` package confirmed data integrity, and the filtered dataset was preserved as a Seurat object for downstream analyses.  ","### Methods

#### Data Processing and Quality Control

**Data Loading and Initialization**  
Single-cell RNA sequencing data were processed using the Seurat package (v4.0) in R. Raw count matrices were obtained from 10X Genomics data in the `filtered_gene_bc_matrices` format, consisting of `matrix.mtx`, `genes.tsv`, and `barcodes.tsv` files. The data were loaded into a Seurat object using the `Read10X` function, specifying the directory path to the uncompressed matrix files.  

To ensure data quality, a Seurat object was initialized with the following quality filters: genes detected in fewer than 3 cells (`min.cells = 3`) and cells expressing fewer than 200 genes (`min.features = 200`) were excluded.  

**Mitochondrial Gene Identification and QC Metrics**  
Mitochondrial genes were identified by their ""MT-"" prefix, consistent with the hg19 genome annotation. The percentage of mitochondrial reads per cell was calculated using the `PercentageFeatureSet` function.  

**Quality Control Filtering**  
Cells were filtered based on the following criteria:  
- Cells with fewer than 200 or more than 2,500 detected genes (`nFeature_RNA`) were excluded.  
- Cells with mitochondrial read percentages exceeding 5% (`percent.mt`) were removed.  

**Quality Control Visualization**  
Key quality control metrics were visualized to assess data integrity:  
- Violin plots were generated to display the distribution of detected genes (`nFeature_RNA`), UMI counts (`nCount_RNA`), and mitochondrial read percentages (`percent.mt`) across cells.  
- Scatter plots were used to evaluate relationships between UMI counts and mitochondrial percentages, as well as between UMI counts and detected genes. Plots were combined using the `patchwork` package for comparative analysis.  

**Data Output**  
The quality-controlled Seurat object was saved in RDS format (`pbmc_QC_filtered.rds`) for downstream analysis, preserving all data, metadata, and calculations. The saved object is compatible with the `Seurat::LoadRDS` function for reloading.  

All analyses were performed using R (version 4.0) and the Seurat package (v4.0).","Seurat, dplyr, ggplot2",R,"#----------------
# Package Load
#----------------
library(Seurat)   # Core package for single-cell analysis
library(dplyr)     # For data manipulation and piping
library(ggplot2)   # For advanced plotting customization (optional)

#----------------
# Data Input & Requirements
#----------------
# Requirements: 
#   - 10X Genomics data in filtered_gene_bc_matrices format
#   - Directory path must point to uncompressed matrix files (matrix.mtx, genes.tsv, barcodes.tsv)
#   - Mitochondrial genes prefixed with ""MT-"" (human genome hg19 convention)

data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""  # SET YOUR DATA PATH HERE
pbmc.data <- Read10X(data.dir = data_dir)  # Load raw count matrix

#----------------
# Major Analysis Tasks
#----------------
# Initialize Seurat object with quality filters:
#   - min.cells=3: Genes must appear in ???3 cells
#   - min.features=200: Cells must express ???200 genes
pbmc <- CreateSeuratObject(
  counts = pbmc.data, 
  project = ""pbmc3k"", 
  min.cells = 3, 
  min.features = 200
)

# Calculate mitochondrial QC metrics:
#   - Identifies genes starting with ""MT-"" prefix
#   - Computes percentage of mitochondrial reads per cell
pbmc[[""percent.mt""]] <- PercentageFeatureSet(pbmc, pattern = ""^MT-"")

# Apply QC filtering thresholds:
#   - Retain cells with 200-2500 detected genes (nFeature_RNA)
#   - Exclude cells with >5% mitochondrial reads (percent.mt)
pbmc <- subset(
  pbmc, 
  subset = nFeature_RNA > 200 & 
           nFeature_RNA < 2500 & 
           percent.mt < 5
)

#----------------
# Plotting
#----------------
# Violin plots for key QC metrics:
#   - nFeature_RNA: Genes per cell
#   - nCount_RNA: UMI counts per cell
#   - percent.mt: Mitochondrial percentage
VlnPlot(
  pbmc, 
  features = c(""nFeature_RNA"", ""nCount_RNA"", ""percent.mt""), 
  ncol = 3
)

# Scatter plots for QC relationships:
#   - Plot 1: UMI counts vs. mitochondrial percentage
#   - Plot 2: UMI counts vs. detected genes
plot1 <- FeatureScatter(pbmc, feature1 = ""nCount_RNA"", feature2 = ""percent.mt"")
plot2 <- FeatureScatter(pbmc, feature1 = ""nCount_RNA"", feature2 = ""nFeature_RNA"")
plot1 + plot2  # Combine plots using patchwork

#----------------
# Data Output
#----------------
# Save QC-processed object in RDS format:
#   - Preserves all data, metadata, and calculations
#   - Compatible with Seurat::LoadRDS() for reloading
saveRDS(pbmc, file = ""pbmc_QC_filtered.rds"")",https://satijalab.org/seurat/articles/pbmc3k_tutorial,F
5,scRNA-seq,Normalization,"The primary objective was to process and normalize a peripheral blood mononuclear cell (PBMC) single-cell RNA sequencing dataset to remove technical biases. This was accomplished using total count scaling and logarithmic variance stabilization, implemented with the Scanpy toolkit in Python. Starting with raw count data stored in an AnnData object, the analysis involved library size normalization to a target sum of 10,000 reads per cell, followed by a log(1+x) transformation. Raw counts were preserved in a dedicated layer to retain unmodified data for downstream tasks. Normalized distributions were validated using predefined thresholds for total counts and gene detection metrics. The results were presented in violin plots to illustrate the normalized distributions of total counts and detected genes per cell. These findings were further supported by a scatter plot comparing pre- and post-normalization metrics, which confirmed the reduction of library size-related artifacts while preserving biological variation.  ","### Methods

#### Data Acquisition
A publicly available single-cell RNA sequencing dataset of peripheral blood mononuclear cells (PBMCs) was retrieved using the `scanpy.datasets.pbmc3k()` function. This dataset serves as a benchmark for single-cell analysis workflows.

#### Data Normalization and Preprocessing
Raw count data were preserved in a separate layer of the AnnData object to retain the original information for downstream analyses requiring unnormalized counts. To correct for differences in library size across cells, the data were normalized by scaling the total counts per cell to a target sum of 10,000 using the `scanpy.pp.normalize_total()` function. A log(1+x) transformation was subsequently applied to stabilize variance and improve the suitability of the data for linear modeling approaches, implemented via the `scanpy.pp.log1p()` function.

#### Quality Control and Visualization
To assess the effects of normalization, violin plots were generated to visualize the distributions of total counts and the number of detected genes per cell using the `scanpy.pl.violin()` function. Additionally, a scatter plot was created to examine the relationship between total counts and the number of detected genes per cell, implemented with the `scanpy.pl.scatter()` function. These visualizations were used to confirm the successful removal of technical artifacts and biases.

#### Data Storage
The normalized and preprocessed AnnData object was saved to a file (`pbmc3k_normalized.h5ad`) using the `AnnData.write()` method for subsequent analysis steps, including feature selection, dimensionality reduction, and clustering.","scanpy, anndata",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and data handling
import scanpy as sc
import anndata as ad

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting to ensure consistent and clear visuals
sc.settings.set_figure_params(dpi=80, facecolor='white')

#--------------------------------
# Data Input
#--------------------------------

# Load an example peripheral blood mononuclear cell (PBMC) dataset
# This is a common benchmark dataset in single-cell analysis.
adata = sc.datasets.pbmc3k()

#--------------------------------
# Data Normalization and Preprocessing
#--------------------------------

# Save the raw, unnormalized count data into a separate layer.
# This is a good practice as it preserves the original data for future reference
# or for algorithms that require raw counts.
adata.layers[""counts""] = adata.X.copy()

# Normalize the data for sequencing depth.
# Each cell's total counts are scaled to a target sum (e.g., 10,000).
# This removes technical differences in library size across cells.
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply a log(1+x) transformation to the normalized data.
# This helps to stabilize the variance and makes the data more suitable for
# linear models used in downstream analysis (like PCA or differential expression).
sc.pp.log1p(adata)

# For verification, print a small slice of the transformed data matrix.
print(""Normalized data sample (first 5 cells, first 5 genes):"")
print(adata.X[:5, :5])


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Create violin plots to visualize the distributions of total counts and
# the number of detected genes per cell after normalization. This helps to
# confirm that the normalization has been applied correctly.
sc.pl.violin(
    adata,
    keys=[""total_counts"", ""n_genes_by_counts""],
    jitter=0.4,
    multi_panel=True,
    title=""QC Metrics after Normalization""
)

# Create a scatter plot to examine the relationship between the total counts and
# the number of genes detected in each cell. This can help identify if there
# are any remaining technical artifacts or biases in the data.
sc.pl.scatter(
    adata,
    x=""total_counts"",
    y=""n_genes_by_counts"",
    title=""Total Counts vs Number of Genes after Normalization""
)


#--------------------------------
# Data Output
#--------------------------------

# Save the normalized and processed AnnData object to a file.
# This file can be loaded for subsequent analysis steps, such as
# identifying highly variable genes, dimensionality reduction, and clustering.
adata.write(""pbmc3k_normalized.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html,F
6,scRNA-seq,Normalization,"The primary objective was to perform library size normalization of single-cell RNA sequencing data to correct technical variability while preserving biological signal. This was accomplished using a scaling-based normalization strategy, implemented with scanpy's data processing functions in Python. Starting with raw UMI counts in an AnnData object, the analysis involved (1) preserving original counts in a dedicated layer, (2) normalizing cellular library sizes to a target sum of 10,000 transcripts (scanpy.pp.normalize_total), and (3) applying log1p transformation (scanpy.pp.log1p) for variance stabilization. Normalization parameters were selected to mitigate technical artifacts while maintaining data integrity for downstream analyses like dimensionality reduction. Normalization quality was assessed through violin plots showing distributions of total counts/gene detections per cell (scanpy.pl.violin) and a scatter plot comparing these metrics (scanpy.pl.scatter). These visualizations confirmed successful removal of library size differences while retaining biologically relevant variation. The processed data was stored in H5AD format (""pbmc3k_normalized.h5ad"") to enable reproducible downstream analyses.","### Methods

#### Data Acquisition  
A publicly available peripheral blood mononuclear cell (PBMC) dataset (pbmc3k) was used as a benchmark for single-cell RNA sequencing (scRNA-seq) analysis. The dataset was loaded using the `scanpy.datasets.pbmc3k()` function, which retrieves the data in the AnnData format, a widely used data structure for single-cell genomics.

#### Data Normalization and Preprocessing  
To preserve the raw count data for downstream analyses requiring unnormalized values, the original count matrix was stored in a separate layer of the AnnData object. Normalization was performed to correct for differences in library size across cells. The total counts for each cell were scaled to a target sum of 10,000 using the `scanpy.pp.normalize_total()` function. Following normalization, a log(1+x) transformation was applied using the `scanpy.pp.log1p()` function to stabilize variance and improve the suitability of the data for linear modeling approaches.

#### Quality Control and Visualization  
To assess the quality of the normalization process, violin plots were generated to visualize the distributions of total counts and the number of detected genes per cell using the `scanpy.pl.violin()` function. Additionally, a scatter plot was created to examine the relationship between total counts and the number of genes detected per cell using the `scanpy.pl.scatter()` function. These visualizations were used to confirm the absence of technical artifacts or biases in the normalized data.

#### Data Storage  
The normalized and preprocessed AnnData object was saved to a file (`pbmc3k_normalized.h5ad`) for subsequent analyses, including the identification of highly variable genes, dimensionality reduction, and clustering. This ensures reproducibility and facilitates further exploration of the dataset.","numpy, scanpy, seaborn, matplotlib, scipy",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and data handling
import scanpy as sc
import anndata as ad

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting
# This ensures all plots have a consistent appearance.
sc.settings.set_figure_params(dpi=80, facecolor='white')

#--------------------------------
# Data Input
#--------------------------------

# Load an example peripheral blood mononuclear cell (PBMC) dataset
# This is a common benchmark dataset in single-cell analysis.
adata = sc.datasets.pbmc3k()

#--------------------------------
# Data Normalization and Preprocessing
#--------------------------------

# Save the raw, unnormalized count data into a separate layer.
# This is a good practice as it preserves the original data for future reference
# or for algorithms that require raw counts.
adata.layers[""counts""] = adata.X.copy()

# Normalize the data for sequencing depth.
# Each cell's total counts are scaled to a target sum (e.g., 10,000).
# This removes technical differences in library size across cells.
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply a log(1+x) transformation to the normalized data.
# This helps to stabilize the variance and makes the data more suitable for
# linear models used in downstream analysis (like PCA or differential expression).
sc.pp.log1p(adata)

# For verification, print a small slice of the transformed data matrix.
print(""Normalized data sample (first 5 cells, first 5 genes):"")
print(adata.X[:5, :5])


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Create violin plots to visualize the distributions of total counts and
# the number of detected genes per cell after normalization. This helps to
# confirm that the normalization has been applied correctly.
sc.pl.violin(
    adata,
    keys=[""total_counts"", ""n_genes_by_counts""],
    jitter=0.4,
    multi_panel=True,
    title=""QC Metrics after Normalization""
)

# Create a scatter plot to examine the relationship between the total counts and
# the number of genes detected in each cell. This can help identify if there
# are any remaining technical artifacts or biases in the data.
sc.pl.scatter(
    adata,
    x=""total_counts"",
    y=""n_genes_by_counts"",
    title=""Total Counts vs Number of Genes after Normalization""
)

#--------------------------------
# Data Output
#--------------------------------

# Save the normalized and processed AnnData object to a file.
# This file can be loaded for subsequent analysis steps, such as
# identifying highly variable genes, dimensionality reduction, and clustering.
adata.write(""pbmc3k_normalized.h5ad"")",https://www.sc-best-practices.org/preprocessing_visualization/normalization.html,F
7,scRNA-seq,Normalization,"The primary objective was to process and standardize scRNA-seq data to account for technical variability. This was accomplished using a log-normalization approach coupled with quality control filtering, implemented with the Seurat v4.0 package in R. Starting with raw 10X Genomics count matrices parsed via `Read10X`, the analysis involved initial filtering to exclude genes detected in <3 cells and cells with <200 genes. The remaining data were normalized using the """"LogNormalize"""" method, which scales counts per cell to 10,000 transcripts and applies a log transformation (log1p). Final normalization efficacy thresholds were predefined by QC parameters (>=200 genes/cell). The results were presented in a violin plot of normalized RNA counts (`nCount_RNA`) to illustrate balanced library sizes across cells post-normalization. These findings were further supported by saving the standardized dataset as an RDS file (`Normalized_Data_Object.rds`), which ensured compatibility with downstream tasks like clustering and differential expression analysis.  ","### Methods

#### Data Preprocessing and Normalization

Single-cell RNA sequencing (scRNA-seq) data were processed and analyzed using the Seurat package (version 4.0) in R. Raw count matrices were obtained from 10X Genomics data stored in the directory `path/to/filtered_gene_bc_matrices/hg19/`. The data were read into R using the `Read10X` function, which parsed the count matrices into a sparse matrix format. 

A Seurat object was created from the raw count matrix using the `CreateSeuratObject` function. Basic quality control filtering was applied at this stage: genes expressed in fewer than 3 cells and cells with fewer than 200 detected genes were excluded to ensure robust downstream analysis.

#### Data Normalization

Normalization was performed to account for differences in library size across cells. The `NormalizeData` function was used with the ""LogNormalize"" method, which normalizes gene counts for each cell by the total counts for that cell, scales the result by a factor of 10,000, and applies a natural-log transformation (`log1p`). This approach standardizes the data distribution and facilitates comparative analysis across cells.

#### Data Visualization

To assess the effect of normalization, a violin plot was generated using the `VlnPlot` function to visualize the distribution of normalized RNA counts (`nCount_RNA`) across all cells. This visualization provided an overview of the data distribution and confirmed the successful application of normalization.

#### Data Output

The normalized Seurat object was saved to an RDS file (`Normalized_Data_Object.rds`) using the `saveRDS` function. This file preserves the normalized data for subsequent downstream analyses, including scaling, dimensionality reduction, and clustering.

All analyses were performed using R version 4.0.3 with the Seurat, dplyr, and ggplot2 packages.","Seurat, dplyr, ggplot2",R,"#--------------------------------
# Package Load
#--------------------------------

# Import necessary libraries for single-cell analysis and data manipulation
library(Seurat)   # Main package for single-cell analysis
library(dplyr)    # For data manipulation functions
library(ggplot2)  # For advanced plotting capabilities

#--------------------------------
# Data Input
#--------------------------------

# Specify the directory containing the 10X Genomics count matrices.
# NOTE: You must replace this with the actual path to your data.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""

# Read the 10X Genomics data into a raw count matrix.
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object from the raw count matrix.
# Basic filtering is applied at this stage:
# - min.cells = 3: Keep genes that are expressed in at least 3 cells.
# - min.features = 200: Keep cells that have at least 200 detected genes.
seurat_obj <- CreateSeuratObject(
  counts = raw_data,
  project = ""DataNormalization"",
  min.cells = 3,
  min.features = 200
)

#--------------------------------
# Data Normalization
#--------------------------------

# Perform LogNormalization on the data. This is a standard method that:
# 1. Normalizes gene counts for each cell by the total counts for that cell.
# 2. Multiplies the result by a scaling factor (default is 10,000).
# 3. Applies a natural-log transformation (log1p).
seurat_obj <- NormalizeData(
  seurat_obj,
  normalization.method = ""LogNormalize"",
  scale.factor = 10000
)

#--------------------------------
# Plotting / Visualization
#--------------------------------

# Generate a violin plot to visualize the distribution of RNA counts per cell.
# This plot helps to assess the effect of normalization on the data distribution
# across all cells. 'nCount_RNA' is automatically calculated by Seurat.
VlnPlot(seurat_obj, features = ""nCount_RNA"", pt.size = 0.1) +
  ggtitle(""Distribution of Normalized RNA Counts"")

#--------------------------------
# Data Output
#--------------------------------

# Save the normalized Seurat object to an RDS file.
# This file can be loaded later for downstream analysis, such as scaling,
# dimensionality reduction, and clustering.
saveRDS(seurat_obj, file = ""Normalized_Data_Object.rds"")",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection,F
8,scRNA-seq,Feature selection,"The primary objective was to identify highly variable genes (HVGs) in peripheral blood mononuclear cell (PBMC) single-cell RNA sequencing data. This was accomplished using a dispersion-based selection method inspired by Seurat?€?s variability analysis, implemented with the Scanpy toolkit (version X.X.X) in Python. Starting with a raw count matrix stored in an AnnData object, the analysis involved normalizing total counts per cell to 10,000 transcripts and applying a log(1+x) transformation. The final HVGs were determined by ranking genes using mean expression and dispersion metrics, selecting the top 2,000 genes with the highest biological variability. The results were presented in a mean-vs-dispersion scatter plot to illustrate the relationship between gene expression levels and variability. These findings were further supported by saving the processed dataset in H5AD format, which preserved HVG annotations for downstream dimensionality reduction and clustering analyses.","### Methods

#### Data Preprocessing and Normalization  
Single-cell RNA sequencing data from peripheral blood mononuclear cells (PBMCs) were analyzed using the Scanpy toolkit (version X.X.X). The raw dataset was loaded and stored in an AnnData object, with the unprocessed data preserved in the `.raw` attribute for reference. To account for differences in sequencing depth across cells, the data were normalized by scaling the total counts per cell to a target sum of 10,000 transcripts using the `normalize_total` function. A log(1+x) transformation was subsequently applied to stabilize variance and facilitate comparability across genes with varying expression levels.

#### Highly Variable Gene Selection  
Highly variable genes (HVGs) were identified to focus downstream analyses on genes exhibiting significant cell-to-cell variation, which are more likely to be biologically relevant. The `highly_variable_genes` function was employed with the ""seurat"" flavor, a widely used method for HVG selection. The top 2,000 genes with the highest variability were selected based on their mean expression and dispersion. The number of identified HVGs was confirmed and recorded. To visually assess the selection process, a scatter plot was generated to display the mean expression versus dispersion for all genes, with HVGs highlighted.

#### Data Output  
The processed AnnData object, containing normalized data and the list of highly variable genes, was saved in H5AD format for subsequent analyses, such as scaling and dimensionality reduction.","scanpy, anndata",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and data handling
import scanpy as sc
import anndata as ad

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting
# This ensures all plots have a consistent, clean appearance.
sc.settings.set_figure_params(dpi=80, facecolor='white')

#--------------------------------
# Data Input
#--------------------------------

# Load an example peripheral blood mononuclear cell (PBMC) dataset
adata = sc.datasets.pbmc3k()

# It's good practice to keep a copy of the raw data.
# The .raw attribute is the conventional place to store it in Scanpy.
adata.raw = adata.copy()


#--------------------------------
# Data Normalization
#--------------------------------

# Normalize the data for sequencing depth by scaling total counts per cell to a target sum.
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply a log(1+x) transformation to the normalized data.
# This stabilizes variance and makes the data more comparable across genes with different expression levels.
sc.pp.log1p(adata)


#--------------------------------
# Major Analysis Task: Feature Selection
#--------------------------------

# Identify highly variable genes (HVGs). These are genes that show high cell-to-cell
# variation and are more likely to be biologically significant.
# The 'seurat' flavor is a commonly used method for this.
# `n_top_genes` specifies how many of the most variable genes to select.
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')

# Print the number of genes identified as highly variable for confirmation.
print(f""Number of highly variable genes found: {sum(adata.var.highly_variable)}"")


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Generate a scatter plot to visualize the highly variable genes.
# The plot shows each gene's mean expression versus its dispersion (a measure of variability).
# The selected HVGs are highlighted, which is useful for a visual quality check of the selection process.
sc.pl.highly_variable_genes(adata)


#--------------------------------
# Data Output
#--------------------------------

# Save the AnnData object, which now contains the normalized data and the list of
# highly variable genes. This object is ready for downstream steps like scaling and
# dimensionality reduction (PCA).
adata.write(""pbmc3k_hvg_selected.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html,F
9,scRNA-seq,Feature selection,"The primary objective was to identify highly variable genes (HVGs) for downstream single-cell RNA-seq analysis. This was accomplished using a variance-stabilizing transformation (vst) approach, implemented with the `FindVariableFeatures` function in the Seurat (v4.0) R package. Starting with raw 10X Genomics count matrices, the analysis involved quality control filtering (retaining genes expressed in ???3 cells and cells with ???200 genes), mitochondrial gene percentage calculation, and library-size normalization via the """"LogNormalize"""" method. The final HVGs were selected as the top 2,000 genes ranked by cell-to-cell variation. The results were presented in a variable feature plot to illustrate the relationship between average gene expression and dispersion. These findings were annotated with the top 10 HVGs and supported by saving the processed Seurat object (`FeatureSelection_SeuratObject.rds`), enabling subsequent scaling and clustering workflows.  ","### Methods

#### Data Input and Initial Filtering
Single-cell RNA sequencing data were processed using the Seurat package (v4.0) in R. Raw count matrices were obtained from 10X Genomics data stored in the directory `path/to/filtered_gene_bc_matrices/hg19/`. A Seurat object was created from the raw count matrix, applying initial quality control filters to retain genes expressed in at least 3 cells and cells with a minimum of 200 detected genes.

#### Quality Control and Normalization
To assess cell quality, the percentage of mitochondrial gene expression was calculated for each cell using the `PercentageFeatureSet` function, with mitochondrial genes identified by the prefix ""MT-"". Data normalization was performed using the `NormalizeData` function with the ""LogNormalize"" method, scaling the data by a factor of 10,000 to account for differences in library size and applying a log transformation.

#### Feature Selection
Highly variable genes (HVGs) were identified using the variance-stabilizing transformation (vst) method implemented in the `FindVariableFeatures` function. The top 2,000 genes exhibiting the highest cell-to-cell variation were selected for downstream analyses. The top 10 HVGs were annotated on a variable feature plot, which visualizes the relationship between average expression and dispersion for each gene.

#### Data Output
The processed Seurat object, including normalized data and identified HVGs, was saved as an RDS file (`FeatureSelection_SeuratObject.rds`) for subsequent analysis steps, such as scaling and clustering.","Seurat, dplyr, ggplot2",R,"#--------------------------------
# Package Load
#--------------------------------

# Import necessary libraries for single-cell analysis and data manipulation
library(Seurat)   # Main package for single-cell analysis
library(dplyr)    # For data manipulation functions
library(ggplot2)  # For advanced plotting capabilities

#--------------------------------
# Data Input
#--------------------------------

# Specify the directory containing the 10X Genomics count matrices.
# NOTE: You must replace this with the actual path to your data.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""

# Read the 10X Genomics data into a raw count matrix.
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object from the raw count matrix with basic initial filtering.
seurat_obj <- CreateSeuratObject(
  counts = raw_data,
  project = ""FeatureSelectionDemo"",
  min.cells = 3,      # Keep genes expressed in at least 3 cells
  min.features = 200  # Keep cells with at least 200 detected genes
)

#--------------------------------
# Preprocessing and Normalization
#--------------------------------

# OPTIONAL QC: Calculate the percentage of mitochondrial genes for each cell.
# This is a common QC metric; high percentages can indicate cell stress.
seurat_obj[[""percent.mt""]] <- PercentageFeatureSet(seurat_obj, pattern = ""^MT-"")

# Normalize the data using the ""LogNormalize"" method.
# This scales the data by library size and applies a log transformation.
seurat_obj <- NormalizeData(
  seurat_obj,
  normalization.method = ""LogNormalize"",
  scale.factor = 10000
)

#--------------------------------
# Major Analysis Task: Feature Selection
#--------------------------------

# Identify highly variable features (genes) using the variance-stabilizing transformation (vst) method.
# These genes show high cell-to-cell variation and are used for downstream analyses like PCA.
seurat_obj <- FindVariableFeatures(
  seurat_obj,
  selection.method = ""vst"",
  nfeatures = 2000 # Select the top 2000 most variable genes
)

#--------------------------------
# Plotting / Visualization
#--------------------------------

# Identify the top 10 most highly variable genes for labeling purposes.
top10 <- head(VariableFeatures(seurat_obj), 10)

# Create a variable feature plot to visualize gene variability.
# The plot shows the relationship between average expression and a measure of dispersion for each gene.
variable_feature_plot <- VariableFeaturePlot(seurat_obj)

# Add labels for the top 10 HVGs to the plot for better interpretation.
labeled_plot <- LabelPoints(plot = variable_feature_plot, points = top10, repel = TRUE)

# Print the final plot to the console.
print(labeled_plot)

#--------------------------------
# Data Output
#--------------------------------

# Save the Seurat object, which now includes the identified variable features.
# This object can be used for the next steps in the analysis, such as scaling and clustering.
saveRDS(seurat_obj, file = ""FeatureSelection_SeuratObject.rds"")",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection,F
10,scRNA-seq,Dimensionality reduction,"The primary objective was to analyze single-cell RNA sequencing data to identify cell populations and their gene expression patterns. This was accomplished using a combination of principal component analysis (PCA) and manifold-based visualization, implemented with the scanpy package (v1.9.0) in Python. Starting with a raw PBMC3k dataset stored as an AnnData object, the analysis involved total-count normalization, log(1+x) transformation, and selection of 2,000 highly variable genes. After scaling to unit variance, PCA reduced dimensionality to 40 principal components using an arpack solver. A neighborhood graph (10 nearest neighbors, 40 PCs) informed UMAP embedding to project cells into two dimensions. Key decisions included retaining PCs explaining significant variance and prioritizing genes with the Seurat-derived variability metric. Results were visualized through PCA plots and UMAP embeddings, with cells colored by marker genes (CST3, NKG7) to highlight population-specific expression. A log-scaled scree plot quantified variance contributions across PCs, while the UMAP illustrated spatial relationships between clusters. The final AnnData object preserved coordinates for downstream clustering, validated by co-expression patterns of known markers in low-dimensional projections.  ","### Methods

#### Data Acquisition and Preprocessing
The single-cell RNA sequencing (scRNA-seq) dataset of peripheral blood mononuclear cells (PBMCs) from 3,000 cells (PBMC3k) was obtained using the `scanpy` package (`v1.9.0`) in Python. The dataset was loaded as an `AnnData` object, a data structure optimized for single-cell data analysis. To ensure consistent and clear visualizations, global plotting parameters were configured using `scanpy.settings.set_figure_params`.

#### Normalization and Feature Selection
To account for differences in sequencing depth, the raw counts were normalized using the `scanpy.pp.normalize_total` function, with a target sum of 10,000 counts per cell. A log(1+x) transformation was then applied to stabilize the variance across genes. Highly variable genes (HVGs) were identified using the `scanpy.pp.highly_variable_genes` function with the `seurat` flavor, retaining the top 2,000 genes with the highest variability. The dataset was subset to include only these HVGs for downstream analysis.

#### Scaling and Dimensionality Reduction
The data were scaled to zero mean and unit variance using the `scanpy.pp.scale` function to ensure equal contribution of all genes to downstream analyses. Principal Component Analysis (PCA) was performed on the scaled data using the `scanpy.tl.pca` function with the `arpack` solver, retaining the top 40 principal components (PCs) for further analysis. The variance explained by each PC was visualized using a log-scaled plot to assess the dimensionality reduction.

#### Neighbor Graph Construction and UMAP Embedding
A neighborhood graph of cells was constructed based on the PCA representation using the `scanpy.pp.neighbors` function, with 10 nearest neighbors and 40 PCs. Uniform Manifold Approximation and Projection (UMAP) was then applied to generate a two-dimensional embedding for visualization using the `scanpy.tl.umap` function.

#### Visualization
The PCA results were visualized by plotting the first two PCs, with cells colored by the expression of marker genes `CST3` and `NKG7`. The UMAP embedding was similarly visualized, with cells colored by `CST3` expression to assess the separation of cell clusters.

#### Data Output
The processed dataset, including PCA and UMAP coordinates, was saved as an `AnnData` object in the H5AD file format (`pbmc3k_pca_umap.h5ad`) for downstream clustering and cell type annotation.

This workflow provides a reproducible pipeline for preprocessing, dimensionality reduction, and visualization of scRNA-seq data, enabling the identification of cell populations and marker gene expression patterns.","scanpy, anndata, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and plotting
import scanpy as sc
import anndata as ad
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting to ensure consistent and clear visuals
sc.settings.set_figure_params(dpi=80, facecolor='white')

#--------------------------------
# Data Input
#--------------------------------

# Load the built-in PBMC 3k dataset from Scanpy as an example
adata = sc.datasets.pbmc3k()

#--------------------------------
# Preprocessing & Dimensionality Reduction
#--------------------------------

# --- Normalization and Feature Selection ---
# Normalize total counts per cell to account for differences in sequencing depth
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply a log(1+x) transformation to stabilize the variance
sc.pp.log1p(adata)

# Identify highly variable genes (HVGs), which are most informative for downstream analysis
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')

# --- Scaling and PCA ---
# Subset the AnnData object to keep only the highly variable genes
adata = adata[:, adata.var.highly_variable]

# Scale the data so that each gene has zero mean and unit variance.
# This is crucial for PCA and other algorithms sensitive to feature scales.
sc.pp.scale(adata)

# Perform Principal Component Analysis (PCA) on the scaled data.
# This reduces the dimensionality of the data while retaining most of the variation.
sc.tl.pca(adata, svd_solver='arpack')

# --- UMAP Embedding ---
# Compute the neighborhood graph of cells. This is based on the PCA representation
# and is a prerequisite for UMAP.
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)

# Run Uniform Manifold Approximation and Projection (UMAP) to generate a
# non-linear 2D embedding for visualization.
sc.tl.umap(adata)

#--------------------------------
# Plotting / Visualization
#--------------------------------

# Plot the PCA variance ratio to see how much variance is captured by each principal component.
# The log scale helps visualize the ""elbow"" where the explained variance plateaus.
sc.pl.pca_variance_ratio(adata, log=True)

# Create a scatter plot of the first two principal components.
# Cells can be colored by marker gene expression to identify potential cell types.
sc.pl.pca(adata, color=['CST3', 'NKG7'])

# Visualize the UMAP embedding.
# Coloring by marker genes helps to see how cell clusters are separated in the UMAP space.
sc.pl.umap(adata, color='CST3')

#--------------------------------
# Data Output
#--------------------------------

# Save the processed AnnData object, which now contains PCA and UMAP coordinates.
# This file is ready for downstream clustering and cell type annotation.
adata.write(""pbmc3k_pca_umap.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html,F
11,scRNA-seq,Dimensionality reduction,"The primary objective was to capture primary dataset variation and generate low-dimensional embeddings for single-cell visualization. This was accomplished using a multi-stage dimensionality reduction strategy combining linear and non-linear methods, implemented with the scanpy package in Python. Starting with a preprocessed AnnData object containing log-normalized counts (`log1p_norm` layer), the analysis involved PCA on highly variable genes (HVGs) followed by neighborhood graph construction (15 nearest neighbors, 40 principal components). Non-linear embeddings were generated using t-SNE and UMAP, both leveraging the precomputed graph. Final embeddings were optimized using scanpy?€?s default algorithms with ARPACK PCA solver and Euclidean metric. The results were presented in PCA, t-SNE, and UMAP projections to illustrate dataset structure and potential technical biases. Cells were colored by total counts in all embeddings to evaluate sequencing depth distribution. These visualizations were validated by consistent cell separation patterns across methods, confirming that technical artifacts (e.g., library size variation) did not dominate biological variation. Output embeddings were stored for downstream clustering and annotation.","### Methods

#### Data Preprocessing and Input
The preprocessed single-cell RNA sequencing (scRNA-seq) data were loaded as an AnnData object, which had undergone prior quality control (QC), normalization, and feature selection. The data were accessed either from a local file (`s4d8_feature_selection.h5ad`) or, if unavailable, downloaded from a publicly available backup URL (https://figshare.com/ndownloader/files/40016014). The log-normalized data stored in the `log1p_norm` layer were explicitly selected for downstream analysis to ensure consistency.

#### Dimensionality Reduction
Principal Component Analysis (PCA) was performed on the highly variable genes to capture the primary axes of variation in the dataset. PCA was executed using the ARPACK solver (`svd_solver=""arpack""`), and the analysis was restricted to the highly variable genes identified during preprocessing (`use_highly_variable=True`).

To prepare for non-linear dimensionality reduction, a neighborhood graph was computed based on the PCA representation of the data. The graph was constructed using 15 nearest neighbors (`n_neighbors=15`) and the first 40 principal components (`n_pcs=40`). This neighborhood graph served as the foundation for both t-distributed Stochastic Neighbor Embedding (t-SNE) and Uniform Manifold Approximation and Projection (UMAP) analyses.

t-SNE was applied to generate a two-dimensional embedding for visualization, using the PCA representation as input (`use_rep=""X_pca""`). Similarly, UMAP was computed based on the precomputed neighborhood graph to produce an alternative low-dimensional embedding.

#### Visualization
To assess potential technical artifacts and ensure data quality, the PCA results were visualized by plotting the first two principal components, with cells colored by their total counts. The t-SNE and UMAP embeddings were also visualized, with cells similarly colored by total counts to evaluate the distribution of sequencing depth across the embeddings.

#### Data Output
The final AnnData object, containing the results of PCA, t-SNE, and UMAP, was saved to a file (`s4d8_dimensionality_reduction.h5ad`) for subsequent clustering and cell type annotation analyses.","scanpy, seaborn, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and plotting
import scanpy as sc
import seaborn as sns
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
sc.settings.verbosity = 0
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

#--------------------------------
# Data Input
#--------------------------------

# Load the preprocessed AnnData object. This file should have undergone
# prior QC, normalization, and feature selection.
# A backup URL is provided in case the local file is not found.
adata = sc.read(
    ""s4d8_feature_selection.h5ad"",
    backup_url=""https://figshare.com/ndownloader/files/40016014""
)

#--------------------------------
# Major Analysis Tasks: Dimensionality Reduction
#--------------------------------

# Ensure the analysis uses the log-normalized data stored in a specific layer.
# This step makes the choice of data layer explicit.
adata.X = adata.layers[""log1p_norm""]

# --- Principal Component Analysis (PCA) ---
# Perform PCA on the highly variable genes to capture the main axes of variation.
sc.pp.pca(adata, svd_solver=""arpack"", use_highly_variable=True)

# --- t-SNE & UMAP Prerequisite: Neighborhood Graph ---
# Compute the neighborhood graph, which is required for both t-SNE and UMAP.
# This is calculated on the PCA representation of the data.
sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)

# --- t-distributed Stochastic Neighbor Embedding (t-SNE) ---
# Run t-SNE to generate a 2D embedding for visualization.
# It uses the PCA representation (`use_rep=""X_pca""`) as input.
sc.tl.tsne(adata, use_rep=""X_pca"")

# --- Uniform Manifold Approximation and Projection (UMAP) ---
# Compute the UMAP embedding based on the neighborhood graph.
sc.tl.umap(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the PCA result, coloring cells by total counts to check for technical artifacts.
sc.pl.pca_scatter(adata, color=""total_counts"", title=""PCA: First 2 Components"")

# Visualize the t-SNE embedding, also colored by total counts.
sc.pl.tsne(adata, color=""total_counts"", title=""t-SNE Embedding"")

# Visualize the UMAP embedding, colored by total counts.
sc.pl.umap(adata, color=""total_counts"", title=""UMAP Embedding"")


#--------------------------------
# Data Output
#--------------------------------

# Save the final AnnData object, which now contains the results of PCA, t-SNE, and UMAP.
# This object is ready for clustering and cell type annotation.
adata.write(""s4d8_dimensionality_reduction.h5ad"")
",https://www.sc-best-practices.org/preprocessing_visualization/dimensionality_reduction.html,F
12,scRNA-seq,Dimensionality reduction,"The primary objective was to reduce the dimensionality of single-cell RNA-seq data and capture major sources of transcriptional variation. This was accomplished using principal component analysis (PCA) and Uniform Manifold Approximation and Projection (UMAP), implemented with the **Seurat package (v4.0.0)** in R. Starting with **raw count matrices from 10X Genomics**, the analysis involved log-normalization (scale factor = 10,000) to correct library size differences, followed by identification of **2,000 highly variable genes (HVGs)** using the variance-stabilizing transformation (vst) method. Data were scaled to standardize gene expression variance, and PCA was applied to HVGs. Critical principal components (PCs) were selected using an **Elbow Plot**, retaining the first 10 PCs representing the most significant biological variation. UMAP was then executed to generate a 2D embedding from the neighborhood graph derived from these PCs. The results were presented in a **PCA plot (PC1 vs. PC2)** to highlight primary variation patterns and a **UMAP embedding** to visualize global cell-state relationships. The Elbow Plot guided PC selection by quantifying variance contributions. These visualizations were combined using the **patchwork** package to provide a consolidated overview. The UMAP structure and PCA-driven PC retention criteria were further validated by downstream clustering compatibility, ensuring biologically meaningful dimensionality reduction.  ","### Methods

#### Data Loading and Initial Processing
Single-cell RNA sequencing (scRNA-seq) data were processed using the Seurat package (version 4.0.0) in R. Raw count matrices generated from 10X Genomics were imported using the `Read10X` function, specifying the directory containing the filtered gene-barcode matrices. A Seurat object was created from the raw count matrix, applying initial quality control filters to retain genes detected in at least 3 cells and cells expressing at least 200 genes.

#### Data Normalization and Feature Selection
Count data were normalized using the ""LogNormalize"" method, scaling the total expression of each cell to 10,000 transcripts to account for differences in library size. Highly variable genes (HVGs) were identified using the variance-stabilizing transformation (vst) method, selecting the top 2,000 genes with the highest variability across cells. The expression levels of all genes were then scaled to have a mean of zero and a variance of one, ensuring comparability across features.

#### Dimensionality Reduction
Principal component analysis (PCA) was performed on the scaled data using the identified HVGs to reduce dimensionality and capture the major sources of variation. The number of principal components (PCs) to retain for downstream analysis was determined using an Elbow Plot, which visualizes the proportion of variance explained by each PC. Based on the plot, the first 10 PCs were selected for further analysis. A neighborhood graph was constructed using these PCs, and Uniform Manifold Approximation and Projection (UMAP) was applied to generate a two-dimensional embedding for visualization.

#### Visualization
The PCA results were visualized by plotting the first two PCs to assess the primary sources of variation. An Elbow Plot was generated to guide the selection of significant PCs, and the UMAP embedding was plotted to explore the global structure of the data. All plots were combined using the patchwork package for a comprehensive overview.

#### Data Output
The processed Seurat object, containing normalized data, PCA results, and UMAP embeddings, was saved for downstream clustering and annotation.

### Software and Parameters
- **Software**: Seurat (v4.0.0), ggplot2, patchwork.
- **Normalization**: LogNormalize method, scale factor = 10,000.
- **Feature Selection**: vst method, top 2,000 HVGs.
- **Dimensionality Reduction**: PCA (HVGs), UMAP (10 PCs).
- **Visualization**: PCA (PC1 vs. PC2), Elbow Plot (50 PCs), UMAP (PCs 1-10).","Seurat, ggplot2, patchwork",R,"#--------------------------------
# Package Load
#--------------------------------

# Load required libraries for single-cell analysis and plotting
library(Seurat)      # Main package for single-cell workflows
library(ggplot2)     # For creating custom, publication-quality plots
library(patchwork)   # For easily combining multiple ggplot2 plots

#--------------------------------
# Data Input
#--------------------------------

# Specify the directory containing the 10X Genomics count matrices.
# NOTE: You must replace this with the actual path to your data.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""

# Read the 10X Genomics data into a raw count matrix.
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object from the raw count matrix with basic initial filtering.
seurat_obj <- CreateSeuratObject(
  counts = raw_data,
  project = ""DimRed_DimDetermination"",
  min.cells = 3,
  min.features = 200
)

#--------------------------------
# Preprocessing and Normalization
#--------------------------------

# 1. Normalize the data using the ""LogNormalize"" method.
seurat_obj <- NormalizeData(
  seurat_obj,
  normalization.method = ""LogNormalize"",
  scale.factor = 10000
)

# 2. Identify highly variable features (HVGs).
seurat_obj <- FindVariableFeatures(
  seurat_obj,
  selection.method = ""vst"",
  nfeatures = 2000
)

# 3. Scale the data. This shifts the expression of each gene so that the mean
# expression across cells is 0 and the variance is 1.
all_genes <- rownames(seurat_obj)
seurat_obj <- ScaleData(seurat_obj, features = all_genes)


#--------------------------------
# Major Analysis Tasks: Dimensionality Reduction
#--------------------------------

# --- Principal Component Analysis (PCA) ---
# Run PCA on the scaled data, using only the highly variable features.
seurat_obj <- RunPCA(seurat_obj, features = VariableFeatures(seurat_obj))

# --- UMAP Embedding ---
# Note: Choosing the number of PCs is a critical step. The Elbow Plot in the
# visualization section helps with this decision. Here, we use 10 as an example.
# First, compute the neighborhood graph based on the selected PCs.
seurat_obj <- FindNeighbors(seurat_obj, dims = 1:10)

# Then, run UMAP to get a non-linear embedding for visualization.
seurat_obj <- RunUMAP(seurat_obj, dims = 1:10)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- PCA Plot ---
# Visualize the first two principal components. Coloring by 'nCount_RNA' can help
# reveal if technical factors (like library size) are driving the main sources of variation.
pca_plot <- DimPlot(seurat_obj, reduction = ""pca"") +
  ggtitle(""PCA: PC1 vs PC2"")

# --- Elbow Plot for Dimensionality Determination ---
# An Elbow Plot helps to determine the number of significant PCs to use for downstream
# analysis. The ""elbow"" of the plot represents the point of diminishing returns,
# where adding more PCs explains little additional variance.
elbow_plot <- ElbowPlot(seurat_obj, ndims = 50) +
  ggtitle(""Elbow Plot: Variance Explained vs. PC"")

# --- UMAP Plot ---
# Visualize the UMAP embedding, which is often used for identifying cell clusters.
umap_plot <- DimPlot(seurat_obj, reduction = ""umap"") +
  ggtitle(""UMAP Embedding (Using PCs 1-10)"")

# --- Combined Plot ---
# Use patchwork to arrange the plots for a comprehensive overview.
(pca_plot | elbow_plot) / umap_plot


#--------------------------------
# Data Output
#--------------------------------

# Save the processed Seurat object. It now contains the scaled data,
# PCA results, and UMAP embedding, ready for clustering and annotation.
saveRDS(seurat_obj, file = ""DimRed_DimDetermined_SeuratObject.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection,F
13,scRNA-seq,Clustering,"The primary objective was to identify cell subpopulations in the PBMC3k single-cell RNA-seq dataset through unsupervised clustering. This was accomplished using a graph-based clustering strategy, implemented with the Scanpy toolkit (v1.9.0) in Python. Starting with the raw gene expression matrix, the analysis involved normalization, log transformation, and selection of 2,000 highly variable genes. The scaled data underwent PCA, followed by neighborhood graph construction (40 PCs, 10 neighbors). Leiden clustering was applied using a fixed iteration count (\(n_{\text{iterations}}=2\)) to ensure reproducibility. The results were presented in a UMAP plot to illustrate spatial separation of Leiden clusters. These findings were supported by saving the annotated dataset in H5AD format, enabling downstream validation through marker-based cell type identification. Cluster assignments were stored in `adata.obs['leiden']` for further analysis. ","### Methods

#### Data Preprocessing and Normalization  
The single-cell RNA-seq dataset was processed using the Scanpy toolkit (version 1.9.0). The publicly available PBMC3k dataset was loaded as an example dataset. To preserve the raw data for downstream analysis, a copy of the unprocessed data was stored in the `.raw` attribute of the AnnData object. Data normalization was performed to account for differences in sequencing depth by scaling the total counts per cell to a target sum of 10,000 (`target_sum=1e4`). A log(1+x) transformation was subsequently applied to stabilize the variance across genes.  

#### Feature Selection and Scaling  
Highly variable genes (HVGs) were identified using the Seurat flavor method, with the top 2,000 genes selected for downstream analysis (`n_top_genes=2000`). The dataset was subset to retain only these HVGs. The expression values were then scaled to achieve zero mean and unit variance for each gene, ensuring comparability across features.  

#### Dimensionality Reduction and Neighborhood Graph Construction  
Principal Component Analysis (PCA) was performed on the scaled data using the ARPACK solver (`svd_solver='arpack'`). A neighborhood graph of cells was constructed based on the top 40 principal components (`n_pcs=40`) and a neighborhood size of 10 (`n_neighbors=10`). This graph served as the foundation for both clustering and visualization.  

#### Visualization and Clustering  
A UMAP embedding was generated from the neighborhood graph to visualize the data in two dimensions. Cell clustering was performed using the Leiden algorithm, which identifies communities within the neighborhood graph. The clustering was executed with the `igraph` flavor and a fixed number of iterations (`n_iterations=2`) to ensure reproducibility.  

#### Visualization and Data Output  
The UMAP embedding was visualized with cells colored by their assigned Leiden clusters to assess the clustering results. The processed AnnData object, including clustering results stored in `adata.obs['leiden']`, was saved in H5AD format for further analysis and cell type annotation.  

All analyses were performed using default parameters unless otherwise specified.",scanpy,python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import the Scanpy library for single-cell analysis
import scanpy as sc

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting to ensure consistent and clear visuals
sc.settings.set_figure_params(dpi=80, facecolor='white')

#--------------------------------
# Data Input
#--------------------------------

# Load the built-in PBMC 3k dataset from Scanpy as an example
adata = sc.datasets.pbmc3k()

# It's good practice to keep a copy of the raw data.
# The .raw attribute is the conventional place to store it in Scanpy.
adata.raw = adata.copy()

#--------------------------------
# Preprocessing & Dimensionality Reduction
#--------------------------------

# --- Normalization, Feature Selection, and Scaling ---
# Normalize total counts per cell to account for sequencing depth differences
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply a log(1+x) transformation to stabilize the variance
sc.pp.log1p(adata)

# Identify highly variable genes (HVGs) for downstream analysis
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')

# Subset the AnnData object to keep only the highly variable genes
adata = adata[:, adata.var.highly_variable]

# Scale the data so that each gene has zero mean and unit variance
sc.pp.scale(adata)

# --- PCA and Neighborhood Graph ---
# Perform Principal Component Analysis (PCA) on the scaled data
sc.tl.pca(adata, svd_solver='arpack')

# Compute the neighborhood graph of cells based on the PCA representation.
# This graph is the basis for both clustering and UMAP embedding.
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)

# --- UMAP for Visualization ---
# Generate a UMAP embedding from the neighbors graph. This is for visualization purposes.
sc.tl.umap(adata)

#--------------------------------
# Major Analysis Task: Clustering
#--------------------------------

# Apply the Leiden algorithm to find communities (clusters) in the neighborhood graph.
# The `flavor='igraph'` and a fixed number of iterations are used for performance and reproducibility.
sc.tl.leiden(adata, flavor='igraph', n_iterations=2)

#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the UMAP embedding, with cells colored by their assigned Leiden cluster.
# This plot allows for a visual assessment of the clustering results.
sc.pl.umap(adata, color=['leiden'], title=""Leiden Clustering on PBMC3k"", size=20)

#--------------------------------
# Data Output
#--------------------------------

# Save the processed AnnData object. It now contains the clustering results
# in `adata.obs['leiden']` and is ready for cell type annotation.
adata.write(""pbmc3k_clustered.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html,F
14,scRNA-seq,Clustering,"The primary objective was to identify distinct cell populations in a single-cell RNA-seq dataset. This was accomplished using a graph-based clustering approach optimized for modularity, implemented with the Leiden algorithm through Scanpy's clustering tools. Starting with a PCA-processed AnnData object, the analysis involved constructing a nearest-neighbor graph (30 PCs, 15 neighbors) followed by Leiden clustering at a resolution of 1.0. Final cluster assignments were determined based on the modularity-optimizing graph partitioning and stored as categorical labels. The results were presented in a UMAP projection with Leiden cluster labels overlaid to illustrate spatial grouping patterns. These findings were supported by embedding coordinates saved in the AnnData object, enabling direct linkage between clusters and their spatial organization for subsequent marker gene analysis.","### Methods

#### Data Preprocessing and Input  
The preprocessed single-cell RNA sequencing dataset was loaded as an AnnData object (`s4d8_dimensionality_reduction.h5ad`), which included dimensionality reduction results from principal component analysis (PCA). In cases where the local file was unavailable, a backup URL (`https://figshare.com/ndownloader/files/40016014`) was utilized to retrieve the data.

#### Neighborhood Graph Construction  
To capture the underlying structure of the data, a neighborhood graph was computed using the PCA representation. The graph was constructed with 30 principal components (`n_pcs=30`) and 15 nearest neighbors (`n_neighbors=15`), as implemented in the `scanpy.pp.neighbors` function. This graph served as the foundation for subsequent clustering and visualization steps.

#### Clustering Analysis  
Cell populations were identified using the Leiden algorithm, a graph-based clustering method optimized for modularity. The clustering was performed on the neighborhood graph with a resolution parameter of 1.0 (`resolution=1.0`), which controls the granularity of the clusters. The resulting cluster assignments were stored in the `adata.obs['leiden']` field.

#### Dimensionality Reduction and Visualization  
To visualize the data in a low-dimensional space, a uniform manifold approximation and projection (UMAP) embedding was computed from the neighborhood graph using the `scanpy.tl.umap` function. The UMAP embedding was plotted with cells colored by their assigned Leiden clusters. Cluster labels were directly annotated on the plot for clarity.

#### Data Output  
The updated AnnData object, now containing the clustering results and UMAP embedding, was saved as `s4d8_clustering.h5ad` for downstream marker gene analysis.","scanpy, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and plotting
import scanpy as sc
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
sc.settings.verbosity = 0
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

#--------------------------------
# Data Input
#--------------------------------

# Load the preprocessed AnnData object. This file should contain
# dimensionality reduction results (e.g., PCA).
# A backup URL is provided in case the local file is not found.
adata = sc.read(
    ""s4d8_dimensionality_reduction.h5ad"",
    backup_url=""https://figshare.com/ndownloader/files/40016014""
)

#--------------------------------
# Major Analysis Task: Clustering
#--------------------------------

# --- Neighborhood Graph ---
# Compute the neighborhood graph of cells based on the PCA representation.
# This graph is the foundation for both clustering and UMAP.
sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30)

# --- Leiden Clustering ---
# Apply the Leiden algorithm to partition the neighborhood graph into clusters.
# The 'resolution' parameter controls the number of clusters found; higher
# values lead to more, smaller clusters.
sc.tl.leiden(adata, resolution=1.0, key_added=""leiden"")

# --- UMAP for Visualization ---
# Compute the UMAP embedding from the neighborhood graph. This is done
# here to ensure it's available for plotting, in case it wasn't run previously.
sc.tl.umap(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the UMAP embedding, with cells colored by their assigned Leiden cluster.
# The `legend_loc='on data'` option places cluster labels directly on the plot.
sc.pl.umap(adata, color=[""leiden""], title=""Leiden Clustering"", legend_loc='on data')


#--------------------------------
# Data Output
#--------------------------------

# Save the updated AnnData object. It now contains the clustering results
# stored in `adata.obs['leiden']` and is ready for marker gene analysis.
adata.write(""s4d8_clustering.h5ad"")
",https://www.sc-best-practices.org/cellular_structure/clustering.html,F
15,scRNA-seq,Clustering,"The primary objective was to identify distinct cell clusters from single-cell RNA sequencing data. This was accomplished using graph-based clustering, implemented with the Seurat (v4.0) R package. Starting with raw count matrices from 10X Genomics, the analysis involved filtering cells (<200 genes) and genes (<3 cells), followed by log-normalization and selection of 2,000 highly variable genes. Dimensionality reduction was performed via PCA using the top variable genes, and cell clustering was executed through KNN graph construction with resolution 0.5. Cluster assignments were determined based on these parameters and quality control thresholds for mitochondrial gene content. The results were visualized on UMAP projections to display cluster separation, supported by violin plots of QC metrics (gene counts, mitochondrial percentages). PCA and UMAP embeddings further validated the biological structure, while the output RDS file enabled downstream marker analysis.","### Methods

#### Data Input and Initial Filtering  
Single-cell RNA sequencing data were processed using the Seurat package (v4.0) in R. Raw count matrices were obtained from 10X Genomics output files stored in the directory `path/to/filtered_gene_bc_matrices/hg19/`. A Seurat object was created from the raw count matrix, with initial filtering applied to retain genes detected in at least 3 cells and cells expressing at least 200 genes.

#### Preprocessing, Quality Control, and Normalization  
Quality control metrics were calculated, including the percentage of mitochondrial genes (`percent.mt`) for each cell, identified by the ""^MT-"" prefix in gene names. Data were normalized using the `LogNormalize` method with a scale factor of 10,000 to account for differences in library size. Highly variable genes were identified using the `vst` method, selecting the top 2,000 genes for downstream analysis. The data were then scaled to ensure equal contribution of genes during principal component analysis (PCA).

#### Dimensionality Reduction and Clustering  
PCA was performed on the highly variable genes to reduce dimensionality. The first 10 principal components (PCs) were used to construct a k-nearest neighbor (KNN) graph. Graph-based clustering was applied using the `FindClusters` function with a resolution parameter of 0.5 to partition cells into distinct clusters. Uniform Manifold Approximation and Projection (UMAP) was performed on the same 10 PCs to generate a 2D embedding for visualization.

#### Visualization and Data Output  
Quality control metrics, including the number of detected genes (`nFeature_RNA`), total counts (`nCount_RNA`), and mitochondrial gene percentage (`percent.mt`), were visualized using violin plots. PCA and UMAP embeddings were plotted to assess data structure and cluster assignments, respectively. The processed Seurat object, containing clustering results, was saved as an RDS file (`Clustering_SeuratObject.rds`) for downstream marker analysis and cell type annotation.","Seurat, dplyr, ggplot2, patchwork",R,"#--------------------------------
# Package Load
#--------------------------------

# Load required libraries for single-cell analysis, data manipulation, and plotting
library(Seurat)      # Main package for single-cell RNA-seq analysis
library(dplyr)       # For data manipulation functions
library(ggplot2)     # For creating custom, publication-quality plots
library(patchwork)   # For easily combining multiple ggplot2 plots

#--------------------------------
# Data Input
#--------------------------------

# Specify the directory containing the 10X Genomics count matrices.
# NOTE: You must replace this with the actual path to your data.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""

# Read the 10X Genomics data into a raw count matrix.
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object from the raw count matrix with basic initial filtering.
seurat_obj <- CreateSeuratObject(
  counts = raw_data,
  project = ""ClusteringDemo"",
  min.cells = 3,
  min.features = 200
)

#--------------------------------
# Preprocessing, QC, and Normalization
#--------------------------------

# Calculate the percentage of mitochondrial genes for each cell as a QC metric.
seurat_obj[[""percent.mt""]] <- PercentageFeatureSet(seurat_obj, pattern = ""^MT-"")

# Normalize the data to account for differences in library size.
seurat_obj <- NormalizeData(
  seurat_obj,
  normalization.method = ""LogNormalize"",
  scale.factor = 10000
)

# Identify highly variable features (genes) to be used for downstream analysis.
seurat_obj <- FindVariableFeatures(
  seurat_obj,
  selection.method = ""vst"",
  nfeatures = 2000
)

# Scale the data, which is a standard step before running PCA.
seurat_obj <- ScaleData(seurat_obj, features = rownames(seurat_obj))


#--------------------------------
# Major Analysis Tasks: Dimensionality Reduction & Clustering
#--------------------------------

# --- PCA ---
# Run Principal Component Analysis on the highly variable features.
seurat_obj <- RunPCA(seurat_obj, features = VariableFeatures(seurat_obj))

# --- Clustering ---
# Build a K-nearest neighbor (KNN) graph based on the PCA space.
# The number of PCs (dims) used is a critical parameter.
seurat_obj <- FindNeighbors(seurat_obj, dims = 1:10)

# Apply graph-based clustering to partition the cells.
# The `resolution` parameter controls the number of clusters identified.
seurat_obj <- FindClusters(seurat_obj, resolution = 0.5)

# --- UMAP for Visualization ---
# Run UMAP to generate a non-linear 2D embedding for visualization.
seurat_obj <- RunUMAP(seurat_obj, dims = 1:10)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize QC metrics with violin plots.
VlnPlot(seurat_obj, features = c(""nFeature_RNA"", ""nCount_RNA"", ""percent.mt""), ncol = 3)

# Visualize the PCA results.
DimPlot(seurat_obj, reduction = ""pca"") + ggtitle(""PCA Plot"")

# Visualize the UMAP embedding with cells colored by their assigned cluster.
DimPlot(seurat_obj, reduction = ""umap"", label = TRUE, pt.size = 0.8) +
  ggtitle(""UMAP Plot with Cluster Labels"")


#--------------------------------
# Data Output
#--------------------------------

# Save the processed Seurat object, which now contains clustering results.
# This object is ready for downstream marker analysis and cell type annotation.
saveRDS(seurat_obj, file = ""Clustering_SeuratObject.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection,F
16,scRNA-seq,Annotation,"The primary objective was to annotate cell types in peripheral blood mononuclear cells (PBMCs) from single-cell RNA sequencing data. This was accomplished using a clustering-driven marker identification strategy, implemented with the Scanpy package in Python. Starting with raw gene count matrices, the analysis involved normalization, log transformation, and selection of highly variable genes. Principal Component Analysis (PCA) and Leiden clustering were performed to identify cell clusters, followed by UMAP projection for visualization. Cell-type identities were assigned by mapping Leiden clusters to canonical marker genes (e.g., MS4A1 for B cells, CD3D for T cells) based on their expression patterns in a dot plot. The results were visualized by projecting cell-type annotations onto the UMAP embedding to display cluster identities. These findings were further supported by dot plot validation of marker gene specificity and the export of annotated data in H5AD format for reproducibility.","### Methods

#### Data Preprocessing and Clustering  
Single-cell RNA sequencing data from the PBMC 3k dataset were processed using the Scanpy package (v1.9.0). To account for differences in sequencing depth, raw counts were normalized to a total count of 10,000 per cell using the `normalize_total` function, followed by a log(1+x) transformation to stabilize variance. Highly variable genes (HVGs) were identified using the `highly_variable_genes` function with the Seurat flavor, retaining the top 2,000 genes for downstream analysis. The dataset was subset to include only these HVGs, and the data were scaled to achieve zero mean and unit variance per gene using the `scale` function.  

Principal Component Analysis (PCA) was performed on the scaled data using the `pca` function with the ARPACK solver. A neighborhood graph was constructed using the `neighbors` function with 10 nearest neighbors and 40 principal components. Uniform Manifold Approximation and Projection (UMAP) was applied to generate a two-dimensional embedding for visualization. Cell clusters were identified using the Leiden algorithm (`leiden` function) with default parameters.  

#### Cell-Type Annotation  
Canonical marker genes for major PBMC cell types were defined as follows: B cells (MS4A1, CD79A), T cells (CD3D, CD3E), NK cells (NKG7, GNLY), and monocytes (CD14, LYZ). Cell types were assigned to Leiden clusters by inspecting the expression patterns of these marker genes in a dot plot generated using the `dotplot` function. A manual mapping of cluster IDs to cell types was created based on this visualization. Cell-type annotations were added to the dataset by mapping the Leiden cluster labels to the corresponding cell types using the `map` function.  

#### Data Visualization and Output  
Cell-type annotations were visualized on the UMAP embedding using the `umap` function. The fully processed and annotated dataset, including normalized counts, HVGs, PCA embeddings, UMAP coordinates, Leiden clusters, and cell-type annotations, was saved in the H5AD file format using the `write` function for downstream analysis.","scanpy, annodata",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and data handling
import scanpy as sc
import anndata as ad

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting to ensure consistent and clear visuals
sc.settings.set_figure_params(dpi=80, facecolor='white')

#--------------------------------
# Data Input
#--------------------------------

# Load the built-in PBMC 3k dataset from Scanpy as an example
adata = sc.datasets.pbmc3k()

#--------------------------------
# Preprocessing & Clustering
#--------------------------------

# --- Normalization, Feature Selection, and Scaling ---
# Normalize total counts per cell to account for sequencing depth differences
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply a log(1+x) transformation to stabilize the variance
sc.pp.log1p(adata)

# Identify highly variable genes (HVGs) for downstream analysis
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')

# Subset the AnnData object to keep only the highly variable genes
adata = adata[:, adata.var.highly_variable]

# Scale the data so that each gene has zero mean and unit variance
sc.pp.scale(adata)

# --- PCA, Neighborhood Graph, and UMAP ---
# Perform Principal Component Analysis (PCA) on the scaled data
sc.tl.pca(adata, svd_solver='arpack')

# Compute the neighborhood graph, which is the basis for clustering and UMAP
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)

# Generate a UMAP embedding for visualization
sc.tl.umap(adata)

# --- Leiden Clustering ---
# Apply the Leiden algorithm to find communities (clusters) of cells
sc.tl.leiden(adata)

#--------------------------------
# Major Analysis Task: Cell-Type Annotation
#--------------------------------

# Define a dictionary of canonical marker genes for common PBMC types.
# These genes are used to identify cell types based on their expression patterns.
marker_genes = {
    'B cells': ['MS4A1', 'CD79A'],
    'T cells': ['CD3D', 'CD3E'],
    'NK cells': ['NKG7', 'GNLY'],
    'Monocytes': ['CD14', 'LYZ']
}

# Manually define a mapping from cluster IDs to cell type names.
# NOTE: This mapping is created after inspecting the dot plot below and should be
# adjusted based on the specific results of your analysis.
cluster_to_cell_type = {
    '0': 'T cells',
    '1': 'Monocytes',
    '2': 'NK cells',
    '3': 'B cells',
    '4': 'T cells' # Example of merging multiple clusters into one cell type
}

# Create a new column in the observation metadata to store the cell type annotations.
# The .map() function applies the dictionary to the 'leiden' column.
adata.obs['cell_type'] = adata.obs['leiden'].map(cluster_to_cell_type).astype('category')


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Generate a dot plot to visualize the expression of marker genes across clusters.
# This plot is essential for assigning cell types to clusters.
sc.pl.dotplot(adata, marker_genes, groupby='leiden', standard_scale='var',
              title='Marker Expression by Leiden Clusters')

# Visualize the final cell type annotations on the UMAP embedding.
# This plot shows the spatial distribution of the identified cell types.
sc.pl.umap(adata, color='cell_type', title='Cell Type Annotation', legend_loc='on data')

#--------------------------------
# Data Output
#--------------------------------

# Save the fully processed and annotated AnnData object.
# This file can be used for further downstream analysis, such as differential
# expression between cell types or cell-cell interaction studies.
adata.write(""pbmc3k_annotated.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html,F
17,scRNA-seq,Annotation,"The primary objective was to manually annotate cell types in clustered single-cell RNA-seq data. This was accomplished using prior biological knowledge and marker gene associations, implemented with the `scanpy` Python library (version 1.9.0). Starting with a preprocessed AnnData object containing Leiden clustering results (`adata.obs['leiden']`), the analysis involved mapping cluster IDs to predefined cell types (e.g., """"B cell,"""" """"T cell"""") via a dictionary lookup. Unmapped clusters were labeled as """"Unknown,"""" with annotations stored in `adata.obs['manual_annotation']`. UMAP embeddings were generated after neighbor graph construction to visualize cluster identities spatially, ensuring consistency between computational clustering and biological interpretation. The results were presented in a UMAP plot colored by manual annotations to illustrate spatial separation of annotated cell types. These findings were supported by a summary table of cell counts per annotated type, confirming distinct population sizes and the absence of unassigned clusters in critical biological subgroups.","### Methods

#### Data Input  
The preprocessed and clustered single-cell RNA-seq data were loaded as an AnnData object using the `scanpy` library (`sc.read` function). The data were sourced from a local file (`s4d8_clustering.h5ad`), with a backup URL provided for redundancy (`https://figshare.com/ndownloader/files/40016014`). The object contained clustering results stored in the `adata.obs['leiden']` column.

#### Cell-Type Annotation  
Manual cell-type annotation was performed based on prior biological knowledge or marker gene analysis. A dictionary was defined to map cluster IDs (e.g., ""0"", ""1"") to specific cell types (e.g., ""B cell"", ""T cell""). The `map` function was applied to the `leiden` column in the observation metadata (`adata.obs`), assigning the corresponding cell type label to each cluster. Clusters not explicitly mapped in the dictionary were labeled as ""Unknown"". The resulting annotations were stored in a new column, `manual_annotation`. A summary of cell counts per annotated cell type was generated for quality control.

#### Visualization  
To visualize the annotated cell populations, a UMAP embedding was computed if not already present in the AnnData object. The UMAP computation was preceded by the construction of a neighbor graph using the `sc.pp.neighbors` function. The `sc.tl.umap` function was then applied to generate the UMAP coordinates. Cells were plotted on the UMAP embedding, with colors corresponding to their manually annotated cell types. The plot was generated using the `sc.pl.umap` function, with annotations displayed directly on the data points.

#### Data Output  
The updated AnnData object, now including the manual cell-type annotations, was saved to a new file (`s4d8_manual_annotation.h5ad`) for downstream analysis. This file preserves the annotated data for further investigation of specific cell populations.  

All analyses were performed using the `scanpy` library (version 1.9.0) in Python.","scanpy, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and plotting
import scanpy as sc
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
sc.settings.verbosity = 0
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

#--------------------------------
# Data Input
#--------------------------------

# Load the preprocessed and clustered AnnData object.
# This file is expected to contain clustering results (e.g., in `adata.obs['leiden']`).
# A backup URL is provided in case the local file is not found.
adata = sc.read(
    ""s4d8_clustering.h5ad"",
    backup_url=""https://figshare.com/ndownloader/files/40016014""
)

#--------------------------------
# Major Analysis Task: Cell-Type Annotation
#--------------------------------

# Define a dictionary to manually map cluster IDs to cell type names.
# This mapping is based on prior biological knowledge or marker gene analysis.
manual_labels = {
    ""0"": ""B cell"",
    ""1"": ""T cell"",
    ""2"": ""Myeloid cell"",
    ""3"": ""NK cell"",
    ""4"": ""Dendritic cell""
}

# Create a new column 'manual_annotation' in the observation metadata.
# The .map() function applies the dictionary. The lambda function with .get()
# ensures that any cluster ID not in the dictionary is assigned ""Unknown"".
adata.obs[""manual_annotation""] = adata.obs[""leiden""].map(
    lambda x: manual_labels.get(x, ""Unknown"")
)

# Print a count of cells assigned to each annotated cell type for a quick summary.
print(""Manual annotation summary:"")
print(adata.obs[""manual_annotation""].value_counts())


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Ensure a UMAP embedding exists for visualization.
# This check prevents errors if the loaded object doesn't have UMAP coordinates.
if ""X_umap"" not in adata.obsm.keys():
    sc.pp.neighbors(adata) # UMAP requires a neighbor graph
    sc.tl.umap(adata)

# Visualize the UMAP embedding, with cells colored by their manual annotation.
# This plot provides a spatial view of the identified cell populations.
sc.pl.umap(
    adata,
    color=""manual_annotation"",
    title=""Manual Cell Type Annotation"",
    legend_loc=""on data""
)

#--------------------------------
# Data Output
#--------------------------------

# Save the updated AnnData object, which now includes the manual cell type annotations.
# This file is ready for downstream analyses focused on specific cell populations.
adata.write(""s4d8_manual_annotation.h5ad"")
",https://www.sc-best-practices.org/cellular_structure/annotation.html,F
18,scRNA-seq,Annotation,"The primary objective was to process single-cell RNA-seq data and annotate cell types. This was accomplished using a workflow integrating preprocessing, graph-based clustering, and marker gene identification, implemented with the Seurat (v4.0) R package. Starting with raw count matrices from 10X Genomics, the analysis involved quality control filtering (retaining cells with >200 genes and genes in >3 cells), normalization (log-normalization with 10k scale factor), and dimensionality reduction via PCA. Clustering was performed on the top 10 principal components using a k-nearest neighbor graph and resolution 0.5. Cell type markers were identified by differential expression testing with thresholds of ???25% min.pct and log2 fold change >0.25. The results were presented in UMAP plots to illustrate cluster identities and a heatmap to display top marker genes per cluster. Manual annotation based on canonical markers (e.g., CD14+ Monocytes, Naive CD4 T) validated cluster identities, while the heatmap confirmed robust expression patterns of key biomarkers like CD3D and CD79A.","### Methods

#### Data Preprocessing and Quality Control  
Single-cell RNA-seq data were processed using the Seurat package (v4.0) in R. Raw count matrices were imported from 10X Genomics output files using the `Read10X` function. A Seurat object was created with initial filtering criteria to retain cells expressing at least 200 genes and genes detected in at least 3 cells. To assess data quality, the percentage of mitochondrial gene expression was calculated for each cell using the `PercentageFeatureSet` function, identifying genes with the ""MT-"" prefix.  

Normalization was performed using the `NormalizeData` function with the ""LogNormalize"" method and a scale factor of 10,000 to account for differences in library size. Highly variable genes were identified using the `FindVariableFeatures` function with the ""vst"" selection method, retaining the top 2,000 genes. The data were scaled using the `ScaleData` function to ensure equal contribution of genes in downstream analyses.  

#### Dimensionality Reduction and Clustering  
Principal component analysis (PCA) was performed on the highly variable genes using the `RunPCA` function. The top 10 principal components were used to construct a k-nearest neighbor (KNN) graph and perform clustering with the `FindNeighbors` and `FindClusters` functions, respectively, using a resolution parameter of 0.5. Uniform Manifold Approximation and Projection (UMAP) was applied to the top 10 principal components using the `RunUMAP` function to generate a 2D embedding for visualization.  

#### Identification of Cluster Biomarkers  
Differentially expressed genes (DEGs) for each cluster were identified using the `FindAllMarkers` function. Only positive markers (genes upregulated in the cluster) were retained, with thresholds set at a minimum percentage of cells expressing the gene (min.pct = 0.25) and a log2 fold change threshold of 0.25.  

#### Cell Type Annotation  
Cell type identities were manually assigned to clusters based on canonical marker genes identified in the DEG analysis and literature references. Cluster labels were updated using the `RenameIdents` function, assigning identities such as ""Naive CD4 T,"" ""CD14+ Monocytes,"" ""Memory CD4 T,"" ""B cell,"" ""CD8 T,"" ""NK cell,"" ""Dendritic cell,"" and ""Platelet.""  

#### Visualization  
UMAP plots were generated to visualize cluster identities before and after cell type annotation using the `DimPlot` function. A heatmap of the top two marker genes per cluster, ranked by average log2 fold change, was created using the `DoHeatmap` function.  

#### Data Output  
The fully processed and annotated Seurat object was saved as an RDS file for downstream analysis and reproducibility.","Seurat, dplyr, ggplot2, patchwork",R,"#--------------------------------
# Package Load
#--------------------------------

# Load required libraries for single-cell analysis, data manipulation, and plotting
library(Seurat)      # Core package for single-cell RNA-seq analysis
library(dplyr)       # For data manipulation, especially for handling marker gene tables
library(ggplot2)     # For creating custom, publication-quality plots
library(patchwork)   # For easily combining multiple ggplot2 plots

#--------------------------------
# Data Input
#--------------------------------

# Specify the directory containing the 10X Genomics count matrices.
# NOTE: You must replace this with the actual path to your data.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""

# Read the 10X Genomics data into a raw count matrix.
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object from the raw count matrix with basic initial filtering.
seurat_obj <- CreateSeuratObject(
  counts = raw_data,
  project = ""ClusterBiomarkers"",
  min.cells = 3,
  min.features = 200
)

#--------------------------------
# Preprocessing and QC
#--------------------------------

# Calculate the percentage of mitochondrial genes for each cell as a QC metric.
seurat_obj[[""percent.mt""]] <- PercentageFeatureSet(seurat_obj, pattern = ""^MT-"")

# Normalize the data to account for differences in library size.
seurat_obj <- NormalizeData(seurat_obj, normalization.method = ""LogNormalize"", scale.factor = 10000)

# Identify highly variable features (genes) for downstream analysis.
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = ""vst"", nfeatures = 2000)

# Scale the data, a standard step before running PCA.
all_genes <- rownames(seurat_obj)
seurat_obj <- ScaleData(seurat_obj, features = all_genes)

#--------------------------------
# Major Analysis Tasks
#--------------------------------

# --- Dimensionality Reduction & Clustering ---
# Run PCA on the highly variable features.
seurat_obj <- RunPCA(seurat_obj, features = VariableFeatures(seurat_obj))

# Build a K-nearest neighbor (KNN) graph and perform clustering.
seurat_obj <- FindNeighbors(seurat_obj, dims = 1:10)
seurat_obj <- FindClusters(seurat_obj, resolution = 0.5)

# Run UMAP to generate a 2D embedding for visualization.
seurat_obj <- RunUMAP(seurat_obj, dims = 1:10)


# --- Finding Cluster Biomarkers ---
# Find differentially expressed features (cluster biomarkers) for every cluster compared to all remaining cells.
# `only.pos = TRUE` ensures we only get positive markers (genes upregulated in the cluster).
cluster_markers <- FindAllMarkers(seurat_obj, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)


# --- Cell Type Annotation ---
# Manually define new cell type names based on canonical markers found in the literature
# and observed in the `cluster_markers` table.
# NOTE: The order and names must be adjusted based on your specific dataset and clustering results.
new.cluster.ids <- c(""Naive CD4 T"", ""CD14+ Monocytes"", ""Memory CD4 T"", ""B cell"",
                     ""CD8 T"", ""NK cell"", ""Dendritic cell"", ""Platelet"")

# Assign the new names to the cluster levels in the Seurat object.
names(new.cluster.ids) <- levels(seurat_obj)
seurat_obj <- RenameIdents(seurat_obj, new.cluster.ids)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the initial UMAP clusters before annotation.
DimPlot(seurat_obj, reduction = ""umap"", label = TRUE, pt.size = 0.8) +
  ggtitle(""UMAP Plot: Clusters before Cell Type Assignment"")

# --- Biomarker Visualization ---
# Extract the top markers for each cluster to visualize on a heatmap.
# Here, we group by cluster and select the top 2 genes based on log2 fold change.
top_markers <- cluster_markers %>%
               group_by(cluster) %>%
               slice_max(order_by = avg_log2FC, n = 2)

# Create a heatmap of the top marker genes.
DoHeatmap(seurat_obj, features = top_markers$gene) + NoLegend()


# --- Final Annotation Visualization ---
# Visualize the UMAP with the final, manually assigned cell type identities.
DimPlot(seurat_obj, reduction = ""umap"", label = TRUE, pt.size = 0.8) +
  ggtitle(""UMAP Plot: Cell Type Identities"")


#--------------------------------
# Data Output
#--------------------------------

# Save the fully processed and annotated Seurat object.
saveRDS(seurat_obj, file = ""Annotated_SeuratObject.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection,F
19,scRNA-seq,Annotation,"The primary objective was to classify immune cell subtypes in a single-cell RNA-seq dataset. This was accomplished using a pre-trained machine learning model with majority voting consensus, implemented with the CellTypist package. Starting with a preprocessed AnnData object containing 2,000 cells, the analysis involved automatic annotation via the ""Immune_All_Low.pkl"" model, followed by consensus-based label aggregation. Final cell-type predictions were determined using majority voting, with confidence scores reflecting prediction reliability.  The results were presented in a UMAP embedding colored by predicted cell types to illustrate subtype distribution and clustering patterns. These findings were further supported by overlaying confidence scores on the UMAP plot, which highlighted prediction certainty, and by saving the annotated AnnData object for integrative downstream analysis.  ","### Methods

#### Data Preprocessing and Input
A preprocessed single-cell RNA-seq dataset was loaded as an AnnData object. The dataset, containing 2,000 cells, was either accessed locally or retrieved from a backup URL if the local file was unavailable.

#### Automatic Cell-Type Annotation
Cell-type annotation was performed using the CellTypist pipeline, which leverages pre-trained machine learning models for cell-type classification. The latest CellTypist models were downloaded to ensure access to the most up-to-date annotations. A specific pre-trained model, ""Immune_All_Low.pkl,"" designed for fine-grained annotation of immune cells, was loaded for analysis. Automatic annotation was executed using the `celltypist.annotate` function with the `majority_voting` parameter set to `True`, enabling consensus-based prediction for each cell. The resulting predicted cell-type labels and their associated confidence scores were stored in the AnnData object.

#### Dimensionality Reduction and Visualization
To visualize the annotation results, a neighborhood graph was constructed using 40 principal components (PCs) and 15 nearest neighbors. Uniform Manifold Approximation and Projection (UMAP) was applied to generate a 2D embedding of the data. The UMAP plot was used to display cells colored by their predicted cell-type labels and the corresponding confidence scores.

#### Data Output
The annotated dataset, including the predicted cell-type labels and confidence scores, was saved as an AnnData object for downstream analysis.","scanpy, celltypist, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis, automatic annotation, and plotting
import scanpy as sc
import celltypist
from celltypist import models
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
# Verbosity 2 provides more detailed logging, which is useful for tracking progress.
sc.settings.verbosity = 2
sc.settings.set_figure_params(dpi=80, facecolor='white', frameon=False)

#--------------------------------
# Data Input
#--------------------------------

# Load a preprocessed single-cell dataset (AnnData object).
# A backup URL is provided in case the local file is not found.
adata = sc.read(
    ""demo_2000_cells.h5ad"",
    backup_url=""https://celltypist.cog.sanger.ac.uk/Notebook_demo_data/demo_2000_cells.h5ad""
)
print(""Data shape:"", adata.shape)

#--------------------------------
# Major Analysis Task: Automatic Cell-Type Annotation
#--------------------------------

# --- Model Preparation ---
# Download the latest CellTypist models to ensure access to the most recent annotations.
# `force_update=True` will overwrite existing models if a newer version is available.
print(""Downloading CellTypist models..."")
models.download_models(force_update=True)

# Load a specific pre-trained CellTypist model.
# ""Immune_All_Low.pkl"" is designed for fine-grained annotation of immune cells.
model = models.Model.load(model=""Immune_All_Low.pkl"")

# --- Annotation ---
# Run CellTypist's automatic annotation on the dataset.
# `majority_voting=True` assigns a final label to each cell based on a consensus
# prediction from the underlying classification models.
print(""Starting automatic annotation..."")
predictions = celltypist.annotate(adata, model=model, majority_voting=True)

# Store the prediction results in the AnnData object for easy access.
adata.obs[""celltypist_cell_label""] = predictions.predicted_labels
adata.obs[""celltypist_confidence""] = predictions.confidence

# --- UMAP for Visualization ---
# Compute the neighborhood graph and UMAP embedding. This is necessary for
# visualizing the annotation results in a 2D space.
sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)
sc.tl.umap(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the UMAP embedding, creating two plots side-by-side:
# 1. Cells colored by their predicted cell type label from CellTypist.
# 2. Cells colored by the confidence score of the prediction.
sc.pl.umap(
    adata,
    color=[""celltypist_cell_label"", ""celltypist_confidence""],
    wspace=0.4,
    title=[""CellTypist: Predicted Labels"", ""Annotation Confidence""]
)


#--------------------------------
# Data Output
#--------------------------------

# Save the updated AnnData object, which now includes the automatic cell type
# annotations and confidence scores from CellTypist.
adata.write(""celltypist_annotated.h5ad"")
",https://www.sc-best-practices.org/cellular_structure/annotation.html,F
20,scRNA-seq,Annotation,"The primary objective was to annotate cell types in follicular lymphoma scRNA-seq data using a marker-guided approach. This was accomplished using a probabilistic model for cell type assignment based on prior marker gene signatures, implemented with the CellAssign module in the scvi-tools Python package. Starting with an AnnData object and a predefined marker gene matrix, the analysis involved subsetting genes to marker sets, normalizing per-cell library sizes to compute size factors, and training the CellAssign model for 400 epochs. The final cell type assignments were determined by selecting the cell type with the highest predicted probability from the model's soft assignment matrix. The results were presented in a validation ELBO convergence plot to confirm successful model training and a heatmap of cell type probabilities to assess assignment confidence. These findings were further supported by a UMAP projection of annotated cells, which visualized the spatial distribution of inferred cell types and validated biologically coherent clustering.  ","### Methods

#### Data Acquisition and Preparation
Single-cell RNA sequencing (scRNA-seq) data from follicular lymphoma samples were obtained from a publicly available dataset, which was downloaded as an AnnData object (`sce_follicular.h5ad`). A corresponding marker gene matrix (`FL_celltype.csv`), where rows represent genes and columns represent cell types, was also retrieved. Both files were stored in a temporary directory for processing. The dataset was loaded into an AnnData object, and gene and cell identifiers were made unique to ensure consistency.

#### Preprocessing for CellAssign
The dataset was subset to include only genes present in the marker gene matrix, as CellAssign relies on these genes for cell type annotation. Per-cell library sizes were calculated, and size factors were derived by normalizing library sizes to their mean. The AnnData object was then prepared for CellAssign analysis using the `setup_anndata` function, which registers the size factors and other necessary metadata for model training.

#### Cell Type Annotation with CellAssign
The CellAssign model was initialized using the subsetted AnnData object and the marker gene matrix. The model was trained for a maximum of 400 epochs, with training progress monitored using the validation Evidence Lower Bound (ELBO). Upon convergence, soft cell type assignment probabilities were predicted for each cell, generating a probability matrix where rows correspond to cells and columns to cell types. The most likely cell type for each cell was determined by selecting the cell type with the highest probability, and these annotations were added to the original AnnData object.

#### Visualization and Validation
Model convergence was assessed by plotting the validation ELBO over training epochs. A heatmap of the predicted cell type probabilities was generated to visualize the confidence of assignments across cell types. For final visualization, Uniform Manifold Approximation and Projection (UMAP) was performed on the annotated dataset, and the resulting embeddings were plotted with cell type annotations overlaid.

#### Data Output
The annotated AnnData object, including CellAssign predictions, was saved to disk (`cellassign_annotated.h5ad`). The temporary directory used for data storage was subsequently cleaned up to free system resources.

### Software and Tools
The analysis was conducted using Python (v3.x) with the following key packages: Scanpy (v1.x) for single-cell data handling and visualization, scvi-tools (v0.x) for CellAssign model implementation, and Seaborn (v0.x) for heatmap generation. PyTorch (v2.x) was used as the backend for model training, with high-precision matrix multiplication enabled for improved computational performance.","os, tempfile, matplotlib, pandas, scanpy, scvi, seaborn, torch",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for system operations, data handling, analysis, and plotting
import os
import tempfile
import matplotlib.pyplot as plt
import pandas as pd
import scanpy as sc
import scvi
import seaborn as sns
import torch
from scvi.external import CellAssign

#--------------------------------
# Script Configuration
#--------------------------------

# Set global parameters for plotting and computation
sc.set_figure_params(figsize=(6, 6), frameon=False)
sns.set_theme()
# Set precision for matrix multiplication in PyTorch for performance.
torch.set_float32_matmul_precision(""high"")

#--------------------------------
# Data Input & Preparation
#--------------------------------

# Create a temporary directory to store downloaded data
save_dir = tempfile.TemporaryDirectory()
print(f""Data will be downloaded to temporary directory: {save_dir.name}"")

# Define file paths for the dataset and the marker gene matrix
adata_path = os.path.join(save_dir.name, ""sce_follicular.h5ad"")
marker_path = os.path.join(save_dir.name, ""FL_celltype.csv"")

# Download the follicular lymphoma dataset and its corresponding marker gene file
# using wget. These files are stored in the temporary directory.
print(""Downloading dataset and marker file..."")
os.system(f""wget -q https://ndownloader.figshare.com/files/27458798 -O {adata_path}"")
os.system(f""wget -q https://ndownloader.figshare.com/files/27458831 -O {marker_path}"")

# Load the single-cell dataset as an AnnData object
adata = sc.read(adata_path)
adata.var_names_make_unique()
adata.obs_names_make_unique()

# Load the marker gene matrix. Rows should be genes and columns should be cell types.
marker_gene_mat = pd.read_csv(marker_path, index_col=0)

#--------------------------------
# Preprocessing for CellAssign
#--------------------------------

# Subset the dataset to include only the genes present in the marker matrix.
# CellAssign only uses these genes for its predictions.
adata_subset = adata[:, marker_gene_mat.index].copy()

# Calculate per-cell library sizes and create a size factor.
# This is used by the model to account for differences in sequencing depth.
library_sizes = adata_subset.X.sum(1)
adata_subset.obs[""size_factor""] = library_sizes / library_sizes.mean()

# Set up the AnnData object for the CellAssign model.
# This function registers the necessary information for the model.
scvi.external.CellAssign.setup_anndata(adata_subset, size_factor_key=""size_factor"")


#--------------------------------
# Major Analysis Task: Annotation with CellAssign
#--------------------------------

# Initialize the CellAssign model with the subsetted data and the marker gene matrix.
model = CellAssign(adata_subset, marker_gene_mat)

# Train the model. The number of epochs can be adjusted based on convergence.
print(""Training CellAssign model..."")
model.train(max_epochs=400)

# Predict the soft cell type assignment probabilities for each cell.
# This returns a DataFrame where rows are cells and columns are cell types.
predictions = model.predict()

# Assign the most likely cell type to each cell in the original AnnData object.
# The `.idxmax(axis=1)` function finds the cell type with the highest probability for each cell.
adata.obs['cellassign_prediction'] = predictions.idxmax(axis=1)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- Model Convergence Plot ---
# Plot the validation ELBO (Evidence Lower Bound) to check for model convergence.
# A stable or plateauing curve indicates that the model has trained sufficiently.
model.history[""elbo_validation""].plot()
plt.xlabel(""Epoch"")
plt.ylabel(""Validation ELBO"")
plt.title(""CellAssign Convergence Plot"")
plt.show()

# --- Prediction Heatmap ---
# Visualize the raw probability matrix as a heatmap.
# This shows the confidence of assignment for each cell to each possible cell type.
plt.figure(figsize=(10, 10))
sns.heatmap(predictions, cmap=""viridis"")
plt.title(""CellAssign Prediction Probabilities"")
plt.show()

# --- UMAP Visualization of Final Annotations ---
# Run standard dimensionality reduction to visualize the final annotations.
print(""Computing UMAP for visualization..."")
sc.pp.neighbors(adata)
sc.tl.umap(adata)
sc.pl.umap(adata, color='cellassign_prediction', title='Final CellAssign Annotations', legend_loc='on data')


#--------------------------------
# Data Output
#--------------------------------

# Save the final, annotated AnnData object.
adata.write(""cellassign_annotated.h5ad"")

# Clean up the temporary directory
save_dir.cleanup()
",https://docs.scvi-tools.org/en/stable/tutorials/notebooks/scrna/cellassign_tutorial.html,F
21,scRNA-seq,Integration,"The primary objective was to correct batch effects in single-cell RNA-seq data while preserving biological variability. This was accomplished using a batch-balanced k-nearest neighbors (BBKNN) strategy, implemented with the BBKNN Python package (version 1.5.1) within the Scanpy framework. Starting with a raw gene count matrix stored in an AnnData object, the analysis involved selecting highly variable genes (HVGs) in a batch-aware manner, followed by total count normalization, log-transformation, and scaling to unit variance. Dimensionality reduction was performed using principal component analysis (PCA) with 50 retained components. The BBKNN algorithm corrected batch effects by constructing balanced nearest-neighbor graphs across batches. Successful integration was confirmed by observing interleaved cells from multiple batches in downstream visualization. The results were presented in a UMAP projection colored by batch identifier to illustrate the reduction of technical variability. Effective integration was evidenced by the absence of batch-specific clusters. The batch-corrected AnnData object was saved for subsequent clustering and annotation, ensuring reproducibility of the integrated dataset.  ","### Methods

#### Data Preprocessing and Feature Selection

Single-cell RNA sequencing data were processed using the Scanpy toolkit (version 1.9.0). The dataset was loaded as an AnnData object, containing raw gene expression counts and metadata, including a batch identifier for each cell. Highly variable genes (HVGs) were identified using a batch-aware approach (`sc.pp.highly_variable_genes`) with the ""cell_ranger"" flavor, selecting the top 2,000 genes per batch to account for batch-specific variability. The dataset was subset to retain only these HVGs for downstream analysis.

#### Normalization and Scaling

To correct for differences in library size, the data were normalized using the `sc.pp.normalize_total` function with a target sum of 10,000 counts per cell. Normalized counts were log-transformed (`sc.pp.log1p`) to stabilize variance, and gene expression values were scaled to zero mean and unit variance (`sc.pp.scale`) to ensure comparability across genes.

#### Dimensionality Reduction

Principal Component Analysis (PCA) was performed (`sc.tl.pca`) to reduce the dimensionality of the dataset, retaining the top 50 principal components (PCs) for downstream analysis. The PCA was computed using the ARPACK solver to optimize computational efficiency.

#### Batch Integration with BBKNN

Batch effects were corrected using Batch-Balanced K-Nearest Neighbors (BBKNN; version 1.5.1). The BBKNN algorithm (`bbknn.bbknn`) was applied to the PCA space, identifying three nearest neighbors within each batch before constructing the final integrated neighborhood graph. This approach ensures that batch effects are minimized while preserving biological variability.

#### Visualization

A Uniform Manifold Approximation and Projection (UMAP) embedding was computed (`sc.tl.umap`) on the BBKNN-corrected neighborhood graph to visualize the integrated dataset in two dimensions. The UMAP plot was generated to assess the effectiveness of batch integration, with cells colored by their batch identifier. Successful integration was indicated by the mixing of cells from different batches rather than clustering by batch.

#### Data Output

The integrated AnnData object, containing batch-corrected gene expression data and metadata, was saved to a file (`bbknn_integrated_data.h5ad`) for downstream analyses, including clustering and cell type annotation.","numpy, scanpy, bbknn, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis, batch correction, and plotting
import numpy as np
import scanpy as sc
import bbknn
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
sc.settings.verbosity = 3  # Set to a higher level for more detailed logging
sc.settings.set_figure_params(dpi=80, facecolor='white')

#--------------------------------
# Data Input
#--------------------------------

# Load your AnnData object from a file.
# NOTE: Replace ""your_data.h5ad"" with the path to your data.
# This dataset should contain a 'batch' column in adata.obs identifying the batch for each cell.
adata = sc.read(""your_data.h5ad"")

#--------------------------------
# Preprocessing & Feature Selection
#--------------------------------

# --- Batch-Aware Feature Selection ---
# Identify highly variable genes (HVGs) using a batch-aware method.
# `batch_key=""batch""` ensures that HVGs are selected per batch, which can
# improve the selection process in the presence of strong batch effects.
sc.pp.highly_variable_genes(
    adata,
    n_top_genes=2000,
    flavor=""cell_ranger"",
    batch_key=""batch""
)
# Subset the data to contain only the selected highly variable genes.
adata = adata[:, adata.var.highly_variable].copy()

# --- Normalization and Scaling ---
# Standard preprocessing steps: normalize, log-transform, and scale the data.
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)
sc.pp.scale(adata)

# --- PCA ---
# Perform Principal Component Analysis (PCA) for dimensionality reduction.
# The resulting PCs will be used as input for BBKNN.
sc.tl.pca(adata, n_comps=50, svd_solver='arpack')


#--------------------------------
# Major Analysis Task: Batch Integration with BBKNN
#--------------------------------

# Run Batch-Balanced K-Nearest Neighbors (BBKNN) to correct for batch effects.
# BBKNN identifies nearest neighbors within each batch first before building the
# final, integrated neighborhood graph.
# `neighbors_within_batch` controls how many neighbors are identified within each batch.
bbknn.bbknn(adata, batch_key='batch', neighbors_within_batch=3)

# --- UMAP for Visualization ---
# Compute the UMAP embedding. Importantly, this is calculated on the BBKNN-corrected
# neighborhood graph, not the original PCA space.
sc.tl.umap(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Create a UMAP plot colored by the 'batch' variable.
# Effective integration should result in cells from different batches mixing together,
# rather than clustering separately by batch.
sc.pl.umap(adata, color=['batch'], title=""UMAP after BBKNN Integration"")


#--------------------------------
# Data Output
#--------------------------------

# Save the integrated AnnData object to a file.
# This object can be used for downstream analyses like clustering and cell type annotation.
adata.write(""bbknn_integrated_data.h5ad"")
",https://www.sc-best-practices.org/cellular_structure/integration.html,F
22,scRNA-seq,Integration,"The primary objective was to integrate a query single-cell RNA-seq dataset with a reference dataset and transfer cell type annotations. This was accomplished using a reference-based integration strategy, implemented with the `sc.tl.ingest` function in the `scanpy` Python package. Starting with shared genes across the reference (PBMC3k) and query (PBMC68k) datasets, the analysis involved dimensionality reduction via PCA (50 components) on the reference, followed by k-nearest neighbor graph construction (15 neighbors) and Louvain clustering. The query dataset was projected onto the reference's UMAP embedding, enabling label transfer. Integration quality was assessed by aligning cell states across datasets using retained parameters (50 PCs, consistent UMAP settings). The results were presented in a combined UMAP plot (reference and query) to illustrate batch alignment and label consistency. These findings were supported by separate reference and query UMAPs colored by Louvain clusters, confirming successful annotation transfer. Final datasets were saved in `.h5ad` format, preserving transferred labels for downstream use.  ","### Methods

#### Data Input and Preprocessing  
The analysis utilized two single-cell RNA-seq datasets: a pre-processed reference dataset (PBMC3k) and a query dataset (PBMC68k reduced). Both datasets were loaded using the `scanpy` package. To ensure compatibility for downstream integration, the intersection of genes present in both datasets was identified, and only these shared genes were retained for further analysis. This step ensured accurate mapping of annotations between the datasets.

#### Reference Dataset Processing  
The reference dataset was processed to generate the necessary components for integration. Principal Component Analysis (PCA) was performed using 50 principal components (`n_comps=50`) to reduce dimensionality. A k-nearest neighbors graph was constructed using 15 neighbors (`n_neighbors=15`) and the first 50 principal components. Uniform Manifold Approximation and Projection (UMAP) was applied to generate a low-dimensional embedding of the reference dataset. Louvain clustering was performed on the reference dataset to define cell clusters, which served as the basis for annotation transfer.

#### Integration of Query Data via Ingest  
The query dataset was integrated onto the reference dataset using the `sc.tl.ingest` function in `scanpy`. This method projected the UMAP embedding and transferred the Louvain cluster labels from the reference dataset to the query dataset. To maintain consistent visualization, the color scheme for the clusters in the reference dataset was applied to the query dataset.

#### Visualization  
Three visualizations were generated to assess the integration:  
1. **Reference UMAP**: A UMAP plot of the reference dataset, colored by Louvain clusters, was generated to visualize the original cell type annotations.  
2. **Query UMAP**: A UMAP plot of the query dataset, with coordinates projected from the reference and colored by the transferred Louvain labels, was created to evaluate the integration.  
3. **Combined UMAP**: The reference and query datasets were concatenated, and a combined UMAP plot was generated to visualize both datasets together. This plot was colored by batch (reference vs. query) and by the transferred Louvain labels to assess the quality of the integration.

#### Data Output  
The annotated query dataset and the combined dataset were saved in `.h5ad` format for further analysis and inspection.","anndata, scanpy, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and plotting
import anndata
import scanpy as sc
import matplotlib.pyplot as plt
import numpy as np

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
sc.settings.verbosity = 2  # Set for detailed logging
sc.settings.set_figure_params(dpi=80, facecolor='white', figsize=(5, 5))

#--------------------------------
# Data Input
#--------------------------------

# Load a pre-processed reference dataset (e.g., PBMC3k)
# This dataset should ideally already have annotations and a UMAP embedding.
print(""Loading reference dataset..."")
adata_ref = sc.datasets.pbmc3k_processed()

# Load the query dataset that you want to annotate.
print(""Loading query dataset..."")
adata = sc.datasets.pbmc68k_reduced()

# Ensure both datasets share the same gene set by taking the intersection of their genes.
# This is a critical step for mapping annotations accurately.
var_names = adata_ref.var_names.intersection(adata.var_names)
adata_ref = adata_ref[:, var_names].copy()
adata = adata[:, var_names].copy()
print(f""Using {len(var_names)} common genes for integration."")

#--------------------------------
# Preprocessing & Embedding on Reference Data
#--------------------------------

# The following steps ensure the reference data has the necessary components (PCA, neighbors, UMAP).
# These might already be present in a pre-processed object but are run here for completeness.
print(""Processing reference dataset..."")
sc.pp.pca(adata_ref, n_comps=50)
sc.pp.neighbors(adata_ref, n_neighbors=15, n_pcs=50)
sc.tl.umap(adata_ref)
sc.tl.louvain(adata_ref) # Example clustering on the reference

#--------------------------------
# Major Analysis Task: Integrate Query Data via Ingest
#--------------------------------

# Use sc.tl.ingest to map annotations and embeddings from the reference to the query data.
# 'louvain' labels from the reference will be transferred to the query.
# The UMAP embedding will also be projected onto the query data.
print(""Integrating query data onto reference using sc.tl.ingest..."")
sc.tl.ingest(adata, adata_ref, obs='louvain', embedding_method='umap')

# For consistent visualization, copy the color scheme for the clusters from the reference.
adata.uns['louvain_colors'] = adata_ref.uns['louvain_colors']

#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- Reference Visualization ---
# Plot the UMAP of the reference data to see the original clusters.
sc.pl.umap(adata_ref, color='louvain', title='Reference UMAP with Louvain Clusters')

# --- Query Visualization ---
# Plot the UMAP of the query data. The coordinates are projected from the reference,
# and the colors represent the newly ingested labels.
sc.pl.umap(adata, color='louvain', title='Query UMAP with Ingested Annotations', size=30)

# --- Combined Visualization (Optional) ---
# Concatenate the reference and query objects to visualize them together.
# This is useful for assessing the quality of the integration.
print(""Creating a combined UMAP for visualization..."")
# Note: The `ingest` function stores the projected UMAP in `adata.obsm['X_umap_ingest']`.
# We need to rename it to `X_umap` in the query object before concatenating.
adata.obsm['X_umap'] = adata.obsm.pop('X_umap_ingest')
adata_concat = anndata.concat(
    [adata_ref, adata],
    label='batch',
    keys=['reference', 'query'],
    join='outer' # Keep all cells from both objects
)

# Plot the combined data, coloring by batch and by the transferred labels.
sc.pl.umap(
    adata_concat,
    color=['batch', 'louvain'],
    title='Combined UMAP: Reference and Query',
    wspace=0.5,
    size=20
)

#--------------------------------
# Data Output
#--------------------------------

# Save the annotated query dataset to a file.
adata.write(""ingest_annotated_query_data.h5ad"")

# Save the combined dataset for further inspection.
adata_concat.write(""ingest_combined_data.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/integrating-data-using-ingest.html,F
23,scRNA-seq,Integration,"The primary objective was to transfer cell type annotations from a reference to a query single-cell RNA sequencing dataset. This was accomplished using a reference-projection integration strategy, implemented with the Scanpy package in Python. Starting with pre-processed PBMC3k (reference) and PBMC68k (query) datasets, the analysis involved identifying shared genes followed by reference PCA (50 PCs) and k-nearest neighbors graph construction (15 neighbors). Clusters from Louvain partitioning of the reference were transferred to the query using the *ingest* method to project query cells onto the reference UMAP. The final annotations were determined by cluster similarity alignment based on shared gene space. Integration quality was evaluated using UMAP projections illustrating reference-to-query batch mixing (via `anndata.concat()` outputs) and label concordance. Transferred annotations were validated by cluster-level colocalization in combined embeddings and color consistency between reference labels and query predictions (saved in H5AD format). Quantitative validation was implicit in the retained gene overlap and computational stability of the projection method.  ","### Methods

#### Data Acquisition and Preprocessing  
Single-cell RNA sequencing datasets were processed using the *Scanpy* package (v1.9.0) in Python. A pre-processed reference dataset (PBMC3k) and a query dataset (PBMC68k) were loaded using the `sc.datasets.pbmc3k_processed()` and `sc.datasets.pbmc68k_reduced()` functions, respectively. To ensure compatibility between the datasets, the intersection of genes present in both datasets was identified, and only these shared genes were retained for downstream analysis. This step was critical to enable accurate annotation transfer and integration.

#### Reference Dataset Processing  
The reference dataset was processed to generate the necessary components for downstream integration. Principal component analysis (PCA) was performed using the `sc.pp.pca()` function with 50 principal components (PCs). A k-nearest neighbors graph was constructed using the `sc.pp.neighbors()` function with 15 neighbors and 50 PCs. Uniform Manifold Approximation and Projection (UMAP) was applied for dimensionality reduction using the `sc.tl.umap()` function. Clustering was performed on the reference dataset using the Louvain algorithm (`sc.tl.louvain()`) to define cell type annotations.

#### Query Dataset Integration  
The query dataset was integrated into the reference dataset using the *Scanpy* ingest function (`sc.tl.ingest()`). This method projected the query data onto the reference UMAP embedding and transferred the Louvain cluster labels from the reference to the query. The color scheme for the clusters was copied from the reference to the query dataset for consistent visualization.

#### Visualization  
To assess the quality of the integration, UMAP plots were generated for both the reference and query datasets. The reference UMAP was visualized with Louvain cluster labels, while the query UMAP was plotted with the transferred annotations. For a combined visualization, the reference and query datasets were concatenated using the `anndata.concat()` function, and UMAP coordinates were combined to plot the integrated data. The combined UMAP was colored by batch (reference vs. query) and by the transferred Louvain labels.

#### Data Output  
The annotated query dataset, including the transferred annotations and UMAP embeddings, was saved to an H5AD file (`ingest_annotated_query_data.h5ad`) for further analysis.

This workflow enabled the transfer of cell type annotations from a well-annotated reference dataset to a query dataset, facilitating the interpretation of single-cell data in the context of known cell types.","os, tempfile, scanpy, scvi, seabor, torch",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and plotting
import anndata
import scanpy as sc
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
sc.settings.verbosity = 2  # Set for detailed logging
sc.settings.set_figure_params(dpi=80, facecolor='white', figsize=(4, 4))

#--------------------------------
# Data Input
#--------------------------------

# Load a pre-processed reference dataset (e.g., PBMC3k)
# This dataset should ideally already have annotations and a UMAP embedding.
print(""Loading reference dataset..."")
adata_ref = sc.datasets.pbmc3k_processed()

# Load the query dataset that you want to annotate.
print(""Loading query dataset..."")
adata = sc.datasets.pbmc68k_reduced()

# Ensure both datasets share the same gene set by taking the intersection of their genes.
# This is a critical step for mapping annotations accurately.
var_names = adata_ref.var_names.intersection(adata.var_names)
adata_ref = adata_ref[:, var_names].copy()
adata = adata[:, var_names].copy()
print(f""Using {len(var_names)} common genes for integration."")

#--------------------------------
# Preprocessing & Embedding on Reference Data
#--------------------------------

# The following steps ensure the reference data has the necessary components (PCA, neighbors, UMAP).
# These might already be present in a pre-processed object.
print(""Processing reference dataset..."")
sc.pp.pca(adata_ref, n_comps=50)
sc.pp.neighbors(adata_ref, n_neighbors=15, n_pcs=50)
sc.tl.umap(adata_ref)
sc.tl.louvain(adata_ref) # Example clustering on the reference

#--------------------------------
# Major Analysis Task: Integrate Query Data via Ingest
#--------------------------------

# Use sc.tl.ingest to map annotations and embeddings from the reference to the query data.
# 'louvain' labels from the reference will be transferred to the query.
# The UMAP embedding will also be projected onto the query data.
print(""Integrating query data onto reference using sc.tl.ingest..."")
sc.tl.ingest(adata, adata_ref, obs='louvain')

# For consistent visualization, copy the color scheme for the clusters from the reference.
adata.uns['louvain_colors'] = adata_ref.uns['louvain_colors']

#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- Reference Visualization ---
# Plot the UMAP of the reference data to see the original clusters.
sc.pl.umap(adata_ref, color='louvain', title='Reference UMAP with Louvain Clusters')

# --- Query Visualization ---
# Plot the UMAP of the query data. The coordinates are projected from the reference,
# and the colors represent the newly ingested labels.
sc.pl.umap(adata, color='louvain', title='Query UMAP with Ingested Annotations', size=30)

# --- Combined Visualization (Optional) ---
# Concatenate the reference and query objects to visualize them together.
# This is useful for assessing the quality of the integration.
print(""Creating a combined UMAP for visualization..."")
adata_concat = anndata.concat(
    [adata_ref, adata],
    label='batch',
    keys=['reference', 'query']
)
# The UMAP coordinates for the query part are from the ingest function.
# We re-compute the reference UMAP to ensure it's in the same object for plotting.
adata_concat.obsm['X_umap'] = np.concatenate(
    [adata_ref.obsm['X_umap'], adata.obsm['X_umap_ingest']]
)

# Plot the combined data, coloring by batch and by the transferred labels.
sc.pl.umap(
    adata_concat,
    color=['batch', 'louvain'],
    title='Combined UMAP: Reference and Query',
    wspace=0.5,
    size=20
)

#--------------------------------
# Data Output
#--------------------------------

# Save the annotated query dataset to a file.
adata.write(""ingest_annotated_query_data.h5ad"")
",https://docs.scvi-tools.org/en/stable/tutorials/notebooks/scrna/harmonization.html,F
24,scRNA-seq,Integration,"The primary objective was to integrate single-cell transcriptomic data across technical batches in a lung atlas dataset. This was accomplished using a deep generative model with a negative binomial likelihood distribution, implemented with the scVI framework in Python. Starting with a raw count matrix stored in an AnnData object, the analysis involved selecting 2,000 highly variable genes (HVGs) using the Seurat v3 method, followed by training an scVI model conditioned on batch information. The model architecture included two hidden layers and a 30-dimensional latent space optimized for batch correction. The latent representation was extracted after training to capture integrated cell states. The results were presented in a UMAP embedding to illustrate the effectiveness of batch integration through colocalization of cells across batches. These findings were validated by saving the batch-corrected latent space and nearest-neighbor graph, enabling reproducible downstream analysis. A clean separation of batches in the UMAP confirmed successful integration while preserving biological variation.  ","### Methods

#### Data Acquisition and Preprocessing  
The lung atlas dataset was downloaded from a publicly available repository (https://figshare.com/ndownloader/files/24539942) and loaded into an AnnData object using the `scanpy` library (v1.9.0). The raw dataset was stored in the `.raw` attribute of the AnnData object for reference during downstream analysis. Highly variable genes (HVGs) were identified using the Seurat v3 flavor of the `scanpy.pp.highly_variable_genes` function, with 2,000 top genes selected based on their variability across batches. The analysis was performed on the raw count data, and the dataset was subset to include only the selected HVGs.

#### Batch Integration with scVI  
Batch correction was performed using the single-cell Variational Inference (scVI) framework (v0.15.0). The AnnData object was registered with scVI using the `setup_anndata` function, specifying the raw count layer and the batch information as covariates. The scVI model was initialized with two hidden layers and a 30-dimensional latent space, assuming a negative binomial gene likelihood distribution to account for UMI-based count data. The model was trained to learn a batch-corrected latent representation of the data. After training, the latent representation was extracted and stored in the AnnData object.

#### Downstream Analysis  
A nearest-neighbor graph was computed on the batch-corrected latent representation using the `scanpy.pp.neighbors` function. Uniform Manifold Approximation and Projection (UMAP) was applied to the integrated neighbor graph to generate a two-dimensional embedding for visualization. The UMAP embedding was visualized using the `scanpy.pl.umap` function, with cells colored by their batch ID to assess the effectiveness of batch integration.

#### Data Output  
The integrated AnnData object, including the batch-corrected latent representation, nearest-neighbor graph, and UMAP embedding, was saved to a file (`scvi_integrated_data.h5ad`) for further analysis. Temporary files created during the analysis were removed to ensure reproducibility and efficient resource management.","os, tempfile, scanpy, scvi, seabor, torch",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for system operations, data handling, analysis, and plotting
import os
import tempfile
import scanpy as sc
import scvi
import seaborn as sns
import torch

#--------------------------------
# Script Configuration
#--------------------------------

# Set global parameters for plotting and computation
sc.set_figure_params(figsize=(6, 6), frameon=False)
sns.set_theme()
# Set precision for matrix multiplication in PyTorch for performance.
torch.set_float32_matmul_precision(""high"")

#--------------------------------
# Data Input & Preparation
#--------------------------------

# Create a temporary directory to store downloaded data
save_dir = tempfile.TemporaryDirectory()
print(f""Data will be downloaded to temporary directory: {save_dir.name}"")

# Define file path for the dataset
adata_path = os.path.join(save_dir.name, ""lung_atlas.h5ad"")

# Download and load the lung atlas dataset.
# The `backup_url` will automatically download the file if not found locally.
print(""Downloading and loading dataset..."")
adata = sc.read(adata_path, backup_url=""https://figshare.com/ndownloader/files/24539942"")
print(adata)

# Store the full, unprocessed dataset in the .raw attribute for reference.
adata.raw = adata

#--------------------------------
# Preprocessing & Feature Selection
#--------------------------------

# Identify highly variable genes (HVGs) using a batch-aware method.
# This approach finds genes that are variable across batches, which is robust
# to batch-specific effects. The `subset=True` argument modifies adata in place.
print(""Selecting highly variable genes..."")
sc.pp.highly_variable_genes(
    adata,
    flavor=""seurat_v3"",
    n_top_genes=2000,
    layer=""counts"",
    batch_key=""batch"",
    subset=True,
)

#--------------------------------
# Major Analysis Task: Batch Integration with scVI
#--------------------------------

# --- Model Setup and Training ---
# Register the AnnData object for scVI analysis. This function specifies
# the data layer, batch information, and other covariates for the model.
scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""batch"")

# Initialize the scVI model.
# `n_layers`: number of hidden layers in the neural network.
# `n_latent`: dimensionality of the latent space.
# `gene_likelihood`: ""nb"" (Negative Binomial) is recommended for UMI-based count data.
model = scvi.model.SCVI(adata, n_layers=2, n_latent=30, gene_likelihood=""nb"")

# Train the scVI model. This learns a batch-corrected latent representation of the data.
print(""Training scVI model..."")
model.train()

# --- Post-Integration Steps ---
# Retrieve the learned latent representation from the trained model.
SCVI_LATENT_KEY = ""X_scVI""
adata.obsm[SCVI_LATENT_KEY] = model.get_latent_representation()

# Compute the nearest-neighbor graph on the scVI latent space.
# This graph will be used for downstream clustering and visualization.
sc.pp.neighbors(adata, use_rep=SCVI_LATENT_KEY)

# Compute the UMAP embedding based on the integrated neighbor graph.
sc.tl.umap(adata)

#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the UMAP embedding, coloring cells by their batch ID.
# Effective integration should show cells from different batches mixing together,
# rather than forming separate, batch-specific clusters.
print(""Visualizing integrated data..."")
sc.pl.umap(adata, color=""batch"", title=""UMAP after scVI Integration"")

#--------------------------------
# Data Output
#--------------------------------

# Save the integrated AnnData object to a file.
print(""Saving integrated data object..."")
adata.write(""scvi_integrated_data.h5ad"")

# Clean up the temporary directory
save_dir.cleanup()
",https://docs.scvi-tools.org/en/stable/tutorials/notebooks/scrna/harmonization.html,F
25,scRNA-seq,Integration,"The primary objective was to integrate single-cell transcriptomic data across batches while preserving biological variation. This was accomplished using a semi-supervised variational inference strategy, implemented with the scANVI model in scVI-tools (Python). Starting with an AnnData object containing unprocessed raw counts, the analysis involved selecting 2,000 highly variable genes (HVGs) using a batch-aware `seurat_v3` method (via Scanpy) to mitigate technical noise. The scANVI model was then trained for 20 epochs with 100 samples per label, explicitly leveraging batch and cell type annotations (`batch_key` and `labels_key`) to refine the latent representation. Unlabeled cells were handled via the ""Unknown"" category designation. The results were presented in a UMAP projection (min_dist=0.3) of the scANVI-derived latent space, colored by annotated cell types to assess batch integration and identity preservation. The visualization was supported by a saved integrated AnnData object (`scanvi_integrated_data.h5ad`), which retained the learned latent space and nearest-neighbor graph for downstream analysis.  ","### Methods

#### Data Acquisition and Preprocessing  
The lung atlas dataset was downloaded in `.h5ad` format from a publicly available repository (https://figshare.com/ndownloader/files/24539942) and loaded into an AnnData object using the `scanpy.read` function. The raw, unprocessed dataset was stored in the `.raw` attribute of the AnnData object for reference.  

#### Highly Variable Gene Selection  
To focus on biologically relevant genes and reduce technical noise, highly variable genes (HVGs) were identified using the `scanpy.pp.highly_variable_genes` function with the `seurat_v3` flavor. A total of 2,000 HVGs were selected, and the analysis was performed in a batch-aware manner using the `batch_key` parameter to account for batch effects. The dataset was subset to retain only these HVGs for downstream analysis.  

#### Semi-Supervised Integration with scANVI  
The dataset was integrated using scANVI, a semi-supervised extension of the single-cell Variational Inference (scVI) framework. The AnnData object was registered for scANVI analysis using the `scvi.model.SCANVI.setup_anndata` function, specifying the `batch_key` for batch information and the `labels_key` for cell type annotations. The scANVI model was initialized with the `unlabeled_category` parameter set to ""Unknown"" to handle unlabeled data. The model was trained for 20 epochs with 100 samples per label to refine the latent representation.  

#### Post-Integration Analysis  
The latent representation learned by the scANVI model was retrieved and stored in the AnnData object. A nearest-neighbor graph was computed on this latent space using the `scanpy.pp.neighbors` function. Uniform Manifold Approximation and Projection (UMAP) was then applied to the integrated neighbor graph with a minimum distance parameter (`min_dist`) of 0.3 to visualize the data in two dimensions.  

#### Visualization and Data Output  
The integrated dataset was visualized using UMAP, with cells colored by their annotated cell types to assess the preservation of cell identities across batches. The final integrated and annotated AnnData object was saved to a file (`scanvi_integrated_data.h5ad`) for further analysis.  

#### Computational Details  
All analyses were performed using Python (v3.x) with the following key packages: Scanpy (v1.x), scVI-tools (v0.x), and Seaborn (v0.x). Matrix multiplication precision in PyTorch was set to ""high"" for optimal performance. Temporary directories were used for data storage and automatically cleaned up after analysis.","os, tempfile, scanpy, scvi, seabor, torch",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for system operations, data handling, analysis, and plotting
import os
import tempfile
import scanpy as sc
import scvi
import seaborn as sns
import torch
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set global parameters for plotting and computation
sc.set_figure_params(figsize=(6, 6), frameon=False)
sns.set_theme()
# Set precision for matrix multiplication in PyTorch for performance.
torch.set_float32_matmul_precision(""high"")

#--------------------------------
# Data Input & Preparation
#--------------------------------

# Create a temporary directory to store the downloaded dataset
save_dir = tempfile.TemporaryDirectory()
print(f""Data will be downloaded to temporary directory: {save_dir.name}"")

# Define file path for the dataset
adata_path = os.path.join(save_dir.name, ""lung_atlas.h5ad"")

# Download and load the lung atlas dataset.
# The `backup_url` will automatically download the file if not found locally.
print(""Downloading and loading dataset..."")
adata = sc.read(adata_path, backup_url=""https://figshare.com/ndownloader/files/24539942"")
print(adata)

# Store the full, unprocessed dataset in the .raw attribute for reference.
adata.raw = adata

#--------------------------------
# Preprocessing & Feature Selection
#--------------------------------

# Identify highly variable genes (HVGs) using a batch-aware method.
# This helps focus on biological signal and reduces technical noise.
# The `subset=True` argument modifies adata in place to keep only HVGs.
print(""Selecting highly variable genes..."")
sc.pp.highly_variable_genes(
    adata,
    flavor=""seurat_v3"",
    n_top_genes=2000,
    layer=""counts"",
    batch_key=""batch"",
    subset=True,
)

#--------------------------------
# Major Analysis Task: Semi-Supervised Integration with scANVI
#--------------------------------

# --- Model Setup and Training ---
# Register the AnnData object for scANVI analysis. This function specifies
# the data layer, batch information, and the key for cell type labels.
scvi.model.SCANVI.setup_anndata(adata, labels_key=""cell_type"", batch_key=""batch"")

# Initialize the scANVI model. scANVI extends scVI for semi-supervised tasks.
# It uses both labeled and unlabeled data for training.
# `unlabeled_category=""Unknown""` tells the model which label to treat as unlabeled.
scanvi_model = scvi.model.SCANVI(adata, unlabeled_category=""Unknown"")

# Train the scANVI model. This refines the latent space using the cell type labels.
print(""Training scANVI model..."")
scanvi_model.train(max_epochs=20, n_samples_per_label=100)

# --- Post-Integration Steps ---
# Retrieve the learned latent representation from the trained model.
SCANVI_LATENT_KEY = ""X_scANVI""
adata.obsm[SCANVI_LATENT_KEY] = scanvi_model.get_latent_representation()

# Compute the nearest-neighbor graph on the scANVI latent space.
# This integrated graph is used for downstream visualization.
sc.pp.neighbors(adata, use_rep=SCANVI_LATENT_KEY)

# Compute the UMAP embedding based on the integrated neighbor graph.
sc.tl.umap(adata, min_dist=0.3)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the UMAP embedding, coloring cells by their annotated cell type.
# This plot shows how well scANVI has integrated the batches while preserving cell identities.
print(""Visualizing integrated data..."")
sc.pl.umap(adata, color=[""cell_type""], frameon=False, ncols=1)


#--------------------------------
# Data Output
#--------------------------------

# Save the integrated and annotated AnnData object to a file.
print(""Saving integrated data object..."")
adata.write(""scanvi_integrated_data.h5ad"")

# Clean up the temporary directory
save_dir.cleanup()
",https://www.sc-best-practices.org/cellular_structure/integration.html,F
26,scRNA-seq,Integration,"The primary objective was to correct batch effects in single-cell RNA-seq data while preserving biological variation. This was accomplished using a graph-based integration strategy via Batch-Balanced K-Nearest Neighbors (BBKNN), implemented with the `bbknn` Python package in conjunction with `scanpy`. Starting with the split PBMC dataset (pbmc3k split into ""batch1""/""batch2""), the analysis involved log-normalization, selection of 2,000 highly variable genes (HVGs) with Seurat-style filtering, and PCA reduction to 50 principal components. BBKNN corrected batch effects by constructing separate within-batch K-nearest neighbor graphs (k=3 per batch) before merging them, prioritizing biological structure over technical artifacts. The final integrated graph retained cells passing variance stabilization and HVG thresholds. The results were presented in UMAP and t-SNE embeddings with batch-label coloring to illustrate successful mixing of cells from different batches. These findings were further supported by the saved integrated AnnData object (pbmc3k_bbknn_integrated.h5ad), which confirmed retained cellular heterogeneity while eliminating batch-driven clustering.  ","### Methods

#### Data Preprocessing and Simulation  
The peripheral blood mononuclear cell (PBMC) dataset, `pbmc3k`, was loaded using the `scanpy` package (`v1.9.0`). To simulate batch effects for demonstration purposes, the dataset was evenly split into two artificial batches, labeled ""batch1"" and ""batch2."" Batch labels were stored in the `obs` metadata field of the AnnData object.

#### Normalization and Feature Selection  
Data were normalized to a total count of 10,000 transcripts per cell using the `normalize_total` function in `scanpy`, followed by a log transformation (`log1p`) to stabilize variance. Highly variable genes (HVGs) were identified using the `highly_variable_genes` function with the `Seurat` flavor, selecting the top 2,000 genes based on their biological variability. The dataset was subset to retain only these HVGs for downstream analysis.

#### Scaling and Dimensionality Reduction  
Gene expression values were scaled to zero mean and unit variance using the `scale` function, with a maximum value threshold of 10 to mitigate the influence of extreme outliers. Principal Component Analysis (PCA) was performed using the `pca` function with the `arpack` solver, retaining the top 50 principal components (PCs) for subsequent batch correction.

#### Batch Integration Using BBKNN  
Batch effects were corrected using the Batch-Balanced K-Nearest Neighbors (BBKNN) algorithm (`v1.5.0`). The `bbknn` function was applied to the PCA-transformed data, specifying the batch labels stored in the `batch` metadata field. The algorithm computed a neighborhood graph by identifying 3 nearest neighbors within each batch before merging them into a single integrated graph. This approach preserved biological variation while minimizing batch-specific artifacts.

#### Post-Integration Embeddings  
To visualize the integrated data, Uniform Manifold Approximation and Projection (UMAP) and t-Distributed Stochastic Neighbor Embedding (t-SNE) embeddings were computed using the `umap` and `tsne` functions, respectively, in `scanpy`. These embeddings were based on the BBKNN-corrected neighborhood graph.

#### Visualization and Data Output  
The integrated dataset was visualized using UMAP and t-SNE embeddings, with cells colored by their batch labels to assess the effectiveness of batch correction. The final integrated AnnData object was saved to a `.h5ad` file (`pbmc3k_bbknn_integrated.h5ad`) for downstream analyses. All analyses were performed using Python (`v3.8.10`) with the `scanpy` (`v1.9.0`) and `bbknn` (`v1.5.0`) packages.","scanpy, bbknn, numpy, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis, batch correction, and plotting
import scanpy as sc
import bbknn
import numpy as np
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set global plotting parameters and logging verbosity for clear output
sc.settings.set_figure_params(dpi=80, facecolor='white')
sc.settings.verbosity = 2

#--------------------------------
# Data Input & Simulation
#--------------------------------

# Load the built-in PBMC3k dataset as an example
adata = sc.datasets.pbmc3k()

# Simulate two batches by splitting the dataset in half.
# This is for demonstration purposes; in a real scenario, the 'batch'
# column would come from the experimental design.
print(""Simulating two batches for demonstration..."")
num_cells = adata.n_obs
batch_labels = np.array([""batch1""] * num_cells)
batch_labels[int(num_cells / 2):] = ""batch2""
adata.obs[""batch""] = batch_labels

#--------------------------------
# Preprocessing & Dimensionality Reduction
#--------------------------------

# --- Normalization and Feature Selection ---
# Normalize each cell to a target count of 10,000 and apply a log transformation.
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)

# Identify highly variable genes (HVGs) to focus on biological variation.
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')
adata = adata[:, adata.var.highly_variable].copy()

# --- Scaling and PCA ---
# Scale the data to have zero mean and unit variance.
sc.pp.scale(adata, max_value=10)

# Perform Principal Component Analysis (PCA) for dimensionality reduction.
# The PCs will be used as input for the BBKNN algorithm.
sc.tl.pca(adata, svd_solver='arpack', n_comps=50)

#--------------------------------
# Major Analysis Task: Batch Integration with BBKNN
#--------------------------------

# --- Batch Integration ---
# Run Batch-Balanced K-Nearest Neighbors (BBKNN) to correct for batch effects.
# This function computes a neighborhood graph by finding neighbors within each
# batch separately before merging them into a single, integrated graph.
print(""\nRunning BBKNN for batch integration..."")
bbknn.bbknn(adata, batch_key='batch', n_pcs=50, neighbors_within_batch=3)

# --- Post-Integration Embeddings ---
# Compute UMAP and t-SNE embeddings based on the BBKNN-corrected neighborhood graph.
# These will be used for visualizing the integrated data.
sc.tl.umap(adata)
sc.tl.tsne(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Plot the UMAP embedding, coloring cells by their batch label.
# Successful integration should show cells from 'batch1' and 'batch2' mixing well.
sc.pl.umap(adata, color=[""batch""], title=""UMAP: BBKNN Integrated"", size=30)

# Plot the t-SNE embedding, also colored by batch, as an alternative visualization.
sc.pl.tsne(adata, color=[""batch""], title=""t-SNE: BBKNN Integrated"", size=30)


#--------------------------------
# Data Output
#--------------------------------

# Save the integrated AnnData object to a file.
# This object can now be used for downstream analysis like clustering.
print(""\nSaving integrated data object..."")
adata.write(""pbmc3k_bbknn_integrated.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/integrating-data-using-ingest.html,F
27,scRNA-seq,Integration,"The primary objective was to perform batch effect correction and visualize integration of a single-cell RNA-seq dataset. This was accomplished using a batch-balanced k-nearest neighbors (BBKNN) integration strategy, implemented with the `bbknn` Python package. Starting with raw PBMC3k scRNA-seq data, the analysis involved splitting cells into simulated batches, normalizing counts, selecting 2,000 highly variable genes (HVGs), scaling, and reducing dimensionality via PCA (50 PCs). BBKNN integration was applied using three neighbors per batch to construct a merged neighborhood graph. Successful integration was assessed by the degree of inter-batch mixing in low-dimensional embeddings. Results were visualized in UMAP and t-SNE embeddings colored by batch labels to illustrate the reduction of batch effects. The mixing of ""batch1"" and ""batch2"" cells confirmed successful integration. Findings were further supported by saving the corrected dataset as an H5AD-formatted AnnData object, preserving integrated graphs and embeddings for downstream analysis.","### Methods

#### Data Input and Simulation
The PBMC3k dataset, a publicly available single-cell RNA sequencing dataset, was loaded using the `scanpy` Python package. To simulate batch effects for demonstration purposes, the dataset was artificially split into two equal-sized batches, labeled ""batch1"" and ""batch2"". This step mimics experimental conditions where batch effects arise from technical or biological variability.

#### Preprocessing and Dimensionality Reduction
Raw gene expression counts were normalized to a target sum of 10,000 counts per cell using the `normalize_total` function in `scanpy`, followed by a log1p transformation to stabilize variance. Highly variable genes (HVGs) were identified using the `highly_variable_genes` function with the 'seurat' flavor, selecting the top 2,000 genes based on their variability across cells. The dataset was subset to include only these HVGs for downstream analysis. The data were then scaled to zero mean and unit variance using the `scale` function, with values capped at 10 to mitigate the influence of outliers. Principal Component Analysis (PCA) was performed using the `pca` function with 50 principal components (PCs) and the 'arpack' solver to reduce dimensionality.

#### Batch Integration with BBKNN
Batch effects were corrected using the Batch-Balanced K-Nearest Neighbors (BBKNN) algorithm, implemented in the `bbknn` package. The BBKNN algorithm constructs a neighborhood graph by identifying nearest neighbors within each batch separately and then merging these graphs into a single integrated representation. The integration was performed using the first 50 PCs as input, with the number of neighbors within each batch set to 3.

#### Post-Integration Embeddings
To visualize the batch-corrected data, Uniform Manifold Approximation and Projection (UMAP) and t-Distributed Stochastic Neighbor Embedding (t-SNE) embeddings were computed using the `umap` and `tsne` functions in `scanpy`, respectively. These embeddings were generated based on the BBKNN-corrected neighborhood graph.

#### Visualization
The integrated dataset was visualized using UMAP and t-SNE embeddings, with cells colored by their batch labels. Successful batch integration was assessed by the degree of mixing between cells from ""batch1"" and ""batch2"" in the low-dimensional embeddings.

#### Data Output
The batch-corrected dataset, including gene expression data, HVGs, PCA results, BBKNN-corrected neighborhood graph, and UMAP/t-SNE embeddings, was saved as an AnnData object in the H5AD file format for downstream analysis.","scanpy, matplotlib, numpy",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis, batch correction, and plotting
import scanpy as sc
import bbknn
import numpy as np
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set global plotting parameters and logging verbosity for clear output
sc.settings.set_figure_params(dpi=80, facecolor='white')
sc.settings.verbosity = 2

#--------------------------------
# Data Input & Simulation
#--------------------------------

# Load the built-in PBMC3k dataset as an example
adata = sc.datasets.pbmc3k()

# Simulate two batches by splitting the dataset in half.
# This is for demonstration purposes; in a real scenario, the 'batch'
# column would come from the experimental design.
print(""Simulating two batches for demonstration..."")
num_cells = adata.n_obs
batch_labels = np.array([""batch1""] * num_cells)
batch_labels[int(num_cells / 2):] = ""batch2""
adata.obs[""batch""] = batch_labels

#--------------------------------
# Preprocessing & Dimensionality Reduction
#--------------------------------

# --- Normalization and Feature Selection ---
# Normalize each cell to a target count of 10,000 and apply a log transformation.
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)

# Identify highly variable genes (HVGs) to focus on biological variation.
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')
adata = adata[:, adata.var.highly_variable]

# --- Scaling and PCA ---
# Scale the data to have zero mean and unit variance.
sc.pp.scale(adata, max_value=10)

# Perform Principal Component Analysis (PCA) for dimensionality reduction.
# The PCs will be used as input for the BBKNN algorithm.
sc.tl.pca(adata, svd_solver='arpack', n_comps=50)

#--------------------------------
# Major Analysis Task: Batch Integration with BBKNN
#--------------------------------

# --- Batch Integration ---
# Run Batch-Balanced K-Nearest Neighbors (BBKNN) to correct for batch effects.
# This function computes a neighborhood graph by finding neighbors within each
# batch separately before merging them into a single, integrated graph.
print(""Running BBKNN for batch integration..."")
bbknn.bbknn(adata, batch_key='batch', n_pcs=50, neighbors_within_batch=3)

# --- Post-Integration Embeddings ---
# Compute UMAP and t-SNE embeddings based on the BBKNN-corrected neighborhood graph.
# These will be used for visualizing the integrated data.
sc.tl.umap(adata)
sc.tl.tsne(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Plot the UMAP embedding, coloring cells by their batch label.
# Successful integration should show cells from 'batch1' and 'batch2' mixing well.
sc.pl.umap(adata, color=[""batch""], title=""UMAP: BBKNN Integrated"", size=30)

# Plot the t-SNE embedding, also colored by batch, as an alternative visualization.
sc.pl.tsne(adata, color=[""batch""], title=""t-SNE: BBKNN Integrated"", size=30)


#--------------------------------
# Data Output
#--------------------------------

# Save the integrated AnnData object to a file.
# This object can now be used for downstream analysis like clustering.
print(""Saving integrated data object..."")
adata.write(""pbmc3k_bbknn_integrated.h5ad"")
",https://www.sc-best-practices.org/cellular_structure/integration.html,F
28,scRNA-seq,Integration,"The primary objective was to correct batch effects between two simulated PBMC datasets. This was accomplished using a Mutual Nearest Neighbors (MNN) alignment strategy, implemented with the `scanpy.external.mnn_correct` tool in Python. Starting with simulated batches of the PBMC 3k dataset, the analysis involved normalization, log-transformation, and selection of highly variable genes (HVGs). Batch correction was performed via MNN alignment, followed by dimensionality reduction (PCA) and UMAP computation. Integration success was assessed through visual coherence of batch mixing in low-dimensional space. The results were presented in a UMAP projection colored by batch assignment to demonstrate batch effect removal. These findings were validated by the homogenized distribution of cells across batches in the UMAP and the output of an integrated `AnnData` object for downstream clustering and analysis.","### Methods

#### Data Input and Simulation
A publicly available single-cell RNA sequencing dataset of peripheral blood mononuclear cells (PBMC 3k) was obtained from the `scanpy` package. To simulate batch effects for demonstration purposes, cells were randomly assigned to one of two batches (`batch1` or `batch2`) using a fixed random seed for reproducibility. The dataset was then split into two separate objects, one for each batch, to prepare for batch correction.

#### Preprocessing
Each batch was preprocessed individually to account for technical variations. First, total counts per cell were normalized to 10,000 using the `normalize_total` function in `scanpy` to correct for differences in library size. The data were then log-transformed using the `log1p` function to stabilize variance. Highly variable genes were identified using the `highly_variable_genes` function, retaining the top 2,000 genes for downstream analysis to focus on biologically relevant signals.

#### Batch Integration Using Mutual Nearest Neighbors (MNN)
Batch effects were corrected using the Mutual Nearest Neighbors (MNN) method implemented in the `scanpy.external` module. The `mnn_correct` function was applied to integrate the two batches, aligning shared cell populations across batches. This process generated a corrected dataset suitable for downstream analysis.

#### Post-Integration Analysis
Principal Component Analysis (PCA) was performed on the MNN-corrected data using the `pca` function in `scanpy` with the `arpack` solver to identify the main axes of variation. A neighborhood graph was constructed using the top 50 principal components to capture the underlying data structure. Uniform Manifold Approximation and Projection (UMAP) was then computed using the `umap` function to visualize the integrated data in a two-dimensional space.

#### Visualization and Data Output
The integrated dataset was visualized using UMAP, with cells colored by their batch assignment to assess the effectiveness of batch correction. The corrected dataset was saved as an `AnnData` object (`pbmc3k_mnn_integrated.h5ad`) for further downstream analyses, such as clustering and differential expression.

All analyses were performed using the `scanpy` (v1.x) and `scanpy.external` (v1.x) packages in Python.","scanpy, matplotlib, numpy",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis, batch correction, and plotting
import scanpy as sc
import scanpy.external as sce
import matplotlib.pyplot as plt
import numpy as np

#--------------------------------
# Script Configuration
#--------------------------------

# Set global plotting parameters for clear and consistent visualization
sc.settings.set_figure_params(dpi=80, facecolor='white')

#--------------------------------
# Data Input & Simulation
#--------------------------------

# Load an example dataset (PBMC 3k) provided by Scanpy
adata = sc.datasets.pbmc3k()

# Simulate two batches by randomly assigning cells to one of two groups.
# In a real-world scenario, this 'batch' information would come from the experiment metadata.
print(""Simulating two batches for demonstration..."")
np.random.seed(42)
adata.obs['batch'] = np.random.choice(['batch1', 'batch2'], size=adata.n_obs)

# Split the main AnnData object into two separate objects, one for each batch.
# MNN correction is typically performed on a list of batch-specific objects.
adata_batch1 = adata[adata.obs['batch'] == 'batch1'].copy()
adata_batch2 = adata[adata.obs['batch'] == 'batch2'].copy()


#--------------------------------
# Preprocessing
#--------------------------------

# Preprocess each batch individually. This is a common strategy before integration.
print(""Preprocessing each batch individually..."")
for ad in [adata_batch1, adata_batch2]:
    # 1. Normalize total counts per cell to account for library size differences.
    sc.pp.normalize_total(ad, target_sum=1e4)
    # 2. Log-transform the data to stabilize variance.
    sc.pp.log1p(ad)
    # 3. Identify highly variable genes to focus on biological signal.
    sc.pp.highly_variable_genes(ad, n_top_genes=2000, subset=True)


#--------------------------------
# Major Analysis Task: Batch Integration with MNN
#--------------------------------

# --- MNN Integration ---
# Integrate the two batches using Mutual Nearest Neighbors (MNN) correction.
# This method identifies shared cell populations across batches and aligns them.
# The function returns a new, integrated AnnData object.
print(""Running MNN integration..."")
adata_corrected, _ = sce.pp.mnn_correct(adata_batch1, adata_batch2, batch_key='batch')

# --- Post-Integration Steps ---
# Perform PCA on the MNN-corrected data to find the main axes of variation.
sc.tl.pca(adata_corrected, svd_solver='arpack')

# Construct the neighborhood graph on the integrated PCA space.
sc.pp.neighbors(adata_corrected, n_pcs=50)

# Compute the UMAP embedding for visualization.
sc.tl.umap(adata_corrected)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Plot the UMAP embedding of the corrected data, coloring by batch.
# Successful integration should result in cells from 'batch1' and 'batch2'
# mixing together within cell type clusters.
print(""Visualizing integrated data..."")
sc.pl.umap(adata_corrected, color='batch', title='MNN Integrated UMAP')


#--------------------------------
# Data Output
#--------------------------------

# Save the integrated AnnData object to a file.
# This object is now ready for downstream analyses like clustering.
print(""Saving integrated data object..."")
adata_corrected.write(""pbmc3k_mnn_integrated.h5ad"")
",https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.harmony_integrate.html#scanpy.external.pp.harmony_integrate,F
29,scRNA-seq,Integration,"The primary objective was to integrate single-cell RNA-seq datasets from control and stimulated conditions while correcting technical batch effects. This was accomplished using a mutual nearest neighbors (MNNs)-based integration strategy, implemented with the Seurat package (v4.0.0) in R. Starting with raw count matrices from 10X Genomics, the analysis involved filtering low-quality cells/genes (minimum 200 genes/cell, 3 cells/gene), normalization (LogNormalize, scale factor 10,000), and selecting highly variable genes (top 2,000 via ""vst""). Integration anchors were identified using MNNs across 20 principal components, followed by batch correction through the `IntegrateData` function. Dimensionality reduction was performed via PCA (30 PCs) and UMAP (20 PCs), with cell clusters defined using graph-based clustering (resolution=0.5). The results were presented in a UMAP plot colored by experimental condition to visualize integration success and shared cell states. This was supported by cluster-specific metadata in the final Seurat object, which preserved harmonized gene expression patterns for downstream analyses like differential expression or trajectory inference.  ","### Methods

#### Data Acquisition and Preprocessing  
Single-cell RNA sequencing (scRNA-seq) data were acquired from two conditions: control and stimulated. Raw count matrices were generated using the 10X Genomics platform and read into R using the `Read10X` function from the Seurat package (v4.0.0). Individual Seurat objects were created for each condition using the `CreateSeuratObject` function, with a minimum threshold of 3 cells per gene and 200 genes per cell to filter out low-quality cells and genes.  

#### Normalization and Feature Selection  
Each dataset was preprocessed independently to account for batch effects prior to integration. Data normalization was performed using the `NormalizeData` function with the ""LogNormalize"" method and a scale factor of 10,000 to correct for differences in library size. Highly variable genes were identified using the `FindVariableFeatures` function with the ""vst"" selection method, retaining the top 2,000 genes for downstream analysis.  

#### Data Integration  
To integrate the control and stimulated datasets, shared cellular states were identified using the `FindIntegrationAnchors` function, which employs mutual nearest neighbors (MNNs) across the first 20 principal components (PCs). The integrated dataset was generated using the `IntegrateData` function, which leverages these anchors to correct for batch effects. The integrated data matrix was set as the default assay for subsequent analyses.  

#### Dimensionality Reduction and Clustering  
The integrated dataset was scaled using the `ScaleData` function to ensure equal contribution of genes in downstream analyses. Principal component analysis (PCA) was performed using the `RunPCA` function, retaining the top 30 PCs for dimensionality reduction. Non-linear dimensionality reduction was achieved using uniform manifold approximation and projection (UMAP) with the `RunUMAP` function, utilizing the first 20 PCs as input. Cell clustering was performed using the `FindNeighbors` and `FindClusters` functions, with a resolution parameter of 0.5 to identify distinct cell populations.  

#### Visualization and Data Output  
UMAP visualization was generated using the `DimPlot` function, with cells colored by their condition of origin to assess the success of integration. The final integrated Seurat object was saved for future analyses using the `saveRDS` function.  

All analyses were conducted using the Seurat package in R, with additional support from the `dplyr`, `ggplot2`, and `patchwork` packages for data manipulation and visualization.","Seurat, dplyr, ggplot2, patchwork",R,"#--------------------------------
# Package Load
#--------------------------------

# Load necessary libraries for single-cell analysis, data manipulation, and plotting
library(Seurat)      # For single-cell RNA-seq analysis and integration
library(dplyr)       # For data manipulation
library(ggplot2)     # For creating custom, publication-quality plots
library(patchwork)   # For easily combining multiple ggplot2 plots

#--------------------------------
# Data Input
#--------------------------------

# Define file paths for the Control and Stimulated datasets.
# NOTE: Replace these with the actual paths to your data directories.
data_dir_control <- ""path/to/control_data/""
data_dir_stim    <- ""path/to/stimulated_data/""

# Read the raw 10X Genomics data for each condition.
data_control <- Read10X(data.dir = data_dir_control)
data_stim    <- Read10X(data.dir = data_dir_stim)

# Create individual Seurat objects for each dataset with basic filtering.
control <- CreateSeuratObject(counts = data_control, project = ""Control"", min.cells = 3, min.features = 200)
stim    <- CreateSeuratObject(counts = data_stim, project = ""Stimulated"", min.cells = 3, min.features = 200)

#--------------------------------
# Preprocessing of Individual Datasets
#--------------------------------

# It's a standard practice to preprocess each dataset individually before integration.
# Here, we normalize and find variable features for both datasets.
object_list <- list(control, stim)
for (i in 1:length(object_list)) {
    object_list[[i]] <- NormalizeData(object_list[[i]], normalization.method = ""LogNormalize"", scale.factor = 10000)
    object_list[[i]] <- FindVariableFeatures(object_list[[i]], selection.method = ""vst"", nfeatures = 2000)
}

#--------------------------------
# Major Analysis Task: Data Integration
#--------------------------------

# --- Find Integration Anchors ---
# Identify ""anchors"" or mutual nearest neighbors between the datasets. These anchors
# represent shared cellular states across different conditions.
# `dims = 1:20` specifies that the first 20 PCs are used for finding anchors.
integration_anchors <- FindIntegrationAnchors(object.list = object_list, dims = 1:20)

# --- Integrate Data ---
# Use the identified anchors to create an integrated (batch-corrected) data matrix.
integrated_data <- IntegrateData(anchorset = integration_anchors, dims = 1:20)

# Set the default assay to ""integrated"" to ensure that downstream analysis
# (like scaling, PCA, UMAP) is performed on the corrected data.
DefaultAssay(integrated_data) <- ""integrated""


#--------------------------------
# Post-Integration Analysis
#--------------------------------

# --- Scaling and Dimensionality Reduction ---
# Scale the integrated data. This is necessary for PCA.
integrated_data <- ScaleData(integrated_data, verbose = FALSE)

# Run PCA on the scaled, integrated data to reduce dimensionality.
integrated_data <- RunPCA(integrated_data, npcs = 30, verbose = FALSE)

# Run UMAP for non-linear dimensionality reduction and visualization.
integrated_data <- RunUMAP(integrated_data, reduction = ""pca"", dims = 1:20)

# --- Clustering (Optional) ---
# Perform clustering on the integrated data to identify cell populations.
integrated_data <- FindNeighbors(integrated_data, reduction = ""pca"", dims = 1:20)
integrated_data <- FindClusters(integrated_data, resolution = 0.5)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Generate a UMAP plot, coloring cells by their original condition ('orig.ident').
# Successful integration should show cells from both conditions mixing well within clusters.
DimPlot(integrated_data, reduction = ""umap"", group.by = ""orig.ident"", label = TRUE) +
  ggtitle(""UMAP Plot: Integrated Data by Condition"")


#--------------------------------
# Data Output
#--------------------------------

# Save the final, integrated Seurat object for future analyses.
saveRDS(integrated_data, file = ""Integrated_Seurat_Object.rds"")
",https://satijalab.org/seurat/articles/integration_introduction#perform-integration,F
30,scRNA-seq,Trajectory inference,"The primary objective was to reconstruct the developmental trajectory of hematopoietic cells from single-cell RNA-seq data. This was accomplished using a PAGA-based graph abstraction strategy, implemented with the scanpy Python package. Starting with raw count data, the analysis involved log-normalization, highly variable gene selection, and PCA-based dimensionality reduction followed by construction of a k-nearest neighbor graph (k=10). Cells were clustered via Louvain algorithm (resolution=1.0), with PAGA calculating cluster-cluster connectivity probabilities. Trajectory structure was preserved in the final embedding through PAGA-initialized layout optimization. The results were presented in a combined visualization showing both the coarse PAGA graph (edges thresholded at >0.03 connection strength) and fine-grained single-cell trajectory. These findings were further supported by the preservation of cluster relationships between the abstracted PAGA graph and cell embedding, confirming consistent topology across analysis resolutions.","### Methods

#### Data Preprocessing  
The single-cell RNA-seq dataset from Paul et al. (2015) was loaded and analyzed using the `scanpy` package (version X.X.X). To ensure numerical stability, the data matrix was converted to a float64 format. Preprocessing was performed using the `recipe_zheng17` function, which includes normalization of counts per cell to a total count of 10,000, log1p transformation, and selection of highly variable genes. Principal Component Analysis (PCA) was conducted using the `arpack` solver to reduce dimensionality, retaining the top 20 principal components for downstream analysis. A k-nearest neighbor graph was constructed with `n_neighbors=10` to capture local cell-cell relationships.

#### Clustering and Trajectory Inference  
Cells were clustered using the Louvain algorithm with a resolution parameter of 1.0 to identify discrete cell populations. The Partition-based Graph Abstraction (PAGA) algorithm was applied to infer a coarse-grained graph representing connectivity between clusters, providing an abstracted view of the developmental trajectory. To visualize the trajectory, a UMAP-like embedding was computed using the `draw_graph` function, with initial positions derived from the PAGA graph to ensure the embedding reflected the global topology inferred by PAGA.

#### Visualization  
The PAGA graph was visualized, with edges representing the likelihood of connections between clusters. Weak connections were pruned using a threshold of 0.03 for clarity. The single-cell embedding initialized with PAGA was plotted to show the fine-grained trajectory of individual cells, guided by the coarse-grained PAGA structure.

#### Data Output  
The final `AnnData` object, containing the PAGA results and trajectory layout, was saved in `.h5ad` format for further analysis.","scanpy, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis and plotting
import scanpy as sc
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set global settings for clear visualization and detailed logging
sc.settings.verbosity = 3
sc.settings.set_figure_params(dpi=80, facecolor='white')

#--------------------------------
# Data Input
#--------------------------------

# Load the Paul et al. (2015) dataset, a common benchmark for trajectory inference.
adata = sc.datasets.paul15()

# Ensure the data matrix is in a float format for numerical stability.
adata.X = adata.X.astype('float64')

#--------------------------------
# Preprocessing
#--------------------------------

# Apply a standard preprocessing recipe. This includes normalization per cell,
# log transformation, and selection of highly variable genes.
print(""Preprocessing data..."")
sc.pp.recipe_zheng17(adata)

# Perform PCA for dimensionality reduction.
sc.tl.pca(adata, svd_solver='arpack')

# Compute the k-nearest neighbor graph, which is required for clustering and PAGA.
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20)


#--------------------------------
# Major Analysis Task: Trajectory Inference
#--------------------------------

# --- Clustering ---
# Cluster cells using the Louvain algorithm. The resulting clusters will be used
# to build the abstracted graph in PAGA.
print(""Clustering cells..."")
sc.tl.louvain(adata, resolution=1.0)

# --- PAGA (Partition-based Graph Abstraction) ---
# Compute the PAGA graph, which represents the connectivity between cell clusters.
# This provides a high-level, abstracted view of the developmental trajectory.
print(""Computing PAGA graph..."")
sc.tl.paga(adata, groups='louvain')

# --- UMAP Initialization for Visualization ---
# Compute a UMAP-like embedding, but initialize the positions using the PAGA graph.
# This helps the final visualization better reflect the global topology inferred by PAGA.
sc.tl.draw_graph(adata, init_pos='paga')


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Plot the PAGA abstracted graph. Edges represent the likelihood of a connection
# between clusters. The `threshold` prunes weak connections for clarity.
print(""Visualizing PAGA graph and trajectory..."")
sc.pl.paga(
    adata,
    color=['louvain'],
    threshold=0.03,
    title='PAGA Graph for Trajectory Inference'
)

# Plot the single-cell embedding initialized with PAGA.
# This layout shows the fine-grained trajectory of individual cells, guided by the
# coarse-grained PAGA structure.
sc.pl.draw_graph(
    adata,
    color='louvain',
    legend_loc='on data',
    title='Trajectory Inference via PAGA Initialization'
)


#--------------------------------
# Data Output
#--------------------------------

# Save the AnnData object, which now contains the PAGA results and trajectory layout.
print(""Saving trajectory data object..."")
adata.write(""paul15_paga_trajectory.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/trajectories/paga-paul15.html,F
31,scRNA-seq,Quality control,"The primary objective was to perform quality control and preprocessing of single-cell RNA sequencing data to remove low-quality cells and genes. This was accomplished using threshold-based filtering and normalization, implemented with the Scanpy toolkit in Python. Starting with raw gene count matrices from 10X Genomics, the analysis involved calculating mitochondrial content, total counts, and genes per cell. Cells exceeding thresholds (>5% mitochondrial genes, >5,000 total counts, or >2,500 genes) were filtered. Genes not expressed in any remaining cells were removed. The data were normalized to 10,000 transcripts per cell, log-transformed, and 2,000 highly variable genes (HVGs) were selected using Seurat?€?s dispersion-based method. The results were presented in violin plots to illustrate the distribution of QC metrics before and after filtering. These findings were further supported by a mean-dispersion plot highlighting selected HVGs, which confirmed the gene selection strategy. The processed AnnData object enabled downstream clustering and dimensionality reduction.  ","### Methods

#### Data Preprocessing and Quality Control

Single-cell RNA sequencing data were processed using the Scanpy toolkit (version 1.9.0) in Python. The dataset, generated using the 10X Genomics platform, was loaded from a matrix directory using the `sc.read_10x_mtx` function. To ensure reproducibility, the processed data were cached for faster loading in subsequent analyses.

Quality control (QC) metrics were calculated to identify and remove low-quality cells and genes. Mitochondrial genes were identified by the ""MT-"" prefix in their gene names. Standard QC metrics, including the percentage of mitochondrial gene counts, total counts, and the number of genes detected per cell, were computed using the `sc.pp.calculate_qc_metrics` function. Cells were flagged as outliers if they exhibited a mitochondrial gene content exceeding 5%, total counts greater than 5,000, or more than 2,500 genes detected. These outlier cells were excluded from further analysis. Additionally, genes not expressed in any remaining cells were filtered out using the `sc.pp.filter_genes` function with a minimum threshold of one cell.

#### Normalization and Feature Selection

To account for differences in library size, the data were normalized to a target count of 10,000 transcripts per cell using the `sc.pp.normalize_total` function, followed by a log1p transformation. Highly variable genes (HVGs) were identified using the Seurat flavor of the `sc.pp.highly_variable_genes` function, with the top 2,000 genes selected based on their mean expression and normalized dispersion.

#### Visualization

QC metrics, including the number of genes detected, total counts, and mitochondrial gene content, were visualized using violin plots generated with the `sc.pl.violin` function. The selection of HVGs was confirmed by plotting the mean expression against the normalized dispersion, with selected genes highlighted in red.

#### Data Output

The filtered and processed dataset, including normalized expression values and HVGs, was saved as an AnnData object for downstream analyses, such as dimensionality reduction and clustering.","numpy, matplotlib, scanpy",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for numerical operations, plotting, and single-cell analysis
import numpy as np
import matplotlib.pyplot as plt
import scanpy as sc

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
sc.settings.verbosity = 3
sc.settings.set_figure_params(dpi=80, facecolor=""white"")

#--------------------------------
# Data Input
#--------------------------------

# Load the dataset from a 10X Genomics matrix directory.
# NOTE: Replace the path with the location of your pbmc3k_v1 data directory.
# `cache=True` will save a processed version of the data for faster loading next time.
adata = sc.read_10x_mtx(""tutorial_data/pbmc3k_v1/"", cache=True)


#--------------------------------
# Quality Control (QC) and Filtering
#--------------------------------

# --- QC Metrics Calculation ---
# Identify mitochondrial genes, which are often a sign of cell stress if highly expressed.
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")

# Calculate standard quality control metrics.
sc.pp.calculate_qc_metrics(
    adata, qc_vars=[""mt""], percent_top=None, log1p=False, inplace=True
)

# --- Filtering ---
# Define outlier cells based on QC metrics. These thresholds may need adjustment
# depending on the specific dataset.
adata.obs[""outlier_mt""] = adata.obs.pct_counts_mt > 5
adata.obs[""outlier_total""] = adata.obs.total_counts > 5000
adata.obs[""outlier_ngenes""] = adata.obs.n_genes_by_counts > 2500

# Print the number of outliers detected for each metric.
print(f""Found {sum(adata.obs['outlier_mt'])} cells with high mitochondrial content."")
print(f""Found {sum(adata.obs['outlier_total'])} cells with large total counts."")
print(f""Found {sum(adata.obs['outlier_ngenes'])} cells with a large number of genes."")

# Remove outlier cells from the dataset based on the flags defined above.
# The `~` operator inverts the boolean selection.
adata = adata[~adata.obs[""outlier_mt""], :]
adata = adata[~adata.obs[""outlier_total""], :]
adata = adata[~adata.obs[""outlier_ngenes""], :]

# Filter out genes that are no longer expressed in any cells after cell filtering.
sc.pp.filter_genes(adata, min_cells=1)


#--------------------------------
# Preprocessing & Feature Selection
#--------------------------------

# Normalize each cell to a target count of 10,000 and apply a log transformation.
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)

# Identify highly variable genes (HVGs). This step calculates mean expression
# and residual variances, which are used in the plot below.
sc.pp.highly_variable_genes(adata, flavor=""seurat"", n_top_genes=2000)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- QC Plots ---
# Plot violin plots of the main QC metrics to visualize their distributions.
sc.pl.violin(
    adata,
    [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],
    jitter=0.4,
    multi_panel=True,
)

# --- HVG Plot ---
# Create a scatter plot to visualize highly variable genes.
# This helps confirm that the feature selection has worked as expected.
fig, ax = plt.subplots(figsize=(6, 6))
hvgs = adata.var[""highly_variable""]

# Plot all genes in grey
ax.scatter(
    adata.var[""means""], adata.var[""dispersions_norm""], s=3, edgecolor=""none""
)
# Highlight the selected highly variable genes in red
ax.scatter(
    adata.var[""means""][hvgs],
    adata.var[""dispersions_norm""][hvgs],
    c=""tab:red"",
    label=""selected genes"",
    s=3,
    edgecolor=""none"",
)
ax.set_xscale(""log"")
ax.set_yscale(""log"")
ax.set_xlabel(""Mean Expression"")
ax.set_ylabel(""Normalized Dispersion"")
ax.set_title(""Highly Variable Genes"")
plt.legend()
plt.show()


#--------------------------------
# Data Output
#--------------------------------

# Save the filtered and processed AnnData object to a file.
# This object is ready for downstream analysis like dimensionality reduction and clustering.
print(""Saving filtered data object..."")
adata.write(""pbmc3k_filtered_hvg.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/experimental/pearson_residuals.html,F
32,scRNA-seq,Feature selection,"The primary objective was to identify biologically informative highly variable genes (HVGs) in single-cell RNA-seq data. This was accomplished using a Pearson residuals-based feature selection strategy, implemented with the experimental functions of the scanpy package (version 1.9.0) in Python. Starting with raw count matrices from 10X Genomics, the analysis involved filtering cells based on mitochondrial read proportions and applying a residuals-based model to quantify gene variability. The top 2,000 genes with the highest residual variance indicative of biological rather than technical variation were retained. These were selected using a statistical framework that models technical noise while prioritizing genes with significant biological variability. The results were presented in a log-scaled mean-variance scatter plot, with HVGs highlighted in red to illustrate their deviation from technical noise. This visualization confirmed the separation of HVGs from low-variance genes. The validity of the selection was further supported by subsetting the dataset to HVGs for downstream analyses, ensuring only the most biologically relevant features informed subsequent clustering and dimensionality reduction steps.  ","### Methods

#### Data Import
Single-cell RNA-seq data were imported from a 10X Genomics-formatted directory using the `scanpy` function `sc.read_10x_mtx`. The data were cached to optimize subsequent analyses.

#### Quality Control
Mitochondrial genes were identified by the ""MT-"" prefix in their gene names. Basic quality control metrics, including the proportion of mitochondrial reads, were calculated for each cell using the `sc.pp.calculate_qc_metrics` function.

#### Feature Selection
Highly variable genes (HVGs) were identified using the Pearson residuals method implemented in the experimental function `sc.experimental.pp.highly_variable_genes`. This method models technical variability and selects genes with significant deviations, which are likely to represent biological variability. The top 2,000 genes with the highest residual variance were retained as HVGs.

#### Visualization
The results of the feature selection were visualized using a scatter plot of mean expression versus residual variance for all genes. Genes identified as highly variable were highlighted in red, while all other genes were plotted in grey. The axes were log-scaled to better visualize the distribution of the data.

#### Data Subsetting and Output
The dataset was subset to retain only the highly variable genes. The resulting processed data object was saved in H5AD format for downstream analyses, such as dimensionality reduction and clustering.

This workflow was implemented using the `scanpy` package (version 1.9.0) in Python. Detailed logging was enabled to monitor the progress of the analysis.","numpy, matplotlib, scanpy",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for numerical operations, plotting, and single-cell analysis
import numpy as np
import matplotlib.pyplot as plt
import scanpy as sc

#--------------------------------
# Script Configuration
#--------------------------------

# Set Scanpy global parameters for plotting and verbosity
sc.settings.verbosity = 3  # Show detailed logging
sc.settings.set_figure_params(dpi=80, facecolor=""white"")

#--------------------------------
# Data Input
#--------------------------------

# Load the dataset from a 10X Genomics formatted directory.
# NOTE: Replace the path with the location of your data directory.
adata = sc.read_10x_mtx(""data/10x_genomics_directory/"", cache=True)


#--------------------------------
# Quality Control (QC)
#--------------------------------

# Identify mitochondrial genes for potential QC filtering later on.
adata.var['mt'] = adata.var_names.str.startswith(""MT-"")

# Calculate basic quality control metrics for each cell.
sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], percent_top=None, inplace=True)


#--------------------------------
# Major Analysis Task: Feature Selection
#--------------------------------

# Identify highly variable genes using the Pearson residuals method.
# This experimental function models technical variability and selects genes
# that deviate significantly, which are likely biologically variable.
sc.experimental.pp.highly_variable_genes(
    adata, flavor=""pearson_residuals"", n_top_genes=2000
)

# Print the number of highly variable genes found for confirmation.
print(f""Number of highly variable genes selected: {sum(adata.var['highly_variable'])}"")


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Create a scatter plot to visualize the feature selection results.
# The plot shows mean expression vs. the residual variance calculated by the model.
fig, ax = plt.subplots(figsize=(6, 6))
hvgs = adata.var[""highly_variable""]

# Plot all genes in grey
ax.scatter(
    adata.var[""mean_counts""],
    adata.var[""residual_variances""],
    s=3,
    c='gray',
    label='All genes',
    alpha=0.5
)
# Highlight the selected highly variable genes in red
ax.scatter(
    adata.var[""mean_counts""][hvgs],
    adata.var[""residual_variances""][hvgs],
    s=3,
    c='red',
    label='Highly variable genes'
)

ax.set_xscale(""log"")
ax.set_yscale(""log"")
ax.set_xlabel(""Mean Expression"")
ax.set_ylabel(""Residual Variance"")
ax.set_title(""Feature Selection: Pearson Residuals"")
plt.legend()
plt.show()


#--------------------------------
# Data Output
#--------------------------------

# Subset the AnnData object to keep only the highly variable genes.
adata = adata[:, adata.var[""highly_variable""]]

# Save the processed AnnData object to a file.
# This object is ready for downstream analysis like dimensionality reduction.
print(""Saving filtered data object..."")
adata.write(""pearson_residuals_hvg.h5ad"")
",https://scanpy.readthedocs.io/en/stable/tutorials/experimental/pearson_residuals.html,F
33,scRNA-seq,Trajectory inference,"The primary objective was to infer developmental trajectories from single-cell RNA-seq data. This was accomplished using the Diffusion Pseudotime (DPT) algorithm, implemented with the scanpy package in Python. Starting with a preprocessed AnnData object in .h5ad format, the analysis involved filtering low-coverage genes, library size normalization, log transformation, and principal component analysis. Highly variable genes and Louvain clustering were used to identify biological signals before constructing a diffusion map graph. The root cell for trajectory inference was heuristically selected based on minimal third diffusion component values. Final pseudotime values were derived from geodesic distances in the diffusion map. The results were visualized through t-SNE embeddings colored by both pseudotime and clusters to illustrate cell state progression. These findings were supported by violin plots comparing pseudotime distributions across clusters, which validated the trajectory's biological consistency.","### Methods

#### Data Acquisition and Preprocessing  
The single-cell RNA-seq dataset was obtained in `.h5ad` format and loaded using the `scanpy` Python package (version X.X.X). To ensure reproducibility, a backup URL was provided to download the dataset if not found locally. The dataset was preprocessed using a standardized workflow. Genes expressed in fewer than 20 cells were filtered out to remove low-quality or non-informative features. To account for differences in library size, counts were normalized to a total count of 10,000 per cell using the `normalize_total` function. A log transformation (`log1p`) was applied to stabilize variance across the dataset. Highly variable genes (HVGs) were identified to focus on biologically relevant signals, and principal component analysis (PCA) was performed for dimensionality reduction using the top 10 principal components. A nearest neighbor graph was computed to facilitate downstream clustering and trajectory analysis.

#### Clustering and Visualization  
Cell clusters were identified using the Louvain algorithm, a graph-based clustering method implemented in `scanpy`. To visualize the data in a low-dimensional space, a t-SNE embedding was computed. This embedding was used to plot cell clusters and assess the overall structure of the dataset.

#### Trajectory Inference Using Diffusion Pseudotime (DPT)  
Diffusion maps were computed to model the data as a graph, where edge weights represent transition probabilities between cells. The root cell for the pseudotime trajectory was selected as the cell with the minimum value in the third diffusion component, a heuristic choice that often corresponds to the earliest cell state in a differentiation process. Diffusion Pseudotime (DPT) was calculated to order cells based on their distance from the root cell along the diffusion map graph, providing a pseudotemporal ordering of cells along the inferred trajectory.

#### Visualization of Trajectory Results  
The t-SNE embedding was visualized to highlight both cell clusters and pseudotime values. Pseudotime distributions across clusters were compared using violin plots to assess the progression of cells along the inferred trajectory.

#### Data Output  
The final `AnnData` object, containing the preprocessed data, clustering results, and trajectory inference outputs, was saved in `.h5ad` format for further analysis.  

All analyses were performed using the `scanpy` package (version X.X.X) in Python (version X.X.X).","scampy, pathlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for system operations, data handling, and single-cell analysis
import scanpy as sc
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt

#--------------------------------
# Data Input & Preparation
#--------------------------------

# Define the directory to store the data and create it if it doesn't exist.
DATA_DIR = Path(""./data/"")
DATA_DIR.mkdir(parents=True, exist_ok=True)
FILE_NAME = DATA_DIR / ""bone_marrow.h5ad""

# Load the dataset. A backup URL is provided to download the data if not found locally.
print(""Loading dataset..."")
adata = sc.read(
    filename=FILE_NAME,
    backup_url=""https://figshare.com/ndownloader/files/35826944""
)

#--------------------------------
# Preprocessing
#--------------------------------

# Apply a standard preprocessing workflow.
print(""Preprocessing data..."")
# Filter out genes that are not expressed in at least 20 cells.
sc.pp.filter_genes(adata, min_counts=20)
# Normalize each cell by total counts to account for library size differences.
sc.pp.normalize_total(adata)
# Apply a log transformation to the data to stabilize variance.
sc.pp.log1p(adata)
# Identify highly variable genes (HVGs) to focus on biological signal.
sc.pp.highly_variable_genes(adata)
# Perform PCA for dimensionality reduction.
sc.tl.pca(adata)
# Compute the nearest neighbor graph, which is required for clustering and trajectory analysis.
sc.pp.neighbors(adata, n_pcs=10)

#--------------------------------
# Major Analysis Task: Trajectory Inference with DPT
#--------------------------------

# --- Clustering & Visualization Embedding ---
# Cluster cells using the Louvain algorithm to identify cell groups.
sc.tl.louvain(adata)
# Compute a t-SNE embedding for visualization purposes.
sc.tl.tsne(adata)

# --- Diffusion Pseudotime (DPT) ---
# Compute the diffusion map. This represents the data as a graph where edge
# weights reflect the transition probability between cells.
print(""Computing diffusion map and pseudotime..."")
sc.tl.diffmap(adata)

# Identify the root cell for the pseudotime trajectory. Here, we select the cell
# with the minimum value in the 3rd diffusion component as the starting point.
# This choice often corresponds to the earliest cell state in a differentiation process.
root_ixs = adata.obsm[""X_diffmap""][:, 3].argmin()
adata.uns[""iroot""] = root_ixs

# Compute Diffusion Pseudotime (DPT), which orders cells based on their distance
# from the root cell along the diffusion map graph.
sc.tl.dpt(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the t-SNE embedding, colored by the identified cell clusters.
sc.pl.scatter(adata, basis=""tsne"", color=""louvain"", title=""t-SNE by Cluster"")

# Visualize the t-SNE embedding, colored by the calculated DPT pseudotime.
# This plot shows the progression of cells along the inferred trajectory.
sc.pl.scatter(
    adata, basis=""tsne"", color=[""dpt_pseudotime""], color_map=""gnuplot2"",
    title=""t-SNE colored by Pseudotime""
)

# Create a violin plot to compare the pseudotime distributions across the different cell clusters.
sc.pl.violin(
    adata, keys=[""dpt_pseudotime""], groupby=""louvain"", rotation=45,
    title=""Pseudotime Distribution by Cluster""
)


#--------------------------------
# Data Output
#--------------------------------

# Save the AnnData object, which now contains the DPT trajectory results.
print(""Saving trajectory data object..."")
adata.write(""bone_marrow_dpt_trajectory.h5ad"")

print(""\nPseudotime analysis completed!"")
", https://www.sc-best-practices.org/trajectories/pseudotemporal.html,F
34,scRNA-seq,Trajectory inference,"The primary objective was to infer cellular trajectories and branch-dependent gene expression dynamics from single-cell RNA-seq data. This was accomplished using a graph-based pseudotime ordering strategy with the DDRTree algorithm, implemented with the Monocle2 R package. Starting with a raw gene expression matrix, the analysis involved constructing a CellDataSet object, filtering low-quality genes (expressed in ???10 cells at ???0.1 detection threshold), and selecting trajectory-defining genes via differential expression testing between experimental conditions (q-value < 0.01). Pseudotime ordering was performed using DDRTree dimensionality reduction, followed by branch analysis (BEAM algorithm at branch point 1) to identify genes with expression patterns dependent on lineage commitment (q-value < 1e-4). The results were presented in a trajectory projection colored by pseudotime and experimental conditions to visualize alignment between biological states and inferred progression. These findings were supported by dispersion plots of ordering genes and heatmaps of branch-specific expression patterns, which confirmed the temporal dynamics and bifurcation points in cellular differentiation.","### Methods

#### Data Preprocessing and Normalization
Single-cell RNA sequencing (scRNA-seq) data were processed using the Monocle2 package (version 2.24.0) in R. The gene expression matrix, cell metadata, and gene annotations were imported from tab-delimited files. A CellDataSet (CDS) object was constructed using the expression matrix, with metadata and gene annotations incorporated as AnnotatedDataFrame objects. The expression data were modeled using a negative binomial distribution, suitable for UMI-based scRNA-seq data, with a lower detection limit set to 0.5. Size factors were estimated to normalize the data, and gene dispersions were calculated to account for variability across genes. Low-quality genes were filtered by retaining only those expressed above a minimum threshold of 0.1 in at least 10 cells.

#### Trajectory Inference
Genes for pseudotime ordering were selected by performing differential expression analysis between experimental conditions (e.g., 'Media') using the `differentialGeneTest` function. Genes with a q-value < 0.01 were identified as ordering genes and set in the CDS object. Dimensionality reduction was performed using the DDRTree algorithm, which is optimized for datasets with complex, branching trajectories. Cells were ordered along the inferred trajectory to calculate pseudotime.

#### Differential Expression Analysis
Differential expression along pseudotime was assessed using a natural smoothing spline model (`sm.ns`) to identify genes whose expression changed significantly as a function of pseudotime (q-value < 0.1). Branch-dependent genes were identified using the BEAM (Branch Expression Analysis Modeling) algorithm, focusing on a specified branch point (branch_point = 1) and retaining genes with a q-value < 1e-4.

#### Visualization and Data Output
The dispersion of ordering genes and the inferred trajectory were visualized using Monocle2?€?s plotting functions. Trajectories were colored by pseudotime and experimental conditions to assess their alignment with the inferred progression. Branch-dependent gene expression patterns were plotted along the branched trajectory. The final Monocle object, containing all analysis results, was saved as an RDS file for downstream use.","monocle, ggplot2, Matrix",R,"#--------------------------------
# Package Load
#--------------------------------

# Load required libraries for single-cell trajectory analysis
library(monocle)   # Core package for Monocle2 analysis
library(ggplot2)   # For advanced plotting customization
library(Matrix)    # For handling sparse matrices

#--------------------------------
# Data Input
#--------------------------------

# NOTE: Replace file paths with the actual location of your data files.
# Read the gene expression matrix (rows: genes, columns: cells).
expr_matrix <- read.table(""fpkm_matrix.txt"", header = TRUE, row.names = 1)

# Read the cell metadata sheet.
sample_sheet <- read.delim(""cell_sample_sheet.txt"", header = TRUE, row.names = 1)

# Read the gene annotation file.
gene_annotation <- read.delim(""gene_annotations.txt"", header = TRUE, row.names = 1)


#--------------------------------
# Construct CellDataSet Object
#--------------------------------

# Create AnnotatedDataFrame objects to hold the metadata.
pd <- new(""AnnotatedDataFrame"", data = sample_sheet)
fd <- new(""AnnotatedDataFrame"", data = gene_annotation)

# Create the main CellDataSet (CDS) object, which is Monocle's primary data structure.
# `negbinomial.size()` is a common choice for UMI-based scRNA-seq data.
cds <- newCellDataSet(
  as.matrix(expr_matrix),
  phenoData = pd,
  featureData = fd,
  lowerDetectionLimit = 0.5,
  expressionFamily = negbinomial.size()
)


#--------------------------------
# Preprocessing and Normalization
#--------------------------------

# Estimate size factors for normalization and gene dispersions for downstream analysis.
cds <- estimateSizeFactors(cds)
cds <- estimateDispersions(cds)

# Filter out low-quality genes. First, detect genes expressed above a minimum threshold.
cds <- detectGenes(cds, min_expr = 0.1)

# Then, subset the list to genes that are expressed in at least 10 cells.
expressed_genes <- row.names(subset(fData(cds), num_cells_expressed >= 10))


#--------------------------------
# Major Analysis Tasks: Trajectory Inference
#--------------------------------

# --- Selecting Genes for Ordering ---
# Identify genes that will be used to order cells in pseudotime.
# Here, we perform differential expression between conditions (e.g., 'Media' column).
# Genes that change significantly between conditions are good candidates for ordering.
diff_test_res <- differentialGeneTest(cds[expressed_genes, ], fullModelFormulaStr = ""~Media"")
ordering_genes <- row.names(subset(diff_test_res, qval < 0.01))

# Set the identified ordering genes in the CDS object.
cds <- setOrderingFilter(cds, ordering_genes)


# --- Trajectory Construction ---
# Reduce the dimensionality of the data using the DDRTree algorithm.
# This method is well-suited for datasets with complex, branching trajectories.
cds <- reduceDimension(cds, max_components = 2, method = ""DDRTree"")

# Order the cells along the trajectory to calculate pseudotime.
cds <- orderCells(cds)


# --- Differential Expression Along Pseudotime ---
# Identify genes whose expression changes as a function of pseudotime.
# The `sm.ns` function models expression using a natural smoothing spline.
diff_genes_pseudotime <- differentialGeneTest(cds[expressed_genes, ], fullModelFormulaStr = ""~sm.ns(Pseudotime)"")
sig_genes_pseudotime <- subset(diff_genes_pseudotime, qval < 0.1)

# Print the top genes that vary along the trajectory.
print(""Top genes changing as a function of pseudotime:"")
print(head(sig_genes_pseudotime[order(sig_genes_pseudotime$qval), ]))


# --- Branch Analysis (BEAM) ---
# Identify genes that are differentially expressed at a branch point in the trajectory.
# NOTE: The `branch_point` parameter must be adjusted based on your specific trajectory.
branch_point <- 1
beam_res <- BEAM(cds, branch_point = branch_point, cores = 1)
beam_sig_genes <- row.names(subset(beam_res, qval < 1e-4))


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Visualize the dispersion of the ordering genes.
plot_ordering_genes(cds)

# Plot the main cell trajectory, colored by different variables.
# Color by Pseudotime to see the progression.
plot_cell_trajectory(cds, color_by = ""Pseudotime"")

# Color by experimental condition to see how it maps onto the trajectory.
plot_cell_trajectory(cds, color_by = ""Media"")

# Plot the expression of branch-dependent genes along the branched trajectory.
plot_genes_branched_pseudotime(
    cds[beam_sig_genes, ],
    branch_point = branch_point,
    color_by = ""Pseudotime""
)


#--------------------------------
# Data Output
#--------------------------------

# Save the final Monocle object, which contains all analysis results.
saveRDS(cds, file = ""monocle_trajectory_object.rds"")
",https://cole-trapnell-lab.github.io/monocle-release/docs/#constructing-single-cell-trajectories,F
35,scRNA-seq,Trajectory inference,"The primary objective was to infer the developmental trajectory of *C. elegans* embryonic cells. This was accomplished using a graph-based pseudotime ordering approach, implemented with the Monocle3 R package. Starting with a raw single-cell RNA-seq expression matrix, the analysis involved PCA-based normalization, batch correction using the `align_cds` function, and UMAP dimensionality reduction. Cells were clustered to define cell states before constructing a principal graph representation of differentiation. Pseudotime values were calculated by ordering cells along the trajectory relative to an interactively selected root node. Differential expression along the trajectory was identified through graph-aware statistical testing, with genes filtered using a q-value threshold of <0.05. The results were presented through a UMAP visualization colored by pseudotime to map cellular progression. Expression dynamics of key trajectory-dependent genes were illustrated via pseudotime-dependent line plots with a minimum expression threshold of 0.5. These findings were further supported by a CSV file listing significant genes and an RDS object preserving the complete analysis framework, enabling reproducible investigation of lineage transitions.","### Methods

#### Data Loading and Preprocessing
Single-cell RNA-seq data from *C. elegans* embryos were obtained from publicly available resources. The expression matrix, cell metadata, and gene annotation were loaded into a `cell_data_set` (CDS) object using the `new_cell_data_set` function from the Monocle3 package (v1.0.0). The CDS object serves as the primary data structure for subsequent analyses.

#### Preprocessing and Dimensionality Reduction
The data were preprocessed using the `preprocess_cds` function, which performs normalization and principal component analysis (PCA) with 50 principal components. To account for potential batch effects, batch correction was applied using the `align_cds` function, specifying the batch information from the cell metadata. Uniform Manifold Approximation and Projection (UMAP) was then employed for further dimensionality reduction using the `reduce_dimension` function.

#### Trajectory Inference
Cells were clustered to identify distinct cell states using the `cluster_cells` function. A principal graph representing the developmental trajectory was constructed using the `learn_graph` function. Pseudotime was calculated by ordering cells along the trajectory with the `order_cells` function, with the root node selected interactively to define the starting point of the trajectory.

#### Differential Expression Analysis
Differential expression analysis was performed to identify genes whose expression changes significantly along the trajectory. The `graph_test` function was used with the principal graph as the neighbor graph, and significant genes were filtered based on a q-value threshold of 0.05.

#### Visualization
The developmental trajectory was visualized by plotting cells colored by pseudotime using the `plot_cells` function. Expression trends of the top six significant trajectory-dependent genes were plotted using the `plot_genes_in_pseudotime` function, with a minimum expression threshold of 0.5.

#### Data Output
The results of the differential expression analysis were saved to a CSV file. The final Monocle3 object, containing all analysis results, was saved in RDS format for further use.

All analyses were performed using R (v4.1.0) and the Monocle3 package. Visualization was conducted using ggplot2 (v3.3.5).","monocle3, ggplot2",R,"#--------------------------------
# Package Load
#--------------------------------

# Load required libraries for single-cell trajectory analysis
library(monocle3)  # Core package for Monocle3 analysis
library(ggplot2)   # For advanced plotting customization

#--------------------------------
# Data Input
#--------------------------------

# Load the C. elegans embryo dataset as an example.
# NOTE: Modify these paths if using your own data.
expression_matrix <- readRDS(url(""https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_expression.rds""))
cell_metadata <- readRDS(url(""https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_colData.rds""))
gene_annotation <- readRDS(url(""https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_rowData.rds""))

# Create the main cell_data_set (CDS) object, which is Monocle3's primary data structure.
cds <- new_cell_data_set(
  expression_matrix,
  cell_metadata = cell_metadata,
  gene_metadata = gene_annotation
)


#--------------------------------
# Preprocessing and Dimensionality Reduction
#--------------------------------

# Apply a standard preprocessing workflow to the CDS object.
# This function normalizes, performs PCA, and prepares the data for downstream analysis.
cds <- preprocess_cds(cds, num_dim = 50)

# If the data has multiple batches, correct for batch effects.
# `alignment_group` should point to the column in cell_metadata that specifies the batch.
cds <- align_cds(cds, alignment_group = ""batch"")

# Reduce the dimensionality further using UMAP. The results are stored in the CDS object.
cds <- reduce_dimension(cds)


#--------------------------------
# Major Analysis Tasks: Trajectory Inference
#--------------------------------

# --- Clustering & Trajectory Construction ---
# Cluster cells to identify distinct cell states or types.
cds <- cluster_cells(cds)

# Learn the principal graph that represents the developmental trajectory.
cds <- learn_graph(cds)

# Order the cells along the trajectory to calculate pseudotime.
# Monocle3 will prompt to select root node(s) interactively if not specified.
cds <- order_cells(cds)


# --- Differential Expression Analysis Along Trajectory ---
# Identify genes whose expression changes significantly as cells traverse the learned trajectory.
# `graph_test` is a powerful function for finding trajectory-dependent genes.
graph_test_res <- graph_test(cds, neighbor_graph = ""principal_graph"", cores = 4)

# Filter the results to get genes with a q-value below a significance threshold.
significant_genes <- subset(graph_test_res, q_value < 0.05)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Plot the trajectory, coloring cells by the calculated pseudotime.
# This visualizes the developmental progression of the cells.
plot_cells(
  cds,
  color_cells_by = ""pseudotime"",
  label_cell_groups = FALSE,
  label_leaves = FALSE,
  label_branch_points = FALSE
)

# Plot the expression trends of the top 6 most significant trajectory-dependent genes.
# This helps to understand the molecular changes occurring along the trajectory.
plot_genes_in_pseudotime(
  cds,
  genes = rownames(significant_genes)[1:6],
  min_expr = 0.5
)


#--------------------------------
# Data Output
#--------------------------------

# Save the differential expression results to a CSV file.
write.csv(significant_genes, ""differential_expression_results.csv"")

# Save the final Monocle3 object, which contains all analysis results.
saveRDS(cds, file = ""monocle3_trajectory_object.rds"")
",https://cole-trapnell-lab.github.io/monocle3/docs/trajectories/,F
36,scRNA-seq,Compositional analysis,"

**Analysis Description**  

The primary objective was to identify condition-associated changes in cell type composition within small intestinal epithelial cells. This was accomplished using a Bayesian compositional data analysis approach, implemented with the scCODA framework in the *pertpy* library.  

Starting with an AnnData object containing annotated single-cell RNA-seq data, the analysis involved aggregating cell-level counts to sample-level compositions, specifying a reference cell type (endocrine), and performing Bayesian inference via the No-U-Turn Sampler (NUTS). Significant compositional changes were determined by applying a false discovery rate (FDR) threshold of 0.2.  

The results were presented in a bar plot of log-fold changes relative to the reference cell type to highlight significant condition effects. These findings were further supported by diagnostic boxplots and stacked barplots, which validated the distribution of cell type proportions across conditions.","### Methods

#### Data Preprocessing and Input
The single-cell RNA sequencing dataset from Haber et al. (2017), comprising small intestinal epithelial cells, was utilized for this analysis. The dataset, which includes cell type annotations and condition information, was loaded using the `pertpy` library (`pt.dt.haber_2017_regions()`). The data were stored in an `AnnData` object, a standard format for single-cell analysis, for subsequent processing.

#### Compositional Data Analysis with scCODA
Compositional data analysis was performed using the scCODA (single-cell Compositional Data Analysis) framework implemented in the `pertpy` library. The analysis was conducted as follows:

1. **Data Aggregation and Model Initialization**  
   The cell-level data were aggregated to the sample level using the `sccoda_model.load()` function. This step involved specifying the cell type identifier (`cell_label`), sample identifier (`batch`), and covariates of interest (`condition`). The function automatically generated sample-level compositional data for downstream analysis.

2. **Model Configuration**  
   The scCODA model was configured using the `sccoda_model.prepare()` function. A statistical formula (`formula=""condition""`) was defined to model the effect of the condition on cell type composition. The endocrine cell type was designated as the reference cell type for relative comparisons.

3. **Bayesian Inference**  
   The model was fit using the No-U-Turn Sampler (NUTS), a Bayesian inference algorithm, via the `sccoda_model.run_nuts()` function. A random number generator key (`rng_key=1234`) was set to ensure reproducibility. The model estimated posterior distributions for the effects of the condition on each cell type.

4. **False Discovery Rate (FDR) Control**  
   To identify credible effects, a false discovery rate (FDR) threshold of 0.2 was applied using the `sccoda_model.set_fdr()` function. Significant changes in cell type composition were extracted using the `sccoda_model.credible_effects()` function.

#### Visualization
Several visualization steps were performed to illustrate the results:

1. **Illustrative Example of Compositional Data**  
   A synthetic dataset was created to demonstrate the principles of compositional data analysis. Global cell abundances for healthy and diseased tissue were visualized using bar plots, highlighting changes in cell type proportions.

2. **Diagnostic Plots**  
   Boxplots and stacked barplots were generated to visualize the distribution of cell type counts and proportions across conditions. These plots were created using the `sccoda_model.plot_boxplots()` and `sccoda_model.plot_stacked_barplot()` functions, respectively.

3. **Final Effects Plot**  
   A bar plot of log-fold changes in cell type composition relative to the reference cell type was generated using the `sccoda_model.plot_effects_barplot()` function. This plot highlighted significant changes associated with the condition.

#### Data Output
The analyzed dataset, including the `AnnData` object and scCODA results, was saved in the H5AD file format (`haber_2017_analyzed.h5ad` and `haber_2017_sccoda_results.h5ad`) for future reference and reproducibility.","pandas, numpy, matplotlib, seaborn, scanpy, pertpy",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for data handling, analysis, plotting, and single-cell analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scanpy as sc
import pertpy as pt  # Pertpy includes tools for compositional analysis (scCODA)


#--------------------------------
# Script Configuration
#--------------------------------

# Set global plotting parameters for clear and consistent visualization
sns.set_theme()


#--------------------------------
# Data Input
#--------------------------------

# Load the Haber et al. (2017) dataset of small intestinal epithelial cells.
# This dataset contains cell type labels and condition information suitable for this analysis.
print(""Loading Haber et al. 2017 dataset..."")
adata = pt.dt.haber_2017_regions()
print(""Loaded data shape:"", adata.shape)


#--------------------------------
# Illustrative Example of Compositional Data
#--------------------------------

# This section demonstrates the core concept of compositional data analysis.
print(""\n--- Illustrating Compositional Data Concepts ---"")
# Define example cell counts for three cell types in healthy and diseased tissue.
healthy_tissue = [2000, 2000, 2000]
diseased_tissue = [4000, 2000, 2000] # Note: Cell type A has doubled.

# Create a DataFrame with the total cell counts.
example_data_global = pd.DataFrame(
    data=np.array([healthy_tissue, diseased_tissue]),
    index=[""Healthy"", ""Diseased""],
    columns=[""A"", ""B"", ""C""]
)

# Reshape the DataFrame for easy plotting with seaborn.
plot_data_global = example_data_global.reset_index().melt(
    id_vars=""index"", value_vars=[""A"", ""B"", ""C""],
    var_name=""Cell type"", value_name=""count""
)


#--------------------------------
# Major Analysis Task: Compositional Analysis with scCODA
#--------------------------------

# --- Model and Data Initialization ---
# Instantiate the scCODA model from pertpy.
sccoda_model = pt.tl.Sccoda()

# Load the data into the scCODA model structure.
# This function automatically aggregates cell-level data to the sample level.
print(""\n--- Setting up scCODA Analysis ---"")
sccoda_data = sccoda_model.load(
    adata,
    type=""cell_level"",
    generate_sample_level=True,
    cell_type_identifier=""cell_label"",
    sample_identifier=""batch"",
    covariate_obs=[""condition""],
)
print(""scCODA data modalities:"", sccoda_data)

# --- Model Configuration and Execution ---
# Prepare the data for the model, specifying the statistical formula and a reference cell type.
# The model will calculate changes relative to this reference.
sccoda_data = sccoda_model.prepare(
    sccoda_data,
    modality_key=""coda"",
    formula=""condition"",
    reference_cell_type=""Endocrine""
)

# Run the Bayesian inference sampler (NUTS) to fit the model.
# `rng_key` ensures reproducibility.
print(""\nRunning Bayesian inference model..."")
sccoda_model.run_nuts(sccoda_data, modality_key=""coda"", rng_key=1234)

# Set the False Discovery Rate (FDR) threshold for identifying credible effects.
sccoda_model.set_fdr(sccoda_data, est_fdr=0.2)

# Extract and print the credible effects (significant changes) for each cell type.
credible_effects = sccoda_model.credible_effects(sccoda_data, modality_key=""coda"")
print(""\nCredible Effects (Significant Changes):\n"", credible_effects)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- Illustrative Example Plots ---
# Plot barplots showing the global abundances from the illustrative example.
fig, ax = plt.subplots(1, 2, figsize=(12, 6))
fig.suptitle(""Illustrative Example: Global Cell Abundances"")
sns.barplot(data=plot_data_global, x=""index"", y=""count"", hue=""Cell type"", ax=ax[0])
ax[0].set_title(""Counts by Status"")
sns.barplot(data=plot_data_global, x=""Cell type"", y=""count"", hue=""index"", ax=ax[1])
ax[1].set_title(""Counts by Cell Type"")
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

# --- scCODA Diagnostic Plots ---
# Create boxplots of cell type counts across conditions to visualize distributions.
print(""\n--- Visualizing Compositional Data ---"")
sccoda_model.plot_boxplots(
    sccoda_data,
    modality_key=""coda"",
    feature_name=""condition"",
    figsize=(12, 5),
    add_dots=True,
    args_swarmplot={""palette"": [""red""]},
)
plt.show()

# Create a stacked barplot to show cell type proportions for each condition.
sccoda_model.plot_stacked_barplot(
    sccoda_data,
    modality_key=""coda"",
    feature_name=""condition"",
    figsize=(4, 2)
)
plt.show()

# --- scCODA Final Effects Plot ---
# Generate a bar plot of the final effects. This shows the log-fold changes of cell types
# relative to the reference, highlighting significant changes.
sccoda_model.plot_effects_barplot(sccoda_data, ""coda"", ""condition"")
plt.show()


#--------------------------------
# Data Output
#--------------------------------

# Save the AnnData object and the scCODA results object.
print(""\nSaving results..."")
adata.write(""haber_2017_analyzed.h5ad"")
sccoda_data.write(""haber_2017_sccoda_results.h5ad"")

print(""\nCompositional analysis completed!"")
",https://www.sc-best-practices.org/conditions/compositional.html,F
37,scRNA-seq,Compositional analysis,"

### Analysis Description

**1. Objective & Approach**  
The primary objective was to identify condition-associated changes in cell population abundance between Salmonella-infected and control intestinal epithelial cells. This was accomplished using a neighborhood-based differential abundance framework, implemented with the Milo algorithm via the `pertpy` Python package.

**2. Core Methodology & Rationale**  
Starting with a Haber et al. (2017) single-cell RNA-seq dataset, the analysis involved log-transformation, selection of 3,000 highly variable genes, and PCA-based dimensionality reduction. A k-nearest neighbor graph (10 neighbors, 30 PCs) was used to define cellular neighborhoods, with sample-level cell counts modeled through a generalized linear model (~condition design). Significant abundance changes were determined using FDR thresholds across interconnected neighborhoods.

**3. Result Visualization & Interpretation**  
Results were presented in a neighborhood connectivity graph overlaid on UMAP embeddings to spatialize abundance patterns, complemented by a beeswarm plot showing log-fold changes versus significance across all neighborhoods. These findings were contextualized through condition/batch-colored UMAPs and a neighborhood size histogram, which respectively confirmed dataset structure and analysis granularity. Statistical outputs were preserved in a MuData object for downstream exploration.

*(126 words)*","### Methods

#### Data Preprocessing
The single-cell RNA-seq dataset from Haber et al. (2017) was loaded using the `pertpy` package. Raw counts were preserved in a separate layer for reference, and log-transformed counts were generated using the `numpy.log1p` function to stabilize variance. Highly variable genes were identified using the `scanpy.pp.highly_variable_genes` function, retaining the top 3,000 genes to focus on biologically relevant signals. Principal component analysis (PCA) was performed on the highly variable genes to reduce dimensionality. A k-nearest neighbor (KNN) graph was constructed using 10 neighbors and 30 principal components, and a UMAP embedding was computed for visualization purposes.

#### Differential Abundance Analysis with Milo
The Milo framework, implemented in the `pertpy` package, was used to perform differential abundance (DA) analysis. The preprocessed AnnData object was loaded into the Milo framework, generating a MuData object capable of handling multiple data modalities. Cell neighborhoods were defined using the KNN graph, with 10% of cells sampled as index cells to create overlapping neighborhoods. Cells from each sample (defined by the `batch` column) were counted within each neighborhood to construct a count matrix for DA testing. A neighborhood graph was built to connect overlapping neighborhoods for visualization and analysis. Differential abundance testing was performed using a generalized linear model with the design formula `~condition`, specifically testing for changes between Salmonella-infected and control conditions. Results were extracted and stored for downstream analysis.

#### Visualization
The initial UMAP embedding was visualized, colored by condition and batch, to assess overall data structure. The distribution of neighborhood sizes was plotted as a histogram to evaluate the granularity of the neighborhood partitioning. The neighborhood graph was visualized to illustrate the connectivity between overlapping neighborhoods. A beeswarm plot was generated to display the log-fold change and significance of differential abundance results across all neighborhoods.

#### Data Output
The final MuData object, containing the original dataset and all Milo analysis results, was saved in HDF5 format for further use.

All analyses were performed using Python (v3.x) with the `scanpy`, `pertpy`, `numpy`, `pandas`, `matplotlib`, and `seaborn` packages.","pandas, numpy, matplotlib, seaborn, scanpy, pertpy",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for data handling, analysis, plotting, and single-cell analysis
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scanpy as sc
import seaborn as sns
import pertpy as pt  # Pertpy provides both scCODA and Milo

#--------------------------------
# Data Input & Preprocessing
#--------------------------------

# Load the Haber et al. (2017) dataset.
print(""Loading Haber et al. 2017 dataset..."")
adata = pt.dt.haber_2017_regions()
print(""Loaded data shape:"", adata.shape)

# --- Standard scRNA-seq preprocessing ---
# Save raw counts into a new layer for reference.
adata.layers[""counts""] = adata.X.copy()

# Create log-transformed counts for analysis.
adata.layers[""logcounts""] = np.log1p(adata.layers[""counts""])
adata.X = adata.layers[""logcounts""].copy()

# Identify highly variable genes to focus on biological signal.
sc.pp.highly_variable_genes(adata, n_top_genes=3000, subset=False)

# Perform PCA on the highly variable genes.
sc.pp.pca(adata)

# Construct the k-nearest neighbor (KNN) graph. This is essential for defining neighborhoods.
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=30)

# Compute a UMAP embedding for visualization.
sc.tl.umap(adata)


#--------------------------------
# Major Analysis Task: Differential Abundance with Milo
#--------------------------------

# --- Model and Data Initialization ---
# Instantiate the Milo model from pertpy.
milo = pt.tl.Milo()

# Load the preprocessed AnnData object into the Milo framework.
# This creates a MuData object, which can hold multiple data modalities.
print(""\n--- Setting up Milo Analysis ---"")
mdata = milo.load(adata)

# --- Define Cell Neighborhoods ---
# Define cell neighborhoods based on the KNN graph. These are overlapping groups
# of cells that represent a fine-grained partitioning of the data.
# `prop=0.1` means 10% of cells are sampled as ""index"" cells to define the neighborhoods.
milo.make_nhoods(mdata, prop=0.1)

# --- Count Cells in Neighborhoods ---
# Count the number of cells from each sample ('batch') within each neighborhood.
# This creates the count matrix that will be used for differential abundance testing.
milo.count_nhoods(mdata, sample_col=""batch"")

# --- Build Neighborhood Graph ---
# Create a graph connecting overlapping neighborhoods for visualization and analysis.
milo.build_nhood_graph(mdata)

# --- Differential Abundance Testing ---
# Perform the DA test to compare conditions (e.g., Salmonella vs. Control).
# The design formula `~condition` tells the model to test for changes related to the 'condition' variable.
print(""\nPerforming differential abundance testing..."")
milo.da_nhoods(mdata, design=""~condition"", model_contrasts=""conditionSalmonella-conditionControl"")

# Retrieve the DA results from the Milo object.
milo_results = mdata[""milo""].obs.copy()
print(""\nDifferential Abundance (DA) results (first 5 neighborhoods):"")
print(milo_results.head())


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- UMAP of Raw Data ---
# Visualize the initial UMAP colored by condition and batch to see the overall data structure.
sc.pl.umap(adata, color=[""condition"", ""batch""], ncols=2, wspace=0.4, title=[""Condition"", ""Batch""])

# --- Neighborhood Size Distribution ---
# Plot a histogram of the number of cells in each neighborhood.
print(""\n--- Visualizing Milo Results ---"")
nhood_size = adata.obsm[""nhoods""].toarray().sum(axis=0)
plt.figure(figsize=(6, 4))
plt.hist(nhood_size, bins=20, edgecolor=""black"")
plt.xlabel(""# cells in each neighborhood"")
plt.ylabel(""Number of neighborhoods"")
plt.title(""Distribution of Neighborhood Sizes"")
plt.show()

# --- Neighborhood Graph ---
# Visualize the graph of overlapping neighborhoods.
with plt.rc_context({""figure.figsize"": [10, 10]}):
    milo.plot_nhood_graph(mdata, alpha=0.1, min_size=5, plot_edges=False)
plt.show()

# --- DA Beeswarm Plot ---
# Create a beeswarm plot to visualize the DA results across all neighborhoods.
# This plot shows the log-fold change and significance for each neighborhood.
milo.plot_da_beeswarm(mdata)
plt.show()


#--------------------------------
# Data Output
#--------------------------------

# Save the MuData object, which contains the original data and all Milo results.
print(""\nSaving results..."")
mdata.write(""haber_2017_milo_results.h5mu"")

print(""\nDifferential abundance analysis with Milo completed!"")
",https://www.sc-best-practices.org/conditions/compositional.html,F
38,scRNA-seq,Enrichment analysis,"

**Enrichment Analysis Description**  

**1. Objective & Approach**  
The primary objective was to identify Reactome pathways enriched among differentially expressed genes across experimental conditions and cell types. This was accomplished using gene set enrichment analysis (GSEA) with a normalized enrichment scoring strategy, implemented with the decoupler package in Python.  

**2. Core Methodology & Rationale**  
Starting with raw scRNA-seq counts, the analysis involved library size normalization with Scanpy, log transformation, and selection of highly variable genes (top 4,000). Differential expression was calculated between groups via a t-test (`rank_genes_groups`), and gene-level t-statistics were used as input for GSEA with Reactome gene sets. Pathways were filtered to retain those with 15?€?500 genes, ensuring robust biological interpretation. Final pathway rankings were determined based on normalized enrichment scores.  

**3. Result Visualization & Interpretation**  
The results were summarized in a bar plot of the top 20 enriched pathways to highlight their relative activation levels. These findings were contextualized by UMAP embeddings colored by cell type and condition, which verified the cellular heterogeneity underlying the differential expression. Enrichment scores and pathway metadata were exported to CSV files, enabling reproducible downstream analysis.  

*(Word count: 125)*","### Methods

#### Data Preprocessing
Single-cell RNA sequencing (scRNA-seq) data were processed using the Scanpy toolkit (version X.X.X). Raw counts were normalized to account for differences in library size using the `normalize_total` function, followed by a log transformation (`log1p`) to stabilize variance. Highly variable genes were identified using the Seurat v3 method (`highly_variable_genes`), selecting the top 4,000 genes based on their expression variability across cells. Principal component analysis (PCA) was performed to reduce dimensionality, and a k-nearest neighbor graph was constructed to compute Uniform Manifold Approximation and Projection (UMAP) embeddings for visualization.

#### Differential Expression Analysis
A combined metadata column (`group`) was created by concatenating the experimental condition and cell type annotations. Differential expression analysis was conducted using a t-test (`rank_genes_groups`) to rank genes based on their expression differences across all groups. The results for a specific target group (e.g., ""stim_FCGR3A+ Monocytes"") were extracted, and t-statistics were computed for highly variable genes.

#### Gene Set Enrichment Analysis (GSEA)
Reactome pathway gene sets were obtained from a Gene Matrix Transposed (GMT) file (`c2.cp.reactome.v7.5.1.symbols.gmt`). Gene sets were filtered to retain those containing between 15 and 500 genes to ensure robustness. GSEA was performed using the `decoupler` package (version X.X.X), with gene-level t-statistics as input. Pathway enrichment scores were normalized, and the top 20 enriched pathways were visualized using a bar plot.

#### Data Visualization and Output
UMAP embeddings were plotted to visualize the data structure, colored by condition and cell type. GSEA results, including normalized enrichment scores, were saved to a CSV file (`gsea_results.csv`). The processed AnnData object, containing differential expression results, was saved for further analysis (`kang_processed_with_de.h5ad`).

All analyses were conducted in Python (version X.X.X), using standard bioinformatics libraries and reproducible workflows.","numpy, pandas, scanpy, decoupler, matplotlib, seaborn",python,"#!/usr/bin/env python
""""""
Example script for gene set enrichment and pathway analysis for single?€?cell RNA?€?seq data.
This script reads an AnnData object, preprocesses the data, performs a t?€?test to rank genes,
extracts DE t-statistics for a selected cell type/condition, loads a Reactome GMT file, runs GSEA via decoupler,
and plots the top enriched pathways.
""""""

#------------------------------------------------------------------------------#
#                           Import necessary modules                           #
#------------------------------------------------------------------------------#
from __future__ import annotations
import os
from pathlib import Path
import numpy as np
import pandas as pd
import scanpy as sc
import decoupler
import matplotlib.pyplot as plt
import seaborn as sns

#------------------------------------------------------------------------------#
#                           Script Configuration                               #
#------------------------------------------------------------------------------#
# Set global parameters for plotting and figure aesthetics
sns.set(style=""whitegrid"")
sc.settings.set_figure_params(dpi=200, frameon=False, figsize=(4, 4))

#------------------------------------------------------------------------------#
#                              Data Input                                      #
#------------------------------------------------------------------------------#
# Read the PBMC dataset from a .h5ad file.
# A backup URL is provided for reproducibility if the file is not found locally.
adata = sc.read(
    ""kang_counts_25k.h5ad"",
    backup_url=""https://figshare.com/ndownloader/files/34464122""
)

# Save the raw counts in a separate layer for later use, a common best practice.
adata.layers[""counts""] = adata.X.copy()

# Rename the ""label"" column to ""condition"" for better clarity in downstream steps.
adata.obs = adata.obs.rename(columns={""label"": ""condition""})

#------------------------------------------------------------------------------#
#                           Data Preprocessing                                 #
#------------------------------------------------------------------------------#
# --- Normalization and Feature Selection ---
# Normalize total counts per cell and apply a log transformation.
sc.pp.normalize_total(adata)
sc.pp.log1p(adata)

# Identify the top 4000 highly variable genes using the ""seurat_v3"" method.
# `layer=""counts""` ensures this is calculated on the untransformed data.
sc.pp.highly_variable_genes(
    adata,
    n_top_genes=4000,
    flavor=""seurat_v3"",
    subset=False,
    layer=""counts""
)

# --- Dimensionality Reduction for Visualization ---
# Compute PCA, build a neighbor graph, and generate a UMAP representation.
sc.pp.pca(adata)
sc.pp.neighbors(adata)
sc.tl.umap(adata)

#------------------------------------------------------------------------------#
#                   Major Analysis Task: Enrichment Analysis                   #
#------------------------------------------------------------------------------#

# --- 1. Differential Expression Analysis ---
# Create a combined 'group' column (e.g., ""stim_FCGR3A+ Monocytes"") to perform
# DE analysis on specific cell type/condition combinations.
adata.obs[""group""] = adata.obs[""condition""].astype(str) + ""_"" + adata.obs[""cell_type""]

# Run a t-test to rank genes based on differential expression across all groups.
sc.tl.rank_genes_groups(adata, groupby=""group"", method=""t-test"", key_added=""t-test"")

# Define the target group for GSEA and extract its DE results.
target_group = ""stim_FCGR3A+ Monocytes""
de_df = sc.get.rank_genes_groups_df(adata, group=target_group, key=""t-test"")

# Filter for highly variable genes and create a DataFrame of t-statistics.
hvg_genes = adata.var_names[adata.var[""highly_variable""]]
t_stats = de_df.set_index(""names"").loc[hvg_genes].sort_values(""scores"", key=np.abs, ascending=False)[[""scores""]]
t_stats = t_stats.rename(columns={""scores"": target_group})

# --- 2. Prepare Pathway Gene Sets (Reactome GMT) ---
# Define the path for the GMT file and download if it doesn't exist.
gmt_path = Path(""c2.cp.reactome.v7.5.1.symbols.gmt"")
if not gmt_path.is_file():
    os.system(""wget -O c2.cp.reactome.v7.5.1.symbols.gmt https://figshare.com/ndownloader/files/35233771"")

def gmt_to_decoupler(pth: Path) -> pd.DataFrame:
    """"""Parse a GMT file into a long-format DataFrame compatible with decoupler.""""""
    pathways = {}
    with pth.open(""r"") as f:
        for line in f:
            parts = line.strip().split(""\t"")
            name, _, *genes = parts
            pathways[name] = genes
    # Convert dictionary to a long-format DataFrame
    return pd.DataFrame(
        [(gene_set, gene) for gene_set, genes in pathways.items() for gene in genes],
        columns=[""geneset"", ""genesymbol""]
    )

# Parse the GMT file and filter gene sets by size for robustness.
reactome = gmt_to_decoupler(gmt_path)
geneset_size = reactome.groupby(""geneset"").size()
gsea_genesets = geneset_size.index[(geneset_size > 15) & (geneset_size < 500)]
reactome_filtered = reactome[reactome[""geneset""].isin(gsea_genesets)]

# --- 3. Run GSEA with Decoupler ---
# Run GSEA using the gene-level t-statistics and the filtered Reactome pathways.
scores, norm, pvals = decoupler.run_gsea(
    mat=t_stats.T,
    net=reactome_filtered,
    source=""geneset"",
    target=""genesymbol""
)

# Combine the GSEA results into a single, sorted DataFrame.
gsea_results = pd.concat({
    ""score"": scores.T,
    ""norm_score"": norm.T,
#    ""pval"": pvals.T
#}, axis=1).droplevel(level=1, axis=1).sort_values(""pval"")
}, axis=1).droplevel(level=1, axis=1).sort_values(""norm_score"", ascending=False)
gsea_results.index.name = ""Pathway""

#------------------------------------------------------------------------------#
#                              Plotting / Visualization                        #
#------------------------------------------------------------------------------#
# Plot UMAP embeddings colored by condition and cell type to visualize the data structure.
sc.pl.umap(adata, color=[""condition"", ""cell_type""], frameon=False, ncols=2)

# Plot the top 20 enriched pathways based on their normalized enrichment score.
top20 = gsea_results.head(20).reset_index()

plt.figure(figsize=(10, 8))
sns.barplot(data=top20, x=""norm_score"", y=""Pathway"", palette=""viridis"")
plt.xlabel(""Normalized Enrichment Score"")
plt.ylabel(""Pathway"")
plt.title(f""Top 20 Enriched Pathways in {target_group}"")
plt.tight_layout()
plt.show()

#------------------------------------------------------------------------------#
#                              Data Output                                     #
#------------------------------------------------------------------------------#
# Save the final GSEA results to a CSV file.
print(""\nSaving GSEA results..."")
gsea_results.to_csv(""gsea_results.csv"")

# Save the AnnData object containing the DE analysis results.
adata.write(""kang_processed_with_de.h5ad"")

print(""\nGene set enrichment analysis completed!"")
",https://www.sc-best-practices.org/conditions/gsea_pathway.html,F
39,scRNA-seq,Cell-cell communication,"

The primary objective was to identify significant ligand-receptor (LR) interactions mediating communication between immune cell subsets. This was accomplished using a ligand-receptor database scoring strategy, implemented with the LIANA framework and CellPhoneDB method in Python. Starting with the Kang et al. PBMC single-cell dataset, the analysis involved preprocessing with scanpy to filter cells (<200 genes) and genes (<3 cell detections), normalize counts, and apply log1p transformation. LIANA was executed on normalized data to score LR pairs between predefined source (CD4 T cells, B cells, monocytes) and target (CD8 T cells, NK cells) populations. Significant interactions were filtered using a p-value threshold ??? 0.01 via the `cellphone_pvals` metric. The results were visualized in a dot plot where color intensity represented mean LR expression (li.pl.dotplot) and dot size inversely reflected interaction significance. These findings were supported by a CSV file listing top interactions and preservation of results in the AnnData object for downstream analysis, ensuring reproducibility.","### Methods

#### Data Loading and Preprocessing
The single-cell transcriptomics dataset from Kang et al. (PBMC dataset) was loaded using the `scanpy` library (`sc.read`) in Python. Raw counts were stored in a separate layer (`adata.layers[""counts""]`) to preserve the original data prior to normalization. Quality control was performed to remove low-quality cells and genes. Cells expressing fewer than 200 genes and genes detected in fewer than 3 cells were filtered out using `sc.pp.filter_cells` and `sc.pp.filter_genes`, respectively. Normalization was applied by scaling each cell?€?s total counts to 10,000 (`sc.pp.normalize_total`), followed by a log1p transformation (`sc.pp.log1p`) to stabilize variance.

#### Ligand-Receptor Interaction Analysis
Ligand-receptor (LR) interactions were inferred using the `LIANA` framework, specifically the `CellPhoneDB` method. The analysis focused on predefined cell populations of interest: CD4 T cells, B cells, and FCGR3A+ Monocytes as sender (source) cell types, and CD8 T cells and NK cells as receiver (target) cell types. The `cellphonedb` function was executed with the following parameters: `groupby=""cell_type""` to specify the cell type annotations, `use_raw=False` to use the normalized data, and `return_all_lrs=True` to return all potential LR pairs. Interactions were considered significant if their p-value was ??? 0.01, as determined by the `cellphone_pvals` metric.

#### Visualization and Data Output
Significant LR interactions were visualized using a dot plot generated with the `li.pl.dotplot` function. Dot color represented the mean expression of the LR pair (`colour=""lr_means""`), while dot size inversely corresponded to the p-value (`size=""cellphone_pvals""`, `inverse_size=True`). The plot was filtered to include only interactions between the specified source and target cell types (`source_labels` and `target_labels`) and displayed the top 20 interactions based on mean expression (`top_n=20`). Significant interaction results were saved to a CSV file (`liana_significant_interactions.csv`), and the processed `AnnData` object, including LIANA results stored in the `.uns` slot, was saved for further analysis (`kang_processed_with_liana.h5ad`).","scanpy, liana, decoupler, matplotlib, seaborn, pandas, numpy",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for data handling, analysis, plotting, and single-cell analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scanpy as sc
import liana as li  # For ligand-receptor interaction inference

#--------------------------------
# Data Input
#--------------------------------

# Load the single-cell transcriptomics dataset.
# A backup URL is provided for reproducibility.
print(""Loading Kang et al. PBMC dataset..."")
adata = sc.read(
    ""kang_counts_25k.h5ad"",
    backup_url=""https://figshare.com/ndownloader/files/34464122""
)

# Store the raw counts in a separate layer before normalization.
adata.layers[""counts""] = adata.X.copy()

#--------------------------------
# Preprocessing & Quality Control
#--------------------------------

# Apply basic quality control filters to remove low-quality cells and genes.
print(""Performing quality control..."")
sc.pp.filter_cells(adata, min_genes=200)
sc.pp.filter_genes(adata, min_cells=3)

# Normalize each cell by total counts and apply a log transformation.
# This is a standard preprocessing pipeline for many single-cell analyses.
sc.pp.normalize_total(adata)
sc.pp.log1p(adata)

#--------------------------------
# Major Analysis Task: Ligand-Receptor Interaction Analysis
#--------------------------------

# --- Define Cell Populations of Interest ---
# Specify the cell types that will act as senders (source) and receivers (target)
# in the communication analysis.
source_cell_types = [""CD4 T cells"", ""B cells"", ""FCGR3A+ Monocytes""]
target_cell_types = [""CD8 T cells"", ""NK cells""]

# --- Run LIANA with CellPhoneDB Method ---
# Use the CellPhoneDB method within the LIANA framework to infer interactions.
# `groupby=""cell_type""` specifies the column with cell annotations.
# `use_raw=False` indicates that the normalized data in `adata.X` should be used.
print(""\nRunning ligand-receptor interaction analysis with CellPhoneDB..."")
from liana.method import cellphonedb
cellphonedb(
    adata,
    groupby=""cell_type"",
    use_raw=False,
    return_all_lrs=True,
    verbose=True
)

# --- Filter and Extract Results ---
# The results are stored in the `adata.uns['liana_res']` slot.
results = adata.uns[""liana_res""]

# Filter for significant ligand-receptor interactions based on the p-value.
significant_results = results[results[""cellphone_pvals""] <= 0.01]
print(f""\nFound {len(significant_results)} significant interactions (p-value <= 0.01)."")


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Generate a dot plot to visualize the top significant ligand-receptor interactions.
# - `colour`: The color of the dots represents the mean expression of the LR pair.
# - `size`: The size of the dots represents the significance (p-value).
# - `source_labels` & `target_labels`: Filter the plot to show interactions between specific cell types.
# - `top_n`: Display the top 20 interactions based on mean expression.
print(""\nGenerating dot plot of top interactions..."")
li.pl.dotplot(
    adata=adata,
    colour=""lr_means"",
    size=""cellphone_pvals"",
    inverse_size=True,  # Make smaller p-values correspond to larger dots
    source_labels=source_cell_types,
    target_labels=target_cell_types,
    filterby=""cellphone_pvals"",
    filter_lambda=lambda x: x <= 0.01,
    orderby=""lr_means"",
    orderby_ascending=False,
    top_n=20,
    figure_size=(9, 5),
    size_range=(1, 6)
)
plt.show()

#--------------------------------
# Data Output
#--------------------------------

# Save the significant interaction results to a CSV file for further inspection.
print(""\nSaving significant interaction results..."")
significant_results.to_csv(""liana_significant_interactions.csv"")

# Save the AnnData object, which now contains the LIANA results in the .uns slot.
adata.write(""kang_processed_with_liana.h5ad"")

print(""\nLigand-receptor interaction analysis completed!"")
",https://www.sc-best-practices.org/mechanisms/cell_cell_communication.html,F
40,scRNA-seq,Cell-cell communication,"The primary objective was to identify condition-associated changes in cell type composition within small intestinal epithelial cells. This was accomplished using a Bayesian compositional data analysis approach, implemented with the scCODA framework in the *pertpy* library. Starting with an AnnData object containing annotated single-cell RNA-seq data, the analysis involved aggregating cell-level counts to sample-level compositions, specifying a reference cell type (endocrine), and performing Bayesian inference via the No-U-Turn Sampler (NUTS). Significant compositional changes were determined by applying a false discovery rate (FDR) threshold of 0.2. The results were presented in a bar plot of log-fold changes relative to the reference cell type to highlight significant condition effects. These findings were further supported by diagnostic boxplots and stacked barplots, which validated the distribution of cell type proportions across conditions.","### Methods

#### Data Loading  
The `pbmc68k_reduced` dataset, a publicly available single-cell RNA sequencing dataset of peripheral blood mononuclear cells (PBMCs), was loaded using the `scanpy` Python package (`v1.X.X`). This dataset was chosen as it provides a preprocessed and annotated example for single-cell analysis.

#### Ligand-Receptor Interaction Analysis  
Ligand-receptor (LR) interactions were inferred using the `LIANA` framework (`vX.X.X`), specifically employing the `CellPhoneDB` method. The analysis was performed on the annotated single-cell data, with cell types specified in the `bulk_labels` column. A curated list of LR pairs from the `consensus` resource was used. Interactions were filtered to include only those where ligands and receptors were expressed in at least 10% of the cells (`expr_prop=0.1`). Results were stored in the `.uns` slot of the `AnnData` object under the key `cpdb_res`.

#### Visualization  
To visualize the cell type composition, a UMAP plot was generated using the `scanpy` package, with cells colored by their `bulk_labels` annotations. Significant LR interactions were visualized using two complementary plots:  
1. **Dot Plot**: A dot plot was generated to display the top LR interactions, with dot color representing the interaction score (`lr_means`) and dot size inversely proportional to the statistical significance (`cellphone_pvals`). Only interactions with p-values ??? 0.05 were included.  
2. **Tile Plot**: A tile plot was created to show detailed expression statistics for the top 10 interactions, ordered by ascending p-values. The tile fill represented the mean expression (`means`), and labels indicated the proportion of expressing cells (`props`), formatted to two decimal places.  

#### Data Output  
The annotated `AnnData` object, including the LR interaction results, was saved in H5AD format (`pbmc68k_with_liana_results.h5ad`) for further analysis and reproducibility.  

All analyses were performed using Python (`v3.X.X`) with the `scanpy`, `LIANA`, and `matplotlib` libraries.","scanpy, liana, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for data handling, analysis, plotting, and single-cell analysis
import scanpy as sc
import liana as li
import matplotlib.pyplot as plt

#--------------------------------
# Data Input
#--------------------------------

# Load the pbmc68k_reduced dataset, a built-in example from Scanpy.
print(""Loading pbmc68k_reduced dataset..."")
adata = sc.datasets.pbmc68k_reduced()

#--------------------------------
# Major Analysis Task: Ligand-Receptor Interaction Analysis
#--------------------------------

# --- Run LIANA with CellPhoneDB Method ---
# Use the CellPhoneDB method within the LIANA framework to infer interactions.
# `groupby='bulk_labels'` specifies the column with cell annotations.
# `resource_name='consensus'` uses a curated list of LR pairs.
# `key_added='cpdb_res'` stores the results in the .uns slot of the AnnData object.
print(""\nRunning ligand-receptor interaction analysis with CellPhoneDB..."")
li.cellphonedb(
    adata,
    groupby='bulk_labels',
    resource_name='consensus',
    expr_prop=0.1,  # Minimum fraction of cells required to express ligand/receptor
    verbose=True,
    key_added='cpdb_res'
)

# --- Inspect Results ---
# Print the first few rows of the result DataFrame to check the output.
print(""\nCellPhoneDB Results (first 5 rows):"")
print(adata.uns['cpdb_res'].head())


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- UMAP of Cell Clusters ---
# Visualize the cell clusters to get an overview of the data structure.
sc.pl.umap(adata, color='bulk_labels', title='UMAP of PBMC68k Cell Types', frameon=False)

# --- Dot Plot of Top Interactions ---
# Generate a dot plot to visualize significant ligand-receptor interactions.
# - Color represents the interaction score (lr_means).
# - Size represents the statistical significance (p-value).
print(""\nGenerating dot plot of top interactions..."")
li.pl.dotplot(
    adata=adata,
    colour='lr_means',
    size='cellphone_pvals',
    inverse_size=True,  # Smaller p-values result in larger dots
    source_labels=['CD34+', 'CD56+ NK', 'CD14+ Monocyte'],
    target_labels=['CD34+', 'CD56+ NK'],
    figure_size=(8, 7),
    filter_fun=lambda x: x['cellphone_pvals'] <= 0.05,  # Filter for significant interactions
    uns_key='cpdb_res'
)
plt.show()

# --- Tile Plot of Expression Statistics ---
# Generate a tile plot to show detailed expression statistics (mean expression and
# proportion of expressing cells) for the top 10 interactions.
print(""\nGenerating tile plot of expression statistics..."")
li.pl.tileplot(
    adata=adata,
    fill='means',
    label='props',
    label_fun=lambda x: f'{x:.2f}',
    top_n=10,
    orderby='cellphone_pvals',
    orderby_ascending=True,
    source_labels=['CD34+', 'CD56+ NK', 'CD14+ Monocyte'],
    target_labels=['CD34+', 'CD56+ NK'],
    uns_key='cpdb_res',
    source_title='Ligand',
    target_title='Receptor',
    figure_size=(8, 7)
)
plt.show()

#--------------------------------
# Data Output
#--------------------------------

# Save the AnnData object, which now contains the LIANA results in the .uns slot.
print(""\nSaving annotated data object..."")
adata.write(""pbmc68k_with_liana_results.h5ad"")

print(""\nLigand-receptor interaction analysis completed!"")
",https://liana-py.readthedocs.io/en/latest/notebooks/basic_usage.html,F
41,scRNA-seq,Cell-cell communication,"The primary objective was to identify **context-specific cell-cell communication patterns** across conditions. This was accomplished using **tensor decomposition of ligand-receptor interactions**, implemented with the **liana** and **cell2cell** Python packages. Starting with **single-cell RNA-seq data post-QC**, the analysis involved **normalization, log-transformation, and ligand-receptor (LR) inference via rank aggregation** against a consensus LR database. A **4D communication tensor** (contexts ?? senders ?? receivers ?? LR pairs) was constructed and decomposed via **regularized tensor factorization** (rank=6) to extract latent interaction patterns. Final communication modules were derived based on **factor contributions and magnitude-based LR rankings**. The results were presented in **UMAP embeddings** (colored by condition/cell type) and **tensor factor plots** to illustrate **context-specific communication dynamics**. These findings were further supported by **interaction network visualizations** (e.g., Factor 6) and **exported tensor decomposition outputs**, which captured distinct sender-receiver-LR relationships underlying biological conditions.  ","### Methods

#### Data Preprocessing and Quality Control  
Single-cell RNA-seq data from the Kang et al. 2018 dataset were loaded and processed using the `scanpy` (v1.9.0) and `liana` (v0.1.0) Python packages. Quality control was performed by filtering cells with fewer than 200 detected genes and genes expressed in fewer than 3 cells. To correct for differences in library size, data were normalized using the `scanpy.pp.normalize_total` function, followed by log transformation (`scanpy.pp.log1p`) to stabilize variance.

#### Ligand-Receptor Interaction Inference  
Ligand-receptor (LR) interactions were inferred using `liana.mt.rank_aggregate.by_sample`, which applies a rank aggregation method to identify LR pairs within each sample. A consensus database of LR pairs was used as the reference resource. The analysis was performed at the cell type level, as defined by the `cell_type` metadata column. The results, including magnitude-based rankings of LR interactions, were stored in the AnnData object for downstream analysis.

#### Tensor Construction and Decomposition  
To model cell-cell communication, a multi-dimensional communication tensor was constructed using `liana.multi.to_tensor_c2c`. The tensor represented interactions across contexts, sender cells, receiver cells, and LR pairs. Tensor decomposition was performed using the `cell2cell.analysis.run_tensor_cell2cell_pipeline` function with a rank of 6 to extract latent communication patterns. The decomposition was optimized using a regular tensor factorization approach, and computations were executed on the CPU.

#### Visualization  
The overall structure of the data was visualized using Uniform Manifold Approximation and Projection (UMAP) embeddings, colored by condition and cell type. Tensor decomposition results were plotted to display the extracted communication factors, each representing distinct patterns of interaction across contexts, senders, receivers, and LR pairs. Additionally, cell-cell communication networks associated with specific factors (e.g., Factor 6) were visualized using `cell2cell.plotting.ccc_networks_plot`.

#### Data Output  
The final AnnData object, including LR interaction results, was saved in H5AD format. The communication tensor and decomposition results were exported to a `.c2c` file for further analysis. Visualization outputs, including tensor factor plots, were saved as high-resolution PNG images (300 dpi).","pandas, scanpy, liana, decoupler, cell2cell, seaborn, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for data handling, analysis, plotting, and single-cell analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scanpy as sc
import liana as li
import decoupler as dc
import cell2cell as c2c
import warnings

#--------------------------------
# Script Configuration
#--------------------------------

# Suppress warnings for a cleaner output during execution
warnings.filterwarnings('ignore')

#--------------------------------
# Data Input
#--------------------------------

# Load a sample dataset. Here we use a built-in dataset from LIANA's testing suite.
# NOTE: Replace this with your own data as needed.
print(""Loading Kang et al. 2018 dataset..."")
adata = li.testing.datasets.kang_2018()

#--------------------------------
# Preprocessing & Quality Control
#--------------------------------

# Apply basic quality control filters.
print(""Performing quality control and preprocessing..."")
sc.pp.filter_cells(adata, min_genes=200)
sc.pp.filter_genes(adata, min_cells=3)

# Normalize and log-transform the data.
sc.pp.normalize_total(adata)
sc.pp.log1p(adata)

#--------------------------------
# Major Analysis Tasks
#--------------------------------

# --- 1. Ligand-Receptor Inference by Sample ---
# Define keys for sample, condition, and cell type columns in adata.obs.
sample_key = 'sample'
condition_key = 'condition'
groupby = 'cell_type'

# Run LIANA's rank aggregation method for each sample individually.
# This infers ligand-receptor interactions within each sample before downstream analysis.
print(""\nRunning ligand-receptor inference for each sample..."")
liana_results = li.mt.rank_aggregate.by_sample(
    adata,
    groupby=groupby,
    resource_name='consensus',  # Use a consensus database of LR pairs
    sample_key=sample_key,
    use_raw=False,
    verbose=True,
    n_perms=None, # Set to an integer (e.g., 1000) for permutation testing
    return_all_lrs=True
)

# Store the LIANA results in the AnnData object.
adata.uns[""liana_res""] = liana_results

# Display the top-ranked interactions.
print(""\nTop aggregated ligand-receptor interactions:"")
print(adata.uns[""liana_res""].sort_values(""magnitude_rank"").head())

# --- 2. Tensor Decomposition for Communication Analysis ---
# Construct a communication tensor. This is a multi-dimensional array representing
# interactions (Context x Sender x Receiver x LR-pair).
print(""\nConstructing communication tensor..."")
tensor = li.multi.to_tensor_c2c(
    adata,
    sample_key=sample_key,
    score_key=""magnitude_rank"",
    how=""outer_cells"" # Use all cells for tensor construction
)

# Perform tensor decomposition to identify latent communication patterns (factors).
# `rank=6` specifies the number of factors to extract.
print(""\nPerforming tensor decomposition..."")
tensor = c2c.analysis.run_tensor_cell2cell_pipeline(
    tensor,
    copy_tensor=True,
    rank=6,
    tf_optimization='regular',
    random_state=0,
    device=""cpu"" # Use 'cuda' if a GPU is available
)

#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- UMAP Visualization ---
# Plot a UMAP to visualize the overall structure of the data by condition and cell type.
print(""\n--- Visualizing Results ---"")
sc.pl.umap(adata, color=[condition_key, groupby], frameon=False)

# --- Tensor Factor Plots ---
# Visualize the results of the tensor decomposition. Each factor represents a
# distinct communication pattern across contexts, senders, receivers, and LR pairs.
factors, axes = c2c.plotting.tensor_factors_plot(
    interaction_tensor=tensor,
    fontsize=10
)
plt.show()

# --- Communication Network Plots ---
# Visualize the cell-cell communication networks for specific factors.
# Here, we plot the network associated with 'Factor 6' as an example.
c2c.plotting.ccc_networks_plot(factors, included_factors=['Factor 6'])
plt.show()

#--------------------------------
# Data Output
#--------------------------------

# Save the final plots and data objects.
print(""\nSaving results..."")
# Save the tensor factor plot
factors[0].figure.savefig(""tensor_factors_plot.png"", dpi=300, bbox_inches='tight')
# Save the AnnData object with LIANA results
adata.write(""kang_2018_with_liana.h5ad"")
# Save the tensor object with decomposition results
c2c.io.export_variable_to_file(tensor, 'communication_tensor.c2c')

print(""\nTensor-based communication analysis completed!"")
",https://liana-py.readthedocs.io/en/latest/notebooks/liana_c2c.html,F
42,scRNA-seq,Cell-cell communication,"The primary objective was to identify deregulated ligand-receptor (LR) interactions and transcription factor (TF) activity changes across cell types under experimental conditions. This was accomplished using pseudobulk differential expression analysis (DEA) and consensus LR interaction scoring, implemented with PyDESeq2 and the LIANA framework in Python. Starting with processed single-cell RNA-seq data, the analysis involved generating pseudobulk profiles per cell type/sample, excluding low-quality samples (<10 cells or <10k counts). Differential expression was tested using PyDESeq2, filtering genes with counts <5 and applying log-fold shrinkage. Deregulated LR pairs were identified via LIANA, integrating DEA statistics (p-value, adjusted p-value) and filtering for expression proportion >0.1. TF activity was inferred using the decoupler package with the Omnipath CollecTRI regulatory network. Final results were prioritized by interaction statistics (LR) and TF activity magnitudes, with significance defined as adjusted p-value <0.05. The results were presented in a UMAP embedding colored by experimental condition and cell type to illustrate overall data structure. Deregulated LR interactions were visualized in a tile plot, highlighting expression levels and significance (asterisks: adjusted p-value <0.05). These findings were supported by CSV outputs of DEA statistics, LR interactions, and TF activity estimates, alongside a saved AnnData object for reproducibility. ","### Methods

#### Data Preprocessing and Quality Control
Single-cell RNA sequencing data from the Kang et al. (2018) dataset were processed using the Scanpy framework. Cells expressing fewer than 200 genes and genes detected in fewer than 3 cells were filtered out to ensure data quality. Normalization was performed to correct for differences in library size, with counts scaled to a target sum of 10,000 per cell. The data were then log-transformed (log1p) for downstream analysis.

#### Pseudobulk and Differential Expression Analysis
Pseudobulk profiles were generated by summing raw counts for each cell type within each sample, using the `decoupler` package. Samples with fewer than 10 cells or fewer than 10,000 total counts were excluded. Differential expression analysis (DEA) was performed using PyDESeq2 for each cell type. Lowly expressed genes were filtered out using a minimum count threshold of 5 and a minimum total count threshold of 10. The DESeq2 model was applied with the experimental condition as the design factor, and the control condition (`ctrl`) was set as the reference. Log-fold changes were shrunk using the `lfcShrink` function to improve robustness. Differential expression results were concatenated into a single DataFrame for downstream analysis.

#### Deregulated Ligand-Receptor Interaction Analysis
Deregulated ligand-receptor (LR) interactions were identified using the LIANA framework. The consensus resource was used to define LR pairs, and interactions were filtered based on an expression proportion threshold of 0.1. Differential expression statistics (statistic, p-value, and adjusted p-value) were incorporated to assess the significance of LR interactions. Results were sorted by interaction statistic for prioritization.

#### Pathway Enrichment Analysis
Transcription factor (TF) activity changes were inferred using the Univariate Linear Model (ULM) implemented in the `decoupler` package. A TF-target regulatory network was obtained from the Omnipath CollecTRI resource. Differential expression statistics were pivoted into a wide format (cells ?? genes) and used as input to estimate TF activities. Top TFs associated with specific cell types (e.g., CD14 monocytes) were identified based on the magnitude of their activity estimates.

#### Visualization
A UMAP embedding was generated to visualize the overall structure of the data, with cells colored by experimental condition, sample, cell type, and abbreviated cell type. The top 15 deregulated LR interactions were visualized using a tile plot, where fill color represented expression levels and asterisks indicated statistical significance (adjusted p-value < 0.05).

#### Data Output
Key results, including differential expression statistics, deregulated LR interactions, and TF activity estimates, were saved as CSV files. The processed AnnData object was saved in H5AD format for further analysis.

This pipeline provides a comprehensive workflow for single-cell data analysis, integrating pseudobulk DEA, LR interaction analysis, and pathway enrichment to uncover biologically relevant insights.","numpy, pandas, scanpy, plotnine, liana, decoupler, omnipath, pydeseq2",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for data handling, analysis, plotting, and single-cell analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scanpy as sc
import liana as li
import decoupler as dc
import omnipath as op
from pydeseq2.dds import DeseqDataSet
from pydeseq2.ds import DeseqStats
import warnings

#--------------------------------
# Script Configuration
#--------------------------------

# Suppress warnings for a cleaner output during execution
warnings.filterwarnings('ignore')

#--------------------------------
# Data Input
#--------------------------------

# Load a sample dataset. Here we use a built-in dataset from LIANA's testing suite.
# NOTE: Replace this with your own data as needed.
print(""Loading Kang et al. 2018 dataset..."")
adata = li.testing.datasets.kang_2018()

#--------------------------------
# Preprocessing & Quality Control
#--------------------------------

# Apply basic quality control filters.
print(""Performing quality control and preprocessing..."")
sc.pp.filter_cells(adata, min_genes=200)
sc.pp.filter_genes(adata, min_cells=3)

# Normalize and log-transform data for visualization and some downstream steps.
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)

#--------------------------------
# Major Analysis Tasks
#--------------------------------

# Define metadata columns of interest for the analysis
sample_key = 'sample'
condition_key = 'condition'
groupby = 'cell_abbr' # Using abbreviated cell types for clarity

# --- 1. Pseudobulk and Differential Expression Analysis (DEA) ---
# Generate pseudobulk profiles by summing counts for each cell type within each sample.
print(""\nGenerating pseudobulk profiles..."")
pdata = dc.get_pseudobulk(
    adata,
    sample_col=sample_key,
    groups_col=groupby,
    layer='counts', # Use raw counts for DESeq2
    mode='sum',
    min_cells=10,
    min_counts=10000
)

# Perform DEA using PyDESeq2 for each cell type.
print(""\nPerforming differential expression analysis with PyDESeq2..."")
dea_results = {}
for cell_group in pdata.obs[groupby].unique():
    # Subset pseudobulk data to the current cell type
    ctdata = pdata[pdata.obs[groupby] == cell_group].copy()

    # Filter out lowly expressed genes for the current cell type
    genes = dc.filter_by_expr(ctdata, group=condition_key, min_count=5, min_total_count=10)
    ctdata = ctdata[:, genes].copy()

    # Build and run the DESeq2 model
    dds = DeseqDataSet(
        adata=ctdata,
        design_factors=condition_key,
        ref_level=[condition_key, 'ctrl'], # Set 'ctrl' as the reference condition
        refit_cooks=True,
        quiet=True
    )
    dds.deseq2()

    # Get statistics and shrink log-fold changes for robustness
    stat_res = DeseqStats(dds, contrast=[condition_key, 'stim', 'ctrl'])
    stat_res.summary()
    stat_res.lfc_shrink(coeff='condition_stim_vs_ctrl')

    dea_results[cell_group] = stat_res.results_df

# Concatenate all DEA results into a single DataFrame.
dea_df = pd.concat(dea_results).reset_index().rename(
    columns={'level_0': groupby, 'level_1': 'gene'}
).set_index('gene')


# --- 2. Deregulated Ligand-Receptor Interaction Analysis ---
# Use LIANA to identify LR interactions that are significantly altered between conditions,
# based on the differential expression statistics calculated above.
print(""\nIdentifying deregulated ligand-receptor interactions..."")
lr_res = li.multi.df_to_lr(
    adata,
    dea_df=dea_df,
    resource_name='consensus',
    expr_prop=0.1,
    groupby=groupby,
    stat_keys=['stat', 'pvalue', 'padj'],
    use_raw=False, # Use log-normalized data for expression proportion check
    complex_col='stat',
    return_all_lrs=False
)

# Sort the results by the interaction statistic.
lr_res = lr_res.sort_values(""interaction_stat"", ascending=False)


# --- 3. Pathway Enrichment Analysis ---
# Use the DEA results to infer transcription factor (TF) activity changes.
print(""\nPerforming pathway enrichment analysis (TF activity)..."")
# Get a TF-target regulatory network from Omnipath's CollecTRI resource.
net = dc.get_collectri()

# Pivot the DEA results to a wide format (cells x genes) with stat values.
dea_wide = dea_df[[groupby, 'stat']].reset_index(names='genes').pivot(
    index=groupby, columns='genes', values='stat'
).fillna(0)

# Run Univariate Linear Model (ULM) from Decoupler to estimate TF activities.
estimates, pvals = dc.run_ulm(mat=dea_wide, net=net)

# Print the top TFs associated with the 'CD14' Monocyte group as an example.
top_tfs = estimates.T.sort_values('CD14', key=abs, ascending=False).head()
print(""\nTop TFs associated with CD14 Monocytes:"")
print(top_tfs)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- UMAP Visualization ---
# Plot a UMAP to visualize the overall structure of the data.
print(""\n--- Visualizing Results ---"")
sc.pl.umap(adata, color=[condition_key, sample_key, 'cell_type', groupby], frameon=False, ncols=2)

# --- Tile Plot of Top Interactions ---
# Visualize the top 15 deregulated ligand-receptor interactions.
# Fill color represents expression, while '*' indicates statistical significance.
li.pl.tileplot(
    liana_res=lr_res,
    fill='expr',
    label='padj',
    label_fun=lambda x: '*' if x < 0.05 else np.nan,
    top_n=15,
    orderby='interaction_stat',
    orderby_ascending=False,
    source_title='Ligand',
    target_title='Receptor'
)


#--------------------------------
# Data Output
#--------------------------------

# Save the key results DataFrames to CSV files.
print(""\nSaving analysis results..."")
dea_df.to_csv(""differential_expression_results.csv"")
lr_res.to_csv(""deregulated_lr_interactions.csv"")
estimates.to_csv(""tf_activity_estimates.csv"")

# Save the processed AnnData object.
adata.write(""kang_processed_for_dea.h5ad"")

print(""\nDifferential communication and pathway analysis completed!"")
",https://liana-py.readthedocs.io/en/latest/notebooks/targeted.html,F
43,scRNA-seq,Enrichment analysis,"The primary objective was to identify pathway activity signatures across single-cell clusters in the PBMC3k dataset. This was accomplished using a gene set enrichment strategy with the PROGENy pathway model, implemented with the decoupler package in Python. Starting with a preprocessed AnnData object containing single-cell transcriptomes, the analysis involved computing pathway activity scores via the Univariate Linear Model (ULM) method (min_n=5 genes/pathway). Scores were stored in the `.obsm` attribute and z-scaled for visualization. Pathway activity was visualized on a UMAP embedding to highlight spatial activation patterns (e.g., TNF?? signaling). Violin plots compared pathway scores across cell types, while a hierarchically clustered matrix plot displayed z-scaled scores for all pathways and clusters. These visualizations revealed cell-type-specific pathway engagement, supported by dendrogram-based clustering relationships.  ","### Methods

#### Data Preprocessing and Visualization
Single-cell RNA sequencing data from the PBMC3k dataset were loaded using the `decoupler` package (`dc.ds.pbmc3k()`). The dataset, which includes pre-processed clustering information, was stored in an AnnData object. Visualization parameters were configured using `scanpy` (`sc.set_figure_params`) to ensure consistent and clear plotting.

#### Pathway Enrichment Analysis
Pathway enrichment analysis was performed using the PROGENy model, a curated set of pathway gene sets with signed weights representing up- and down-regulation. The PROGENy model was loaded for the human organism using the `dc.op.progeny()` function. Pathway activity scores were computed for each cell using the Univariate Linear Model (ULM) method implemented in `decoupler` (`dc.run_ulm()`). The analysis was performed with a minimum of 5 genes per pathway (`min_n=5`). The resulting pathway enrichment scores were stored in the `.obsm` attribute of the AnnData object under the key `'ulm_estimate'`. For visualization, the pathway scores were extracted into a separate AnnData object using the `dc.get_obsm_to_anndata()` function.

#### Visualization of Pathway Activity
The original cell clusters were visualized on a Uniform Manifold Approximation and Projection (UMAP) embedding using `scanpy` (`sc.pl.umap()`). Pathway activity for specific pathways, such as TNFa signaling, was overlaid on the UMAP embedding to highlight spatial patterns of pathway activation. Pathway activity scores were compared across cell types using violin plots (`sc.pl.violin()`). To provide a comprehensive overview of pathway activity, a matrix plot was generated, displaying z-scaled pathway scores across all cell types (`sc.pl.matrixplot()`). The matrix plot included hierarchical clustering of pathways and cell types, with dendrograms enabled (`dendrogram=True`).

#### Data Output
The AnnData object, now containing pathway enrichment scores in the `.obsm` attribute (`'ulm_estimate'`), was saved in the H5AD file format (`adata.write()`) for downstream analysis and reproducibility.

This workflow enabled the systematic identification and visualization of pathway activity in single-cell data, providing insights into the functional states of individual cells and their relationships to specific biological processes.","scanpy, decoupler, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for single-cell analysis, pathway analysis, and plotting
import scanpy as sc
import decoupler as dc
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set global plotting parameters for clear and consistent visualization
sc.set_figure_params(figsize=(5, 5), frameon=False)

#--------------------------------
# Data Input
#--------------------------------

# Load an example dataset (PBMC 3k) from Decoupler's built-in datasets.
# This dataset is pre-processed with clustering information.
print(""Loading pbmc3k dataset..."")
adata = dc.ds.pbmc3k()

# Display a summary of the loaded dataset.
print(adata)


#--------------------------------
# Major Analysis Task: Pathway Enrichment
#--------------------------------

# --- Load Pathway Gene Sets ---
# Get the PROGENy model, which contains a curated set of pathway gene sets
# with signed weights representing up/down-regulation.
print(""\nLoading PROGENy pathway model..."")
progeny = dc.op.progeny(organism='human')

# --- Compute Enrichment Scores ---
# Run the Univariate Linear Model (ulm) from Decoupler to compute pathway
# enrichment scores for each cell.
# The result is stored in `adata.obsm['ulm_estimate']`.
print(""Computing pathway enrichment scores..."")
dc.run_ulm(data=adata, net=progeny, source='source', target='target', weight='weight', min_n=5)

# Extract the computed enrichment scores into a separate AnnData object for easier plotting.
# This creates a new object where the .X matrix contains the pathway scores.
scores = dc.get_obsm_to_anndata(adata, obsm_key='ulm_estimate')


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- UMAP of Cell Clusters ---
# Visualize the original cell clusters from the dataset.
print(""\n--- Visualizing Results ---"")
sc.pl.umap(adata, color='leiden', title='UMAP of PBMC Clusters')

# --- UMAP of Pathway Activity ---
# Visualize the activity of a specific pathway (e.g., TNFa signaling) on the UMAP.
# Red indicates higher pathway activity, and blue indicates lower activity.
sc.pl.umap(scores, color=['TNFa'], cmap='RdBu_r', vcenter=0, title='TNFa Pathway Activity')

# --- Violin Plot of Pathway Activity ---
# Compare the distribution of pathway activity scores across different cell types.
sc.pl.violin(scores, keys=['TNFa'], groupby='celltype', rotation=90)

# --- Matrix Plot of All Pathways ---
# Show a heatmap of all pathway activities across all cell types.
# The scores are z-scaled for better comparability across pathways.
sc.pl.matrixplot(
    adata=scores,
    var_names=scores.var_names,
    groupby='celltype',
    dendrogram=True,
    standard_scale='var',
    colorbar_title='Z-scaled scores',
    cmap='RdBu_r'
)
plt.show()


#--------------------------------
# Data Output
#--------------------------------

# Save the AnnData object, which now contains the pathway enrichment scores.
print(""\nSaving data with enrichment scores..."")
# Note: The scores are in adata.obsm['ulm_estimate'], and adata.obsm['ulm_pvals']
adata.write(""pbmc3k_with_progeny_scores.h5ad"")

print(""\nPathway enrichment analysis completed!"")
",https://decoupler-py.readthedocs.io/en/latest/notebooks/scell/rna_sc.html,F
44,scRNA-seq,Enrichment analysis,"The primary objective was to identify genes and pathways differentially expressed between COVID-19 and normal conditions. This was accomplished using a pseudobulk-based differential expression analysis followed by pathway activity inference, implemented with the PyDESeq2 package for statistical modeling and the Decoupler package for pathway enrichment in Python. Starting with scRNA-seq data aggregated into pseudobulk samples, the analysis involved DESeq2 modeling of raw counts with disease status and sex as covariates. Pathway activities were estimated using the PROGENy gene sets via Decoupler?€?s univariate linear model. Significant genes and pathways were filtered using an adjusted p-value threshold of 0.05. The results were presented in volcano plots to illustrate magnitude and significance of gene expression changes, and bar plots to display pathway activity differences. PCA and UAP visualizations highlighted sample clustering and cell-type-specific patterns. Key results were validated through CSV output of statistics and pathway scores, supported by pseudobulk data stored in H5AD format for reproducibility.  ","### Methods

#### Data Preprocessing and Pseudobulking  
Single-cell RNA sequencing (scRNA-seq) data were obtained from the COVID-19 dataset included in the Decoupler package. Raw count matrices were loaded into an AnnData object for downstream analysis. To aggregate single-cell expression profiles into pseudobulk samples, counts were summed for each cell type within individual samples using the `pseudobulk` function from the Decoupler package. Low-quality pseudobulk samples were filtered out based on thresholds of at least 10 cells and 1,000 total counts per sample. Raw counts were preserved in a separate layer for subsequent differential expression analysis. For visualization and dimensionality reduction, pseudobulk data were normalized to a total count of 10,000 using the `normalize_total` function from Scanpy, followed by log1p transformation and scaling with a maximum value of 10.

#### Differential Expression Analysis  
Differential expression analysis (DEA) was performed using the PyDESeq2 package to identify genes differentially expressed between COVID-19 and normal conditions. A DESeqDataSet object was constructed from the raw pseudobulk counts, with a design formula incorporating disease status and sex as covariates. The model was fit using the `deseq2` method, and statistical results were extracted for the contrast between COVID-19 and normal conditions. The analysis was performed with 8 CPUs to optimize computational efficiency.

#### Pathway Enrichment Analysis  
Pathway activity changes were inferred from the differential expression results using the PROGENy model, a curated set of pathway gene sets specific to human biology. Pathway activities were estimated using the Univariate Linear Model (ULM) implemented in the Decoupler package. Significant pathways were identified based on an adjusted p-value threshold of 0.05.

#### Visualization  
To explore the dataset, Uniform Manifold Approximation and Projection (UMAP) was applied to the single-cell data, with cell types and disease states overlaid for visualization. Principal Component Analysis (PCA) was performed on the pseudobulk data to identify major sources of variation across samples. Differential expression results were visualized using volcano plots, highlighting genes with significant fold changes. Pathway enrichment results were displayed using bar plots, focusing on significantly altered pathways.

#### Data Output  
Key results, including differential expression statistics and significant pathway activities, were saved as CSV files. The processed pseudobulk data were stored in an H5AD file for further analysis.

All analyses were performed using Python (version 3.x) with the following packages: Scanpy (version 1.x), Decoupler (version 1.x), PyDESeq2 (version 0.x), NumPy (version 1.x), and Pandas (version 1.x). Visualization was conducted using Matplotlib (version 3.x) and Scanpy?€?s plotting functions.","numpy, scanpy, pandas,decoupler",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for data handling, analysis, plotting, and single-cell analysis
import numpy as np
import pandas as pd
import scanpy as sc
import decoupler as dc
import matplotlib.pyplot as plt
from pydeseq2.dds import DeseqDataSet, DefaultInference
from pydeseq2.ds import DeseqStats

#--------------------------------
# Script Configuration
#--------------------------------

# Set global plotting parameters for clear and consistent visualization
sc.set_figure_params(figsize=(4, 4), frameon=False)

#--------------------------------
# Data Input
#--------------------------------

# Load an example single-cell RNA sequencing dataset.
# Here, we use a COVID-19 dataset from Decoupler's built-in datasets.
print(""Loading covid5k dataset..."")
adata = dc.ds.covid5k()

# Display a summary of the loaded dataset.
print(adata)


#--------------------------------
# Preprocessing and Pseudobulking
#--------------------------------

# --- Pseudobulking ---
# Aggregate single-cell expression data into pseudobulk profiles.
# This sums the counts for each cell type within each individual sample.
print(""\nGenerating pseudobulk profiles..."")
pdata = dc.pp.pseudobulk(
    adata=adata,
    sample_col='individual',
    groups_col='celltype',
    mode='sum' # Sum counts for each gene
)

# --- Pseudobulk QC and Preprocessing ---
# Filter out low-quality pseudobulk samples.
dc.pp.filter_samples(pdata, min_cells=10, min_counts=1000)

# Normalize and preprocess the pseudobulk data for visualization and PCA.
# Note: Raw counts are kept for DESeq2 analysis.
pdata.layers['counts'] = pdata.X.copy()
sc.pp.normalize_total(pdata, target_sum=1e4)
sc.pp.log1p(pdata)
sc.pp.scale(pdata, max_value=10)


#--------------------------------
# Major Analysis Tasks
#--------------------------------

# --- 1. Differential Expression Analysis (DEA) with PyDESeq2 ---
# Define and run the DESeq2 model on the raw pseudobulk counts.
# The design formula `~disease + sex` models the effect of disease while accounting for sex.
print(""\nPerforming differential expression analysis with PyDESeq2..."")
inference = DefaultInference(n_cpus=8)
dds = DeseqDataSet(
    adata=pdata,
    design_factors=['disease', 'sex'],
    refit_cooks=True,
    inference=inference
)
dds.deseq2()

# Extract statistical results for the contrast between COVID-19 and normal conditions.
stat_res = DeseqStats(
    dds,
    contrast=['disease', 'COVID-19', 'normal'],
    inference=inference
)
stat_res.summary()
results_df = stat_res.results_df


# --- 2. Pathway Enrichment Analysis ---
# Use the DEA results to infer pathway activity changes with Decoupler.
print(""\nPerforming pathway enrichment analysis..."")
# Get the PROGENy model, a curated set of pathway gene sets.
progeny = dc.op.progeny(organism='human')

# Run Univariate Linear Model (ulm) to estimate pathway activities from the DE statistics.
pw_acts, pw_padj = dc.run_ulm(
    mat=results_df[['stat']].T.rename(index={'stat': 'disease.vs.normal'}),
    net=progeny
)

# Filter for significantly altered pathways.
significant_mask = (pw_padj.T < 0.05).iloc[:, 0]
significant_pw_acts = pw_acts.loc[:, significant_mask]


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- UMAP of Single-Cell Data ---
# Visualize the initial cell type and disease state distribution.
print(""\n--- Visualizing Results ---"")
sc.pl.umap(adata, color=['celltype', 'disease'], ncols=1, title=[""Cell Types"", ""Disease State""])

# --- Pseudobulk QC Plot ---
# Visualize the cell type composition of the filtered pseudobulk samples.
dc.pl.obsbar(adata=pdata, y='celltype', hue='disease', figsize=(6, 3))

# --- PCA of Pseudobulk Data ---
# Explore the major sources of variation across the pseudobulk samples.
sc.tl.pca(pdata)
sc.pl.pca(pdata, color='disease', size=100, title=""PCA of Pseudobulk Samples"")

# --- Volcano Plot of DEA Results ---
# Visualize the differential expression results, highlighting significant genes.
dc.pl.volcano(results_df, x='log2FoldChange', y='pvalue')

# --- Bar Plot of Pathway Enrichment ---
# Visualize the pathway enrichment results for significantly altered pathways.
dc.pl.barplot(data=significant_pw_acts, name='disease.vs.normal', figsize=(3, 3))


#--------------------------------
# Data Output
#--------------------------------

# Save the key results DataFrames and the processed AnnData object.
print(""\nSaving analysis results..."")
results_df.to_csv(""pseudobulk_dea_results.csv"")
significant_pw_acts.to_csv(""significant_pathway_activities.csv"")
pdata.write(""pseudobulk_processed_data.h5ad"")

print(""\nPseudobulk differential analysis completed!"")
",https://decoupler-py.readthedocs.io/en/latest/notebooks/scell/rna_psbk.html,F
45,scRNA-seq,Enrichment analysis,"The primary objective was to reconstruct hematopoietic cellular trajectories and estimate transcription factor (TF) and pathway activity dynamics during mouse gastrulation. This was accomplished using a graph-based trajectory inference strategy combined with linear modeling of regulatory networks, implemented with the `scanpy` and `decoupler` packages in Python. Starting with a preprocessed, log-normalized mouse gastrulation dataset, the analysis involved dimensionality reduction via PCA, diffusion pseudotime (DPT) computation on a k-nearest neighbor graph, and activity estimation of TFs and pathways using the Univariate Linear Model (ULM). TF-target interactions from the CollecTRI network and pathway-gene weights from PROGENy were applied to compute activity scores, with TFs required to have ???5 targets. The trajectory root was set to ""Blood progenitors 1,"" and cells were ordered along the DPT-inferred path. Results were presented on UMAP embeddings colored by pseudotime, cell type, and activity scores to visualize trajectory progression and activity patterns. Violin plots comparing TF/pathway activity distributions across cell types confirmed lineage-specific regulatory dynamics. These findings were supported by the PAGA graph quantifying inter-cluster connectivity, corroborating the biological plausibility of the inferred trajectory.  ","### Methods

#### Data Preprocessing and Trajectory Inference  
The mouse gastrulation dataset was loaded using the `erygast1k` function from the `decoupler` package. The dataset was already log-normalized, and no additional normalization was performed. Dimensionality reduction was carried out using principal component analysis (PCA), and a k-nearest neighbor graph was computed based on the PCA representation using the `neighbors` function from the `scanpy` package.  

To infer cellular trajectories, a diffusion map was computed using the `diffmap` function, which served as the basis for diffusion pseudotime (DPT) analysis. The k-nearest neighbor graph was recomputed on the diffusion map to better capture the underlying manifold. Partition-based Graph Abstraction (PAGA) was applied to visualize the connectivity between cell types, with the `celltype` annotation used as the grouping variable. The root of the trajectory was defined as the cell type ""Blood progenitors 1,"" and DPT was computed to order cells along the inferred trajectory.  

#### Transcription Factor and Pathway Activity Analysis  
Transcription factor (TF) activity was estimated using the CollecTRI TF-target network for mouse, retrieved via the `collectri` function from the `decoupler` package. The Univariate Linear Model (ULM) was applied to calculate TF activity scores for each cell, with a minimum of 5 targets required for each TF. Pathway activity was similarly estimated using the PROGENy pathway model for mouse, obtained via the `progeny` function. ULM was reapplied to compute pathway activity scores. TF and pathway activity scores were extracted into separate AnnData objects for downstream visualization.  

#### Visualization  
Cellular heterogeneity and trajectory inference results were visualized using uniform manifold approximation and projection (UMAP). UMAP embeddings were colored by cell type, developmental stage, and DPT pseudotime. TF and pathway activity scores were visualized on UMAP embeddings and as violin plots to compare activity distributions across cell types.  

#### Data Output  
The final AnnData object, containing all preprocessing, trajectory inference, and enrichment analysis results, was saved for further use.  

Software and packages used: `scanpy` (v1.9.0), `decoupler` (v1.3.0), and `numpy` (v1.23.0).","numpy, scanpy, pandas,decoupler",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for data handling, analysis, plotting, and single-cell analysis
import numpy as np
import scanpy as sc
import decoupler as dc

#--------------------------------
# Script Configuration
#--------------------------------

# Set global plotting parameters for clear and consistent visualization
sc.set_figure_params(figsize=(5, 5), frameon=False)
sc.settings.verbosity = 3  # Set for detailed logging

#--------------------------------
# Data Input
#--------------------------------

# Load the mouse gastrulation dataset from Decoupler's built-in datasets.
print(""Loading mouse gastrulation dataset..."")
adata = dc.ds.erygast1k()

#--------------------------------
# Preprocessing & Trajectory Inference
#--------------------------------

# --- Preprocessing ---
# The loaded data is already log-normalized. We proceed to dimensionality reduction.
# Compute neighbors using the pre-computed PCA representation.
print(""\nPreprocessing and computing neighbors..."")
sc.pp.neighbors(adata, use_rep='X_pca')

# --- Trajectory Inference with PAGA/DPT ---
# Compute a diffusion map, which is the basis for DPT.
sc.tl.diffmap(adata)

# Recompute neighbors on the diffusion map to better capture the manifold.
sc.pp.neighbors(adata, use_rep='X_diffmap')

# Run Partition-based Graph Abstraction (PAGA) to get a high-level
# view of the connectivity between cell types.
sc.tl.paga(adata, groups='celltype')

# Define the root of the trajectory for pseudotime calculation.
root_celltype = ""Blood progenitors 1""
iroot = np.flatnonzero(adata.obs['celltype'] == root_celltype)[0]
adata.uns['iroot'] = iroot

# Compute Diffusion Pseudotime (DPT) to order cells along the trajectory.
sc.tl.dpt(adata)


#--------------------------------
# Major Analysis Tasks: Enrichment Analysis
#--------------------------------

# --- 1. Transcription Factor (TF) Activity Analysis ---
print(""\nPerforming TF activity enrichment analysis..."")
# Retrieve the CollecTRI TF-target network for mouse from Decoupler's resources.
collectri = dc.op.collectri(organism='mouse')

# Run the Univariate Linear Model (ulm) to estimate TF activity scores for each cell.
# The results are stored in adata.obsm['ulm_estimate'] and adata.obsm['ulm_pvals'].
dc.run_ulm(data=adata, net=collectri, source='source', target='target', weight='weight', min_n=5)

# Extract the TF activity scores into a separate AnnData object for easier plotting.
# This creates a new object where the .X matrix contains the TF scores.
score_tf = dc.get_obsm_to_anndata(adata, obsm_key='ulm_estimate')


# --- 2. Pathway Activity Analysis ---
print(""\nPerforming pathway activity enrichment analysis..."")
# Retrieve the PROGENy pathway model for mouse.
progeny = dc.op.progeny(organism='mouse')

# Run ULM again to estimate pathway activity scores.
# Note: This overwrites the previous results in adata.obsm['ulm_*'], which is why
# we extracted the TF scores to a separate object first.
dc.run_ulm(data=adata, net=progeny, source='source', target='target', weight='weight', min_n=5)

# Extract the pathway activity scores into another AnnData object.
score_pathway = dc.get_obsm_to_anndata(adata, obsm_key='ulm_estimate')


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- UMAP of Raw Data and Trajectory ---
print(""\n--- Visualizing Results ---"")
# Visualize the initial UMAP colored by cell type and developmental stage.
sc.pl.umap(adata, color=['celltype', 'stage'], ncols=1, title=[""Cell Types"", ""Developmental Stage""])

# Visualize the DPT pseudotime ordering on the UMAP.
sc.pl.umap(adata, color=['dpt_pseudotime'], title=""Diffusion Pseudotime"")


# --- TF Activity Visualization ---
# Choose a transcription factor to visualize, e.g., ""Klf3"".
tf = 'Klf3'
# Plot a UMAP colored by the Klf3 enrichment score.
sc.pl.umap(score_tf, color=[tf], cmap='RdBu_r', vcenter=0, title=f""{tf} Activity"")
# Plot a violin plot showing the distribution of the Klf3 score across cell types.
sc.pl.violin(score_tf, keys=[tf], groupby='celltype', rotation=90, ylabel=f'{tf} score')


# --- Pathway Activity Visualization ---
# Choose a pathway to visualize, e.g., ""PI3K"".
pathway = 'PI3K'
# Plot a UMAP colored by the PI3K pathway enrichment score.
sc.pl.umap(score_pathway, color=[pathway], cmap='RdBu_r', vcenter=0, title=f""{pathway} Pathway Activity"")
# Plot a violin plot showing the distribution of the PI3K score across cell types.
sc.pl.violin(score_pathway, keys=[pathway], groupby='celltype', rotation=90, ylabel=f'{pathway} score')


#--------------------------------
# Data Output
#--------------------------------

# Save the final AnnData object, which contains all analysis results.
print(""\nSaving final AnnData object..."")
adata.write(""erygast1k_with_trajectory_and_enrichment.h5ad"")

print(""\nTrajectory and enrichment analysis completed!"")
",https://decoupler-py.readthedocs.io/en/latest/notebooks/scell/rna_pstime.html,F
46,scRNA-seq,Gene regulatory networks analysis,"The primary objective was to reconstruct gene regulatory networks from single-cell data using the SCENIC pipeline, implemented with `pyscenic`. Starting with an H5AD file, key steps included GEX-focused preprocessing (log-transformation, batch-aware HVG selection via `flavor=""seurat""`), donor-batch subsetting (`s1d1`), and loom file preparation for SCENIC input. Regulatory networks were inferred externally using a known TF database and parallel computation. Results were visualized through a histogram of GRN importance scores, revealing interaction strengths, and UMAP embeddings confirming dataset integrity before/after subsetting. Supporting QC metrics included cell-level gene counts. This workflow enabled systematic identification of TF-gene interactions while addressing computational constraints through strategic subsetting and batch-aware feature selection.","### Methods

#### Data Preprocessing
Single-cell RNA-seq data were loaded from an H5AD file using the `scanpy` package (`sc.read_h5ad`). The dataset was filtered to retain only gene expression (GEX) features, discarding other modalities. A log-transformation was applied to the expression matrix (`sc.pp.log1p`) to stabilize variance. Highly variable genes (HVGs) were identified using a batch-aware method (`sc.pp.highly_variable_genes`) with the `flavor=""seurat""` parameter, ensuring robust feature selection across batches.

#### Data Subsetting for SCENIC Analysis
To reduce computational complexity, the dataset was subset to include only cells from a single donor batch (`s1d1`). This subset was used for downstream analysis while preserving the full dataset for broader comparisons.

#### Preparation of Loom File for SCENIC
A loom file, required as input for the SCENIC pipeline, was generated from the subsetted AnnData object. The loom file was created using the `loompy.create` function, with the expression matrix transposed to meet SCENIC's format requirements. Row attributes included gene names, while column attributes included cell IDs, the number of detected genes per cell (`nGene`), and the total UMI counts per cell (`nUMI`). The loom file was saved to a specified directory.

#### External SCENIC Analysis
Gene regulatory network (GRN) inference was performed using the `pyscenic` command-line tool. The analysis was executed externally with the following parameters: the input loom file, a list of known transcription factors (`allTFs_hg38.txt`), and the output file (`adj.csv`) containing the inferred regulatory network adjacencies. The command was run with three workers to optimize computational efficiency.

#### Post-Analysis and Visualization
Upon completion of the SCENIC analysis, the GRN results were loaded from the output file (`adj.csv`). The distribution of GRN importance scores, reflecting the strength of regulatory interactions, was visualized using a histogram. UMAP embeddings were generated to visualize the overall structure of the dataset before and after subsetting, with cells colored by batch and cell type. Additionally, the distribution of the number of genes detected per cell was plotted as a quality control metric.

#### Data Output
The subsetted AnnData object, preprocessed for SCENIC analysis, was saved to an H5AD file (`s1d1_preprocessed_for_scenic.h5ad`) for future use.

This workflow ensured a comprehensive and reproducible analysis of single-cell RNA-seq data, facilitating the identification of gene regulatory networks and their visualization.","pyscenic, loompy, matplotlib, numpy, pandas, scanpy, seaborn","python, bash","#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for system operations, data handling, analysis, and plotting
import warnings
from pathlib import Path
import loompy
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scanpy as sc
import seaborn as sns

#--------------------------------
# Script Configuration
#--------------------------------

# Suppress warnings for a cleaner output during execution
warnings.filterwarnings(""ignore"")
# Set global plotting parameters
sc.set_figure_params(facecolor=""white"")
sns.set_theme()

#--------------------------------
# Data Input
#--------------------------------

# Load the single-cell RNA-seq data.
# NOTE: Replace the path with the actual location of your data file.
adata = sc.read_h5ad(""path/to/your_openproblems_bmmc_multiome_genes_filtered.h5ad"")
print(""Initial dataset shape:"", adata.shape)

#--------------------------------
# Data Preprocessing
#--------------------------------

# Filter for gene expression (GEX) features if the dataset is multi-modal.
rna = adata[:, adata.var[""feature_types""] == ""GEX""].copy()
del adata  # Free up memory

# Apply a log-transformation to the data.
sc.pp.log1p(rna)

# Identify highly variable genes (HVGs) using a batch-aware method.
sc.pp.highly_variable_genes(rna, batch_key=""batch"", flavor=""seurat"")
print(""Preprocessing complete."")


#--------------------------------
# Major Analysis Task: Prepare for SCENIC
#--------------------------------

# --- Step 1: Subset Data for Analysis ---
# For demonstration, we subset the data to a single batch/donor ('s1d1').
# SCENIC can be run on the full dataset, but this reduces computational time for an example.
adata_batch = rna[rna.obs[""batch""] == ""s1d1"", :].copy()
print(f""\nSubsetting data to batch 's1d1'. New shape: {adata_batch.shape}"")


# --- Step 2: Create Loom File for SCENIC ---
# SCENIC requires a specific file format (.loom) for its command-line interface.
# We create this file from our preprocessed AnnData object.
loom_path = ""data/neurips_processed_input.loom""
Path(""data"").mkdir(exist_ok=True) # Ensure the directory exists

# Define row and column attributes required by the loom format.
row_attrs = {""Gene"": np.array(adata_batch.var.index)}
col_attrs = {
    ""CellID"": np.array(adata_batch.obs.index),
    ""nGene"": np.array(np.sum(adata_batch.X > 0, axis=1)).flatten(),
    ""nUMI"": np.array(np.sum(adata_batch.X, axis=1)).flatten(),
}

# Create the loom file. Note that the expression matrix must be transposed.
print(f""Creating loom file at: {loom_path}"")
loompy.create(loom_path, adata_batch.X.T, row_attrs, col_attrs)


#--------------------------------
# External Step: Run pyscenic
#--------------------------------

# The core GRN inference in SCENIC is run via a command-line tool.
# This step is performed outside of this script in a terminal environment.
#
# EXAMPLE COMMAND:
# pyscenic grn data/neurips_processed_input.loom allTFs_hg38.txt \
#          -o adj.csv --num_workers 3
#
# - `data/neurips_processed_input.loom`: The input file we created.
# - `allTFs_hg38.txt`: A list of known transcription factors.
# - `-o adj.csv`: The output file containing gene regulatory network adjacencies.
#
# This command produces a file ('adj.csv') which we load in the next step.
print(""\nSCENIC GRN inference must be run externally via the command line."")


#--------------------------------
# Post-Analysis: Load and Visualize GRN Results
#--------------------------------

# Assuming the 'pyscenic grn' command has been run, we now load its output.
try:
    results_adjacencies = pd.read_csv(""adj.csv"")
    print(f""\nSuccessfully loaded GRN results. Found {results_adjacencies.shape[0]} associations."")
    print(results_adjacencies.head())
except FileNotFoundError:
    print(""\n'adj.csv' not found. Please run the external pyscenic command first."")
    results_adjacencies = None


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- UMAP Visualization ---
# Plot UMAPs to visualize the overall data structure before and after subsetting.
# Note: This assumes 'GEX_X_umap' coordinates are pre-computed in the loaded file.
print(""\n--- Visualizing Data ---"")
sc.pl.embedding(rna, ""GEX_X_umap"", color=[""cell_type"", ""batch""], title=""UMAP: All Cells"")
sc.pl.embedding(adata_batch, ""GEX_X_umap"", color=[""cell_type"", ""batch""], title=""UMAP: Donor s1d1"")

# --- GRN Importance Score Distribution ---
# If GRN results were loaded, plot a histogram of the importance scores.
# This score reflects the strength of the regulatory link between a TF and its target.
if results_adjacencies is not None:
    plt.figure(figsize=(8, 5))
    plt.hist(np.log10(results_adjacencies[""importance""] + 1e-10), bins=50, color=""skyblue"", edgecolor=""black"")
    plt.xlabel(""Log10(Importance Score)"")
    plt.ylabel(""Frequency"")
    plt.title(""Distribution of GRN Importance Scores"")
    plt.show()

# --- Genes Detected per Cell ---
# Plot the distribution of the number of genes detected per cell. This is a useful QC metric.
n_genes_detected_per_cell = np.sum(adata_batch.X > 0, axis=1)
n_genes_series = pd.Series(n_genes_detected_per_cell.A.flatten() if hasattr(n_genes_detected_per_cell, 'A') else n_genes_detected_per_cell.flatten())

fig, ax = plt.subplots(figsize=(8, 5), dpi=100)
sns.histplot(n_genes_series, bins=""fd"", edgecolor=""black"", ax=ax)
ax.set_xlabel(""Number of Genes Detected"")
ax.set_ylabel(""Number of Cells"")
ax.set_title(""Distribution of Genes Detected per Cell (Donor s1d1)"")
plt.tight_layout()
plt.show()

#--------------------------------
# Data Output
#--------------------------------

# Save the subsetted AnnData object used for the analysis.
print(""\nSaving subsetted AnnData object..."")
adata_batch.write(""s1d1_preprocessed_for_scenic.h5ad"")

print(""\nSCENIC data preparation script completed!"")
",https://www.sc-best-practices.org/mechanisms/gene_regulatory_networks.html,F
47,scRNA-seq,Annotation,"The primary objective was to detect chromosomal copy number variations (CNVs) in single-cell tumor populations through relative expression analysis. This was accomplished using a reference-based comparative genomic approach, implemented with the inferCNV (v1.10.1) R package and integrated with scRNA-seq data processed via Seurat (v4.0). Starting with a pre-processed Seurat object containing raw gene counts, the analysis involved extracting a cell annotation file (mapping cells to clusters) and a gene order file with genomic coordinates. Clusters labeled ""0"" and ""8"" were designated as diploid reference cells. The inferCNV pipeline compared tumor cell expression against this reference group using a 0.1 expression cutoff and subcluster-level resolution. Key parameters excluded denoising/HMM steps for efficiency while retaining cluster-grouped CNV inference. The results were presented in a CNV heatmap to visualize genome-wide amplifications (purple) and deletions (blue-green) across individual cells. These findings were supported by the saved RDS file containing inferred CNV profiles and metadata, which confirmed spatially coherent copy number alterations in tumor subpopulations.  ","### Methods

#### **Single-Cell Copy Number Variation Analysis Using inferCNV**

**Data Input and Preprocessing**  
Single-cell RNA sequencing (scRNA-seq) data were processed using the *Seurat* package (v4.0). A pre-processed *Seurat* object containing the raw count matrix was loaded, and the raw integer count matrix was extracted for downstream analysis. The count matrix was formatted with genes as rows and cells as columns, as required by the *inferCNV* pipeline.  

**Preparation of inferCNV Input Files**  
To perform copy number variation (CNV) inference, two input files were prepared:  
1. **Cell Annotation File**: A tab-delimited file mapping each cell ID to its corresponding cell type or cluster annotation was generated. The cell type information was derived from the `seurat_clusters` metadata in the *Seurat* object.  
2. **Gene Order File**: A gene order file specifying the genomic coordinates (chromosome and start position) for each gene was used to order genes along chromosomes in the final heatmap.  

**inferCNV Analysis**  
The *inferCNV* pipeline was executed to infer large-scale chromosomal alterations. The analysis was performed as follows:  
1. **Creation of inferCNV Object**: An *inferCNV* object was created using the raw count matrix, cell annotation file, and gene order file. Cell clusters labeled as ""0"" and ""8"" were designated as the reference group to represent normal cells for relative expression normalization.  
2. **CNV Inference Pipeline**: The *inferCNV* pipeline was run with the following parameters:  
   - A cutoff of 0.1 was applied, as recommended for 10x Genomics data.  
   - Cells were grouped by their annotation for clustering.  
   - The analysis mode was set to ""subclusters"" to enable detailed CNV inference at the subcluster level.  
   - Denoising and Hidden Markov Model (HMM) prediction were not applied.  
   - Preliminary heatmap plotting was skipped to expedite computation.  
   - Results were saved in the specified output directory (`infercnv_output/`).  

**Visualization**  
A final CNV heatmap was generated to visualize inferred amplifications and deletions across the genome for each cell. A custom color palette was applied, with amplifications represented in purple and deletions in blue-green. The heatmap was saved as a PDF file in the output directory.  

**Data Output**  
The final *inferCNV* object, containing all analysis results, was saved as an RDS file for future inspection. All output files, including plots and intermediate results, were stored in the `infercnv_output/` directory.  

**Software and Packages**  
The analysis was performed using *inferCNV* (v1.10.1) for CNV inference, *Seurat* (v4.0) for scRNA-seq data handling, and *RColorBrewer* for color palette generation. All scripts were executed in R (v4.1.0).","Seurat, infercnv, RColorBrewer",R,"#--------------------------------
# Package Load
#--------------------------------

# Load required libraries for inferCNV analysis and data handling
library(infercnv)      # Main package for inferring copy number variations
library(Seurat)        # Used for handling single-cell RNA-seq data
library(RColorBrewer)  # Provides color palettes for plotting

#--------------------------------
# Data Input
#--------------------------------

# Load a pre-processed Seurat object containing your scRNA-seq data.
# NOTE: Replace the path with the actual location of your .RDS file.
pbmc <- readRDS(""../data/pbmc.RDS"")

# Extract the raw count matrix from the Seurat object.
# inferCNV requires a raw integer count matrix with genes as rows and cells as columns.
raw_counts <- pbmc@assays$RNA@counts

#--------------------------------
# Prepare inferCNV Inputs
#--------------------------------

# --- Create Cell Annotation File ---
# This file maps each cell ID to a specific cell type or cluster annotation.
# It should be a two-column, tab-delimited file without headers.
cell_annotations <- data.frame(
  cell_id = colnames(pbmc),
  cell_type = as.character(pbmc@meta.data$seurat_clusters),
  stringsAsFactors = FALSE
)
# Write the annotation file to disk.
write.table(
  cell_annotations,
  file = ""celltype_pbmc.txt"",
  sep = ""\t"",
  row.names = FALSE,
  col.names = FALSE,
  quote = FALSE
)

# --- Gene Order File ---
# This file provides the genomic coordinates for each gene, which inferCNV uses
# to order the genes along chromosomes in the final heatmap.
# It should be a three-column file: Gene, Chromosome, Start Position.
# NOTE: You must provide your own gene order file (e.g., ""gencode_v19_gene_pos.txt"").
gene_order_file_path <- ""gencode_v19_gene_pos.txt""

#--------------------------------
# Major Analysis Task: Run inferCNV
#--------------------------------

# --- Create inferCNV Object ---
# This object is the central data structure for the analysis.
# `ref_group_names` specifies which cell groups to use as the ""normal"" reference
# for calculating relative expression changes.
infercnv_obj <- CreateInfercnvObject(
  raw_counts_matrix = as.matrix(raw_counts),
  annotations_file = ""celltype_pbmc.txt"",
  gene_order_file = gene_order_file_path,
  ref_group_names = c(""0"", ""8"") # Example: Use clusters 0 and 8 as reference
)

# --- Run the inferCNV pipeline ---
# This is the main computational step. It normalizes expression, centers it
# relative to the reference cells, and identifies large-scale chromosomal alterations.
infercnv_obj <- infercnv::run(
  infercnv_obj,
  cutoff = 0.1,                 # Recommended for 10x Genomics data
  out_dir = ""infercnv_output/"", # Directory to store all output files
  cluster_by_groups = TRUE,     # Group cells by their annotation
  denoise = FALSE,              # Optional: apply denoising
  HMM = FALSE,                  # Optional: run Hidden Markov Model for CNV prediction
  no_prelim_plot = TRUE,        # Skip plotting the preliminary heatmap
  analysis_mode = ""subclusters"" # Analyze at the subcluster level for more detail
)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# Define a custom color palette for the final CNV heatmap.
custom_color_pal <- colorRampPalette(c(""#8DD3C7"", ""white"", ""#BC80BD""))(100)

# Generate the final CNV plot. This creates a PDF file in the output directory.
# The plot visualizes inferred amplifications (purple) and deletions (blue-green)
# across the genome for each cell.
infercnv::plot_cnv(
  infercnv_obj,
  plot_chr_scale = TRUE,
  output_filename = ""infercnv_final_plot"",
  output_format = ""pdf"",
  custom_color_pal = custom_color_pal
)

#--------------------------------
# Data Output
#--------------------------------

# The `infercnv::run` function automatically saves the results and plots
# in the specified `out_dir`. The final inferCNV object is also returned,
# which can be saved for later inspection if needed.
saveRDS(infercnv_obj, file = ""infercnv_output/final_infercnv_object.rds"")

print(""\ninferCNV analysis completed! Check the 'infercnv_output' directory for results."")
",https://blog.csdn.net/weixin_56845253/article/details/130551826,F
48,scRNA-seq,Annotation,"The primary objective was to infer tumor-specific copy number variations (CNVs) using single-cell transcriptomics. This was accomplished using a computational CNV inference pipeline, implemented with the infercnv R package alongside Seurat for data management. Starting with a pre-processed Seurat object containing harmonized scRNA-seq data, the analysis involved subsetting 3,000 tumor cells and combining them with normal reference clusters (0 and 18). Raw count data were processed with infercnv using reference-normalized CNV prediction (ward.D2 hierarchical clustering, 0.1 expression cutoff, denoising enabled). Tumor CNV scores were computed from residual matrices, quantifying deviations from the normal genomic baseline. The results were presented in a CNV score distribution boxplot to illustrate inter-cluster variability in genomic aberrations. These findings were supported by merging per-cell CNV scores into the Seurat metadata, enabling downstream correlation of CNV burden with transcriptional phenotypes.  ","### Methods

#### Data Processing and Preparation

Single-cell RNA sequencing (scRNA-seq) data were processed and analyzed using the `Seurat` package (v4.0) in R. A pre-processed Seurat object containing harmonized scRNA-seq data was loaded for downstream analysis. Cell types were annotated based on clustering information, with clusters ""0"" and ""18"" designated as ""Normal"" reference cells, while all other clusters were classified as ""Tumor."" To manage computational load, a random subset of 3,000 tumor cells was sampled, and these were combined with all normal cells for further analysis. The raw integer count matrix was extracted from the subsetted Seurat object for use in copy number variation (CNV) inference.

#### InferCNV Analysis

The `infercnv` package (v1.6.0) was employed to infer CNVs from the scRNA-seq data. An `infercnv` object was created using the raw count matrix, a cell annotation file mapping cells to their cluster IDs, and a gene order file specifying genomic coordinates for each gene. The clusters ""0"" and ""18"" were designated as the reference group for normalization. The CNV inference pipeline was executed with the following parameters: a cutoff of 0.1 for 10x Genomics data, hierarchical clustering using the ""ward.D2"" method, denoising enabled, and HMM-based CNV prediction disabled. Results were saved to a specified output directory.

#### CNV Scoring

A per-cell CNV score was calculated based on the output of the `infercnv` analysis. The observation and reference matrices generated by `infercnv::run` were read, combined, and scaled. A squared residual score was computed to quantify CNV burden for each cell. The resulting CNV scores were merged with the metadata of the original Seurat object for downstream analysis.

#### Visualization and Data Output

The distribution of CNV scores across clusters was visualized using a boxplot created with the `ggpubr` package (v0.4.0). The final `infercnv` object and CNV score boxplot were saved to the output directory for further use and reference.

#### Software and Packages

All analyses were performed using R (v4.1.0) with the following packages: `Seurat` (v4.0) for single-cell data management, `dplyr` (v1.0.7) and `tibble` (v3.1.3) for data manipulation, `infercnv` (v1.6.0) for CNV inference, and `ggpubr` (v0.4.0) for visualization.","Seurat, dplyr, tibble, infercnv, ggpubr",R,"#--------------------------------
# Package Load
#--------------------------------

# Load required libraries for analysis, data handling, and plotting
library(Seurat)        # For single-cell data management
library(dplyr)         # For data manipulation
library(tibble)        # For advanced data frame functionalities
library(infercnv)      # Main package for inferring copy number variations
library(ggpubr)        # For creating publication-quality plots

#--------------------------------
# Data Input
#--------------------------------

# Load a pre-processed Seurat object.
# NOTE: Replace the path with the actual location of your .RDS file.
scRNA_obj <- readRDS(""./scRNA_harmony_EP.rds"")

#--------------------------------
# Prepare inferCNV Inputs
#--------------------------------

# --- Annotate and Subset Cells ---
# Annotate cell types based on clustering information.
# Here, clusters ""0"" and ""18"" are defined as ""Normal"" reference cells.
meta_data <- scRNA_obj@meta.data %>%
  mutate(cell_type = case_when(
    RNA_snn_res.0.6 %in% c(""0"", ""18"") ~ ""Normal"",
    TRUE ~ ""Tumor""
  ))

# Get cell IDs for tumor and normal groups.
tumor_cells <- rownames(meta_data)[meta_data$cell_type == ""Tumor""]
normal_cells <- rownames(meta_data)[meta_data$cell_type == ""Normal""]

# To manage computational load, randomly sample a subset of tumor cells.
set.seed(123)
tumor_sample <- sample(tumor_cells, min(3000, length(tumor_cells)), replace = FALSE)

# Combine the sampled tumor cells with all normal cells for the analysis.
selected_cells <- c(tumor_sample, normal_cells)
new_scRNA <- subset(scRNA_obj, cells = selected_cells)


# --- Extract Expression Matrix ---
# inferCNV requires a raw integer count matrix.
exprMatrix <- as.matrix(GetAssayData(new_scRNA, slot = ""counts""))


# --- Create Cell Annotation File ---
# This file maps each cell ID to its cluster ID. inferCNV uses this for grouping.
# NOTE: This is different from the Tumor/Normal annotation used for sampling.
cellAnnot <- new_scRNA@meta.data[, ""RNA_snn_res.0.6"", drop = FALSE]


# --- Gene Order File ---
# This file provides the genomic coordinates for each gene.
# NOTE: You must provide your own gene order file.
gene_order_file_path <- ""path/to/gene_pos.txt""


#--------------------------------
# Major Analysis Task: Run inferCNV
#--------------------------------

# --- Create inferCNV Object ---
# `ref_group_names` specifies which clusters to use as the ""normal"" reference.
infercnv_obj <- CreateInfercnvObject(
  raw_counts_matrix = exprMatrix,
  annotations_file = cellAnnot, # This can be a data.frame directly
  delim = ""\t"",
  gene_order_file = gene_order_file_path,
  ref_group_names = c(""0"", ""18"") # Use normal clusters as reference
)

# --- Run the inferCNV pipeline ---
# This is the main computational step.
infercnv_obj <- infercnv::run(
  infercnv_obj,
  cutoff = 0.1,                 # Recommended for 10x Genomics data
  out_dir = ""./output/cnv_epithelial/"", # Directory for all output files
  cluster_by_groups = FALSE,    # Cluster cells across all groups
  hclust_method = ""ward.D2"",    # Hierarchical clustering method
  denoise = TRUE,               # Apply denoising to improve signal
  HMM = FALSE                   # Disable HMM-based CNV prediction in this run
)


#--------------------------------
# Downstream Analysis: CNV Scoring (Optional)
#--------------------------------

# --- Calculate CNV Score ---
# This section calculates a per-cell CNV score based on the inferCNV output.
# Read the observation and reference matrices generated by infercnv::run.
obs <- read.table(""./output/cnv_epithelial/infercnv.observations.txt"", header = TRUE)
ref <- read.table(""./output/cnv_epithelial/infercnv.references.txt"", header = TRUE)

# Combine, scale, and calculate a squared residual score.
expr <- cbind(obs, ref)
expr_scale <- scale(t(expr))
tmp1 <- sweep(expr_scale, 2, apply(expr_scale, 2, min), FUN = ""-"")
tmp2 <- apply(expr_scale, 2, max) - apply(expr_scale, 2, min)
expr_1 <- t(2 * sweep(tmp1, 2, tmp2, FUN = ""/"") - 1)
cnv_score_df <- as.data.frame(colSums(expr_1 * expr_1))
colnames(cnv_score_df) <- ""cnv_score""

# Format the CNV score DataFrame.
cnv_score_df <- cnv_score_df %>%
  rownames_to_column(var = ""cell"") %>%
  mutate(cell = gsub(""\\."", ""-"", cell)) # Ensure cell names match Seurat object


# --- Merge Scores into Seurat Object ---
# Subset the Seurat object to match the cells with CNV scores and merge the scores.
scRNA_sample <- subset(scRNA_obj, cells = cnv_score_df$cell)
meta_with_cnv <- scRNA_sample@meta.data %>%
  rownames_to_column(var = ""cell"") %>%
  inner_join(cnv_score_df, by = ""cell"") %>%
  column_to_rownames(var = ""cell"")


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- CNV Score Boxplot ---
# Create a boxplot to visualize the distribution of CNV scores across different clusters.
cnv_boxplot <- ggboxplot(
  meta_with_cnv,
  x = ""RNA_snn_res.0.6"",
  y = ""cnv_score"",
  fill = ""RNA_snn_res.0.6""
) +
scale_y_continuous(limits = c(0, 3000)) +
xlab(""Cluster"") +
ylab(""CNV Score"") +
theme(
  panel.border = element_rect(colour = ""black"", fill = NA, size = 0.5),
  legend.position = ""none""
)
print(cnv_boxplot)


#--------------------------------
# Data Output
#--------------------------------

# The `infercnv::run` function automatically saves the main heatmap and other results.
# Here, we explicitly save the final inferCNV object and the CNV score plot.
saveRDS(infercnv_obj, file = ""./output/cnv_epithelial/final_infercnv_object.rds"")

# Save the CNV score boxplot to a PDF file.
ggsave(
  plot = cnv_boxplot,
  filename = ""./output/cnv_epithelial/CNV_score_by_cluster.pdf"",
  width = 7,
  height = 4
)

print(""\ninferCNV analysis and CNV scoring completed!"")
",https://blog.csdn.net/lijianpeng0302/article/details/145998388,F
49,scRNA-seq,Annotation,"The primary objective was to distinguish tumor cells from normal cells through single-cell copy number variation (CNV) analysis. This was accomplished using a reference-based sliding window approach, implemented with the `infercnvpy` Python package. Starting with the scRNA-seq dataset from Maynard et al. (2020), the analysis involved averaging gene expression across 250-gene genomic windows and comparing target cells to reference normal cells (B cells, T cells, macrophages). Principal component analysis (PCA) and Leiden clustering were applied to the CNV matrix to group cells by genomic alteration patterns. Tumor classification was determined by manual inspection of chromosome heatmaps and CNV scores exceeding baseline thresholds. The results were presented in UMAP embeddings colored by CNV Leiden clusters and CNV scores to illustrate distinct genomic alteration profiles. These findings were further supported by grouped CNV heatmaps with dendrograms, which confirmed tumor-specific amplification/deletion patterns. Validation included overlaying tumor/normal classifications on transcriptomics-based UMAPs, demonstrating concordance between CNV-driven and gene expression-derived cell states.","### Methods

#### Data Preprocessing and Configuration  
The single-cell RNA sequencing dataset from Maynard et al. (2020) was loaded using the `infercnvpy` Python package. Gene annotations, including chromosome, start, and end positions, were verified to ensure compatibility with copy number variation (CNV) analysis. Warnings were suppressed, and global plotting parameters were configured for consistent visualization.

#### CNV Inference  
Copy number variations were inferred using the `infercnvpy.tl.infercnv` function. A sliding window approach with a window size of 250 genes was employed to average gene expression across genomic regions. Reference cells, defined as normal cell types (e.g., B cells, T cells, macrophages), were used to establish baseline expression levels for comparison. Target cells were compared to this reference to identify regions of genomic amplification or deletion.

#### CNV-Based Clustering  
To identify groups of cells with similar CNV profiles, dimensionality reduction and clustering were performed. Principal component analysis (PCA) was applied to the CNV matrix using `infercnvpy.tl.pca`. A neighborhood graph was constructed based on the PCA results using `infercnvpy.pp.neighbors`, and Leiden clustering (`infercnvpy.tl.leiden`) was applied to partition cells into CNV-based clusters.  

#### CNV Visualization and Scoring  
A UMAP embedding was computed using `infercnvpy.tl.umap` to visualize CNV profiles in a low-dimensional space. A per-cell CNV score was calculated using `infercnvpy.tl.cnv_score` to quantify the extent of genomic alterations.  

#### Tumor vs. Normal Classification  
Cells were classified as ""tumor"" or ""normal"" based on their CNV profiles. Tumor clusters were identified by manual inspection of chromosome heatmaps and CNV scores, and cells within these clusters were labeled as ""tumor"" using the `cnv_leiden` cluster assignments.  

#### Visualization  
Multiple visualizations were generated to interpret the results:  
1. **UMAP Embeddings**: Original transcriptomics-based UMAPs were plotted to visualize cell type distributions. CNV-based UMAPs were colored by CNV Leiden clusters, CNV scores, and original cell type annotations.  
2. **CNV Heatmaps**: Heatmaps of inferred CNVs were generated, grouped by both original cell type and CNV-based Leiden clusters. Dendrograms were included to illustrate cluster hierarchies.  
3. **Final Classification**: Tumor and normal classifications were visualized on both CNV-based and transcriptomics-based UMAPs. Separate CNV heatmaps were generated for tumor and normal cells.  

#### Data Output  
The final annotated data object, containing all CNV inference and clustering results, was saved in the H5AD file format for downstream analysis.  

#### Software and Parameters  
All analyses were performed using Python (v3.x) with the `scanpy` (v1.x) and `infercnvpy` (v0.x) packages. Key parameters included a sliding window size of 250 genes for CNV inference and Leiden clustering with default resolution settings.","scanpy, infercnvpy, matplotlib, warnings",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for data handling, analysis, plotting, and single-cell analysis
import scanpy as sc
import infercnvpy as cnv
import matplotlib.pyplot as plt
import warnings

#--------------------------------
# Script Configuration
#--------------------------------

# Suppress warnings for a cleaner output during execution
warnings.simplefilter(""ignore"")
# Set global plotting parameters for clear and consistent visualization
sc.settings.set_figure_params(figsize=(5, 5))

#--------------------------------
# Data Input
#--------------------------------

# Load an example dataset for inferCNV analysis.
# This dataset from Maynard et al., 2020 is suitable for this purpose.
print(""Loading Maynard et al. 2020 dataset..."")
adata = cnv.datasets.maynard2020_3k()

# Display gene annotations to confirm the required columns (chromosome, start, end) are present.
print(adata.var.loc[:, [""ensg"", ""chromosome"", ""start"", ""end""]].head())


#--------------------------------
# Major Analysis Tasks: CNV Inference and Clustering
#--------------------------------

# --- 1. Run inferCNV ---
# This is the main computational step. It infers copy number variations by comparing
# gene expression in target cells to a set of reference (""normal"") cells.
print(""\nRunning infercnvpy analysis..."")
cnv.tl.infercnv(
    adata,
    reference_key=""cell_type"",
    # Define which cell types are used as the normal reference
    reference_cat=[
        ""B cell"", ""Macrophage"", ""Mast cell"", ""Monocyte"", ""NK cell"",
        ""Plasma cell"", ""T cell CD4"", ""T cell CD8"", ""T cell regulatory"",
        ""mDC"", ""pDC""
    ],
    window_size=250 # Size of the sliding window for averaging expression
)

# --- 2. CNV-based Clustering ---
# Cluster cells based on their inferred CNV profiles to identify groups
# of cells with similar large-scale genomic alterations.
print(""\nPerforming CNV-based clustering..."")
# Perform PCA on the CNV matrix.
cnv.tl.pca(adata)
# Compute a neighborhood graph on the PCA results.
cnv.pp.neighbors(adata)
# Run Leiden clustering to find CNV-based clusters.
cnv.tl.leiden(adata)

# --- 3. CNV UMAP and Scoring ---
# Compute a UMAP embedding and a per-cell CNV score based on the CNV profiles.
print(""Computing CNV UMAP and scores..."")
cnv.tl.umap(adata)
cnv.tl.cnv_score(adata)


# --- 4. Tumor vs. Normal Classification ---
# Manually classify cells as ""tumor"" or ""normal"" based on the CNV clusters.
# NOTE: The cluster IDs to be labeled as ""tumor"" need to be determined by inspecting
# the chromosome heatmap and CNV scores from the plots below.
print(""Classifying tumor vs. normal cells..."")
adata.obs[""cnv_status""] = ""normal""
# Example: mark cells in specific cnv_leiden clusters as tumor
tumor_clusters = [""10"", ""16"", ""13"", ""8"", ""12"", ""17"", ""1"", ""14"", ""11""]
adata.obs.loc[adata.obs[""cnv_leiden""].isin(tumor_clusters), ""cnv_status""] = ""tumor""


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- Initial Data Visualization ---
# Visualize the original UMAP from transcriptomics data to see cell type distribution.
print(""\n--- Visualizing Results ---"")
sc.pl.umap(adata, color=""cell_type"", title=""Transcriptomics UMAP by Cell Type"")

# --- CNV Heatmaps ---
# Plot a heatmap of inferred CNVs across the genome, grouped by original cell type.
# This shows which cell types exhibit large-scale genomic alterations.
cnv.pl.chromosome_heatmap(adata, groupby=""cell_type"", title=""CNV Heatmap by Cell Type"")

# Plot the CNV heatmap again, but grouped by the new CNV-based Leiden clusters.
# A dendrogram is included to show the hierarchy of clusters.
cnv.pl.chromosome_heatmap(adata, groupby=""cnv_leiden"", dendrogram=True, title=""CNV Heatmap by CNV Cluster"")

# --- CNV UMAPs ---
# Create a multi-panel plot to visualize the CNV-based UMAP embedding.
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(11, 11))
ax4.axis(""off"") # Turn off the unused fourth subplot
# Plot CNV UMAP colored by:
# 1. CNV Leiden cluster
cnv.pl.umap(adata, color=""cnv_leiden"", legend_loc=""on data"", legend_fontoutline=2, ax=ax1, show=False, title=""CNV UMAP by CNV Leiden Cluster"")
# 2. CNV score
cnv.pl.umap(adata, color=""cnv_score"", ax=ax2, show=False, title=""CNV UMAP by CNV Score"")
# 3. Original cell type annotation
cnv.pl.umap(adata, color=""cell_type"", ax=ax3, show=False, title=""CNV UMAP by Original Cell Type"")
plt.tight_layout()
plt.show()


# --- Final Classification Visualization ---
# Visualize the final tumor vs. normal classification on both the CNV-based UMAP
# and the original transcriptomics-based UMAP.
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
fig.suptitle(""Final Tumor/Normal Classification"")
# CNV UMAP
cnv.pl.umap(adata, color=""cnv_status"", ax=ax1, show=False)
# Transcriptomics UMAP
sc.pl.umap(adata, color=""cnv_status"", ax=ax2, show=False)
plt.show()

# Generate separate CNV heatmaps for the classified tumor and normal cells.
cnv.pl.chromosome_heatmap(adata[adata.obs[""cnv_status""] == ""tumor"", :], title=""CNV Heatmap of Tumor Cells"")
cnv.pl.chromosome_heatmap(adata[adata.obs[""cnv_status""] == ""normal"", :], title=""CNV Heatmap of Normal Cells"")


#--------------------------------
# Data Output
#--------------------------------

# Save the final AnnData object, which contains all inferCNVpy analysis results.
print(""\nSaving final AnnData object..."")
adata.write(""maynard2020_with_infercnv.h5ad"")

print(""\ninferCNVpy analysis completed!"")
",https://infercnvpy.readthedocs.io/en/latest/notebooks/tutorial_3k.html,F
50,scRNA-seq,Trajectory inference,"The primary objective was to infer lineage trajectories in bone marrow single-cell RNA-seq data. This was accomplished using a diffusion map-based trajectory inference strategy, implemented with the Palantir algorithm and Scanpy package in Python. Starting with raw scRNA-seq data in an .h5ad format, the analysis involved library-size normalization, HVG selection, and PCA-based dimensionality reduction. Diffusion maps and multiscale space modeling established a developmental manifold. Pseudotime values and terminal state probabilities (e.g., dendritic cells, monocytes) were computed using 500 waypoints, with start/endpoints defined through prior biological knowledge. Results were shown via UMAP (highlighting terminal states) and diffusion component plots to illustrate progenitor-to-differentiated cell transitions. Gene trend plots for markers like *CD34* and *GATA1* along pseudotime supported lineage commitments, while a saved .h5ad file ensured reproducibility for downstream analyses.","### Methods

#### Data Acquisition and Preprocessing
Single-cell RNA sequencing (scRNA-seq) data from a bone marrow sample were obtained in the form of an `.h5ad` file from a publicly accessible repository. The dataset was loaded using the `scanpy` package (`sc.read`). To account for differences in library size, raw counts were normalized per cell using the `scanpy.pp.normalize_per_cell` function. The data were subsequently log-transformed using the `palantir.preprocess.log_transform` method with a pseudocount of 0.1 to stabilize variance. Highly variable genes (HVGs) were identified using the `scanpy.pp.highly_variable_genes` function, selecting the top 1,500 genes based on the `cell_ranger` flavor. Principal component analysis (PCA) was performed using `scanpy.pp.pca` to reduce dimensionality and mitigate sparsity. Optionally, gene expression was imputed using the MAGIC algorithm (`palantir.utils.run_magic_imputation`) to smooth trends for visualization purposes.

#### Trajectory Inference with Palantir
Trajectory inference was performed using the Palantir algorithm. First, diffusion maps were computed using `palantir.utils.run_diffusion_maps` with five components to estimate a low-dimensional phenotypic manifold. The multiscale space was determined using `palantir.utils.determine_multiscale_space` to select the optimal number of components for manifold representation. Terminal states were defined as distinct cell populations (e.g., dendritic cells, monocytes, erythrocytes) based on prior knowledge, and a start cell representing a progenitor state was selected. Pseudotime and cell fate probabilities were calculated using the core Palantir algorithm (`palantir.core.run_palantir`) with 500 waypoints.

#### Visualization
Diffusion map components were visualized using `palantir.plot.plot_diffusion_components`. A UMAP embedding was computed using `scanpy.pp.neighbors` and `scanpy.tl.umap` to provide an overview of the data structure, with clusters and terminal states highlighted. Pseudotime and terminal state probabilities were plotted using `palantir.plot.plot_palantir_results`. Expression trends of selected marker genes (e.g., *CD34*, *MPO*, *GATA1*, *IRF8*) along pseudotime were visualized using `palantir.plot.plot_gene_trends`.

#### Data Output
The processed dataset, including all Palantir results, was saved as an `.h5ad` file using `scanpy.write` for downstream analysis and reproducibility.","os, warnings, pathlib, numpy, pandas, scanpy, palantir, matplotlib, numba",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for system operations, data handling, analysis, and plotting
import os
import warnings
from pathlib import Path
import numpy as np
import pandas as pd
import scanpy as sc
import palantir
import matplotlib.pyplot as plt
from numba.core.errors import NumbaDeprecationWarning

#--------------------------------
# Script Configuration
#--------------------------------

# Suppress specific warnings for a cleaner output during execution
warnings.filterwarnings(""ignore"", category=NumbaDeprecationWarning)
warnings.filterwarnings(""ignore"", module=""scanpy"", message=""No data for colormapping"")
# Set global plotting parameters
sc.set_figure_params(figsize=(5, 5), frameon=False)

#--------------------------------
# Data Input
#--------------------------------

# Define the directory and file path for the dataset
data_dir = os.path.expanduser(""./"")
download_url = ""https://dp-lab-data-public.s3.amazonaws.com/palantir/marrow_sample_scseq_counts.h5ad""
file_path = os.path.join(data_dir, ""marrow_sample_scseq_counts.h5ad"")

# Read the single-cell dataset. A backup URL is provided to download it if not found locally.
print(""Loading marrow sample dataset..."")
adata = sc.read(file_path, backup_url=download_url)

#--------------------------------
# Data Preprocessing
#--------------------------------

# 1. Normalize counts per cell to account for library size differences.
print(""\nPreprocessing data..."")
sc.pp.normalize_per_cell(adata)

# 2. Log-transform the data. Palantir's wrapper uses a pseudocount of 0.1.
palantir.preprocess.log_transform(adata)

# 3. Identify highly variable genes (HVGs) to focus on biological signal.
sc.pp.highly_variable_genes(adata, n_top_genes=1500, flavor=""cell_ranger"")

# 4. Run PCA to reduce dimensionality and mitigate sparsity.
sc.pp.pca(adata)

# 5. (Optional) Impute gene expression using MAGIC for smoother visualizations of gene trends.
# Note: This creates a dense matrix and can be memory-intensive.
print(""Running MAGIC imputation..."")
imputed_X = palantir.utils.run_magic_imputation(adata)


#--------------------------------
# Major Analysis Task: Trajectory Inference with Palantir
#--------------------------------

# --- Step 1: Diffusion Maps ---
# Compute diffusion maps to estimate a low-dimensional phenotypic manifold.
print(""\nComputing diffusion maps..."")
dm_res = palantir.utils.run_diffusion_maps(adata, n_components=5)

# Determine the multiscale space based on the eigenspectrum of the diffusion operator.
# This helps to select the optimal number of components for representing the manifold.
ms_data = palantir.utils.determine_multiscale_space(adata)


# --- Step 2: Trajectory Calculation ---
# Define terminal cell states. These are the endpoints of the developmental trajectories.
# NOTE: These cell IDs are examples and must be replaced with relevant cells from your dataset.
terminal_states = pd.Series(
    [""DC"", ""Mono"", ""Ery""],
    index=[""Run5_131097901611291"", ""Run5_134936662236454"", ""Run4_200562869397916""]
)

# Define the start cell for the trajectory analysis.
# This is often a cell representing a progenitor or stem cell state.
# NOTE: This cell ID is an example and must be adjusted for your data.
start_cell = ""Run5_164698952452459""

# Run the core Palantir algorithm to calculate pseudotime and cell fate probabilities.
print(""\nRunning Palantir trajectory analysis..."")
pr_res = palantir.core.run_palantir(
    adata,
    start_cell,
    num_waypoints=500,
    terminal_states=terminal_states
)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- Diffusion Map Visualization ---
print(""\n--- Visualizing Results ---"")
# Plot the computed diffusion components.
palantir.plot.plot_diffusion_components(adata)
plt.show()

# --- UMAP Visualization ---
# Compute a UMAP embedding for a general overview of the data structure.
sc.pp.neighbors(adata)
sc.tl.umap(adata)
sc.pl.embedding(adata, basis=""umap"", color=""clusters"", frameon=False, title=""UMAP by Cluster"")
plt.show()

# Highlight the chosen terminal state cells on the UMAP.
palantir.plot.highlight_cells_on_umap(adata, terminal_states)
plt.show()

# --- Palantir Results Visualization ---
# Plot the main Palantir results: pseudotime and terminal state probabilities.
palantir.plot.plot_palantir_results(adata, s=3)
plt.show()

# --- Gene Expression Trend Visualization ---
# Plot the imputed expression trends for selected marker genes along pseudotime.
genes = [""CD34"", ""MPO"", ""GATA1"", ""IRF8""]
palantir.plot.plot_gene_trends(adata, genes)
plt.show()


#--------------------------------
# Data Output
#--------------------------------

# Save the processed AnnData object containing all Palantir results.
print(""\nSaving processed data object..."")
output_path = os.path.join(data_dir, ""marrow_sample_palantir_processed.h5ad"")
adata.write(output_path)

print(""\nPalantir trajectory analysis completed!"")
",https://palantir.readthedocs.io/en/latest/notebooks/Palantir_sample_notebook.html,F
51,scRNA-seq,Trajectory inference,"The primary objective was to infer developmental trajectories in pancreatic cells using RNA velocity dynamics. This was accomplished using a kinetic modeling approach that predicts transcriptional dynamics through spliced/unspliced mRNA ratios, implemented with the scVelo Python package. Starting with the pancreas scRNA-seq dataset, preprocessing involved filtering low-count genes, normalizing counts, selecting top 2,000 highly variable genes, and computing velocity moments (30 PCA components, 30 nearest neighbors). RNA velocities were estimated through stochastic modeling of transcriptional kinetics, followed by velocity graph construction and pseudotime calculation using developmental directionality from velocity vectors. A UMAP embedding with velocity streamlines demonstrated global directionality of cell state transitions, while overlaid vector plots showed localized velocity magnitudes. The integration of velocity pseudotime as a gradient on UMAP revealed progressive paths from progenitor to mature endocrine cells. These visualizations were corroborated by pseudotime-ordered expression dynamics of key maturation markers, confirming the biological plausibility of predicted trajectories.","### Methods

#### Data Preprocessing  
The pancreas dataset, a built-in example from the `scVelo` package, was loaded for RNA velocity analysis. To preprocess the data, the `filter_and_normalize` function from `scVelo` was applied. This step included filtering genes with fewer than 20 shared counts across cells, normalizing each cell by its total counts, selecting the top 2000 highly variable genes, and log-transforming the expression data. The first and second-order moments of expression were then computed using the `moments` function, which internally performed principal component analysis (PCA) with 30 principal components and constructed a neighborhood graph with 30 nearest neighbors.

#### RNA Velocity Estimation  
RNA velocities were estimated using the default stochastic model implemented in the `velocity` function of `scVelo`. This model inferred transcription, splicing, and degradation rates to predict the future state of individual cells. A velocity graph was subsequently constructed using the `velocity_graph` function, representing potential cell state transitions based on the computed velocities. Additionally, velocity-based pseudotime was calculated using the `velocity_pseudotime` function to order cells along inferred developmental trajectories.

#### Visualization  
To visualize the RNA velocity results, a streamline plot of the velocity field was generated on a UMAP embedding using the `velocity_embedding_stream` function. This provided a smooth representation of the directional flow of cell states. Individual velocity vectors were also plotted on the UMAP embedding using the `velocity_embedding` function, showing the direction and magnitude of change for local groups of cells. Finally, the calculated velocity pseudotime was visualized on the UMAP embedding using the `scatter` function, with a continuous gradient indicating the inferred developmental paths.

#### Data Output  
The processed `AnnData` object, containing all RNA velocity analysis results, was saved as a `.h5ad` file for further use.

All analyses were performed using the `scVelo` (v0.2.4) and `Scanpy` (v1.8.2) packages in Python. Visualizations were generated using `Matplotlib` (v3.5.1) with default settings optimized for presentation.","scanpy, scvelo, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for RNA velocity analysis, data handling, and plotting
import scvelo as scv
import scanpy as sc
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set scVelo global parameters for logging and plotting aesthetics
scv.settings.verbosity = 3          # Set for detailed logging
scv.settings.presenter_view = True  # Use settings suitable for presentation plots
scv.set_figure_params('scvelo')     # Apply the scVelo default plotting style

#--------------------------------
# Data Input
#--------------------------------

# Load the pancreas dataset, a built-in example from scVelo.
# NOTE: To use your own data, you would replace this line, e.g.:
# adata = scv.read('path/to/your/file.loom', cache=True)
print(""Loading pancreas dataset..."")
adata = scv.datasets.pancreas()

#--------------------------------
# Preprocessing
#--------------------------------

# Apply a standard scVelo preprocessing recipe. This function:
# 1. Filters genes based on a minimum number of shared counts.
# 2. Normalizes each cell by its total counts.
# 3. Selects the top 2000 highly variable genes.
# 4. Log-transforms the expression data.
print(""\nPreprocessing data..."")
scv.pp.filter_and_normalize(adata, min_shared_counts=20, n_top_genes=2000)

# Compute the first and second-order moments of expression for velocity estimation.
# This step internally performs PCA and computes the neighborhood graph.
scv.pp.moments(adata, n_pcs=30, n_neighbors=30)


#--------------------------------
# Major Analysis Task: RNA Velocity Inference
#--------------------------------

# --- Velocity Estimation ---
# Compute RNA velocities using the default stochastic model. This model estimates
# transcription, splicing, and degradation rates to infer the future state of cells.
print(""\nEstimating RNA velocity..."")
scv.tl.velocity(adata)

# --- Velocity Graph ---
# Construct the velocity graph, which represents likely cell state transitions
# based on the computed velocities.
scv.tl.velocity_graph(adata)

# --- Pseudotime Calculation (Optional) ---
# Calculate velocity-based pseudotime, which orders cells along a trajectory
# inferred from the velocity graph.
print(""Calculating velocity pseudotime..."")
scv.tl.velocity_pseudotime(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- Velocity Streamline Plot ---
# Visualize the RNA velocity field as streamlines on a UMAP embedding.
# This provides a smooth representation of the directional flow.
print(""\n--- Visualizing Results ---"")
scv.pl.velocity_embedding_stream(
    adata,
    basis='umap',
    figsize=(8, 8),
    title=""Velocity Streamlines on UMAP""
)

# --- Velocity Arrow Plot ---
# Visualize velocities as individual arrows on the UMAP embedding.
# This shows the direction and magnitude of change for local groups of cells.
scv.pl.velocity_embedding(
    adata,
    arrow_length=3,
    arrow_size=2,
    dpi=120,
    title=""Velocity Vectors on UMAP""
)

# --- Pseudotime Plot ---
# Visualize the calculated velocity pseudotime on the UMAP embedding.
# This plot should show a continuous gradient along the inferred developmental paths.
scv.pl.scatter(
    adata,
    color='velocity_pseudotime',
    cmap='gnuplot',
    size=50,
    title=""Velocity-based Pseudotime""
)

# Ensure all plots are displayed, especially when running as a script.
plt.show()


#--------------------------------
# Data Output
#--------------------------------

# Save the AnnData object containing all RNA velocity analysis results.
print(""\nSaving processed data object..."")
adata.write(""pancreas_scvelo_processed.h5ad"")

print(""\nscVelo analysis completed!"")
",https://scvelo.readthedocs.io/en/stable/VelocityBasics.html,F
52,scRNA-seq,Trajectory inference,"The primary objective was to infer pancreatic cell differentiation trajectories using RNA velocity analysis. This was accomplished using a dynamical RNA velocity model combined with latent time estimation, implemented with the *scVelo* package in Python. Starting with the pancreas scRNA-seq dataset from *scVelo*, the analysis involved preprocessing (filtering low-count genes, selecting highly variable genes, and normalizing), followed by estimating transcriptional kinetics and constructing a velocity graph. Pseudotime-like latent time was derived from transcriptional dynamics to order cells along differentiation paths. Dynamic genes were identified based on their likelihood of conforming to the inferred dynamical model. The results were presented as RNA velocity streamlines overlaid on UMAP embeddings to illustrate directionality and transition probabilities. Cells were colored by latent time to highlight temporal progression. These findings were further supported by a heatmap of dynamic genes ordered by peak expression timing, which confirmed sequential activation of differentiation-associated transcriptional programs.","### Methods

#### Data Preprocessing
The pancreas dataset, a built-in example from the `scVelo` package, was loaded for RNA velocity analysis. The data were preprocessed using the `scv.pp.filter_and_normalize` function to filter out genes with fewer than 20 shared counts and retain the top 2,000 highly variable genes. This step ensured robust downstream analysis by normalizing the data and reducing noise. The first and second-order moments of gene expression were computed using the `scv.pp.moments` function with 30 principal components and 30 nearest neighbors to capture local gene expression dynamics.

#### RNA Velocity Inference
Transcriptional dynamics were recovered using the `scv.tl.recover_dynamics` function, which estimates rate parameters for transcription, splicing, and degradation for each gene. RNA velocities were then computed in 'dynamical' mode using the `scv.tl.velocity` function, leveraging the learned kinetics to provide a robust estimation of cell state transitions. The velocity graph was constructed using the `scv.tl.velocity_graph` function to infer cell-to-cell transition probabilities. Latent time, a measure of a cell's internal clock based on its transcriptional dynamics, was calculated using the `scv.tl.latent_time` function to represent the cell's position along the differentiation trajectory.

#### Visualization
The RNA velocity field was visualized as streamlines on the UMAP embedding using the `scv.pl.velocity_embedding_stream` function. Latent time was plotted on the UMAP embedding using the `scv.pl.scatter` function with a 'gnuplot' color map to illustrate continuous progression along the inferred developmental paths. A heatmap of the top 300 dynamic genes, ordered by their peak expression time along the latent time trajectory, was generated using the `scv.pl.heatmap` function. These genes were selected based on their highest likelihood of being explained by the dynamical model.

#### Data Output
The processed `AnnData` object, containing all RNA velocity analysis results, was saved in H5AD format with gzip compression for further analysis and reproducibility.

This workflow was implemented using the `scVelo` and `scanpy` packages in Python, with specific parameters and functions as described above.","scanpy, scvelo, matplotlib",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for RNA velocity analysis, data handling, and plotting
import scvelo as scv
import scanpy as sc
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Set scVelo global parameters for logging and plotting aesthetics
scv.settings.verbosity = 3
scv.settings.presenter_view = True
scv.set_figure_params('scvelo')

#--------------------------------
# Data Input
#--------------------------------

# Load the pancreas dataset, a built-in example from scVelo.
# NOTE: To use your own data, you would replace this line, e.g.:
# adata = scv.read('path/to/your/file.loom', cache=True)
print(""Loading pancreas dataset..."")
adata = scv.datasets.pancreas()

#--------------------------------
# Preprocessing
#--------------------------------

# Apply a standard scVelo preprocessing recipe.
print(""\nPreprocessing data..."")
scv.pp.filter_and_normalize(adata, min_shared_counts=20, n_top_genes=2000)

# Compute the first and second-order moments of expression for velocity estimation.
scv.pp.moments(adata, n_pcs=30, n_neighbors=30)


#--------------------------------
# Major Analysis Task: Dynamical RNA Velocity Inference
#--------------------------------

# --- Recover Full Splicing Kinetics ---
# Run the dynamical model to recover the full transcriptional dynamics.
# This step estimates rate parameters for transcription, splicing, and degradation for each gene.
print(""\nRecovering transcriptional dynamics..."")
scv.tl.recover_dynamics(adata)

# --- Velocity Estimation (Dynamical Model) ---
# Compute RNA velocities using the 'dynamical' mode, which leverages the learned kinetics.
# This provides a more robust and quantitative estimation of cell state transitions.
print(""Estimating RNA velocity using the dynamical model..."")
scv.tl.velocity(adata, mode='dynamical')

# --- Velocity Graph and Latent Time ---
# Construct the velocity graph to infer cell-to-cell transition probabilities.
scv.tl.velocity_graph(adata)

# Calculate latent time, a measure of a cell's internal clock based on its transcriptional
# dynamics. It represents the cell's position along the differentiation trajectory.
print(""Calculating latent time..."")
scv.tl.latent_time(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- Velocity Streamline Plot ---
# Visualize the RNA velocity field as streamlines on the UMAP embedding.
print(""\n--- Visualizing Results ---"")
scv.pl.velocity_embedding_stream(
    adata,
    basis='umap',
    title=""Dynamical RNA Velocity Stream on UMAP""
)

# --- Latent Time Plot ---
# Visualize the calculated latent time on the UMAP embedding.
# This should show a continuous progression along the inferred developmental paths.
scv.pl.scatter(
    adata,
    color='latent_time',
    color_map='gnuplot',
    size=80,
    title=""Velocity-based Latent Time""
)

# --- Heatmap of Top Dynamic Genes ---
# Visualize the expression dynamics of the top 300 genes with the highest likelihood
# of being explained by the dynamical model. Genes are ordered by their peak expression
# time along the latent time trajectory.
top_genes = adata.var['fit_likelihood'].sort_values(ascending=False).index[:300]
scv.pl.heatmap(
    adata,
    var_names=top_genes,
    sortby='latent_time',
    col_color='clusters',
    n_convolve=100,
    title=""Heatmap of Top Dynamic Genes""
)

# Ensure all plots are displayed.
plt.show()


#--------------------------------
# Data Output
#--------------------------------

# Save the AnnData object containing all RNA velocity analysis results.
print(""\nSaving processed data object..."")
adata.write(""pancreas_scvelo_dynamical_processed.h5ad"", compression='gzip')

print(""\nscVelo dynamical analysis completed!"")
",https://scvelo.readthedocs.io/en/stable/DynamicalModeling.html,F
53,scRNA-seq,Trajectory inference,"The primary objective was to infer cellular state transitions and predict future cell states in the dentate gyrus through RNA velocity analysis. This was accomplished using a stochastic model that quantifies unspliced/spliced mRNA balance to predict transcriptional dynamics, implemented with the scVelo package (v1.0.0) in Python. Starting with the built-in scVelo dentate gyrus dataset, preprocessing included gene filtering (>30 shared counts), normalization, selection of 2000 highly variable genes, and log-transformation. First- and second-order moments were computed using 30 principal components and nearest neighbors. RNA velocities were estimated via the stochastic model (`scv.tl.velocity`), with cell transitions encoded in a velocity graph (`scv.tl.velocity_graph`). The final trajectory model derived directional probabilities based on RNA velocity consistency across neighboring cells. Results were visualized as velocity streamlines and vectors projected onto UMAP, using `scv.pl.velocity_embedding_stream` and `scv.pl.velocity_embedding` to illustrate global differentiation directions and localized movement magnitudes. The streamline density map highlighted major developmental paths, while velocity vectors confirmed coherent directional trends among cell neighborhoods. Processed data was saved as a compressed AnnData object (H5AD) for reproducibility and downstream analysis. ","### Methods

#### Data Preprocessing  
The dentate gyrus dataset, a built-in example from the scVelo package (version 1.0.0), was used for RNA velocity analysis. Data preprocessing was performed using the `scv.pp.filter_and_normalize` function, which included the following steps: (1) filtering genes with fewer than 30 shared counts across cells, (2) normalizing each cell by its total counts, (3) selecting the top 2000 highly variable genes, and (4) log-transforming the expression data. The first and second-order moments of gene expression were computed using the `scv.pp.moments` function, with 30 principal components (PCs) and 30 nearest neighbors for constructing the neighborhood graph.  

#### RNA Velocity Estimation  
RNA velocities were estimated using the stochastic model implemented in the `scv.tl.velocity` function, which infers the future state of individual cells based on the balance of unspliced and spliced mRNA. A velocity graph was subsequently constructed using the `scv.tl.velocity_graph` function to represent likely cell state transitions and capture underlying cellular dynamics.  

#### Visualization  
RNA velocity results were visualized on a UMAP embedding. Two visualization approaches were employed: (1) velocity streamlines, generated using the `scv.pl.velocity_embedding_stream` function, provided a smooth representation of directional flow; and (2) velocity vectors, generated using the `scv.pl.velocity_embedding` function, displayed the direction and magnitude of change for local groups of cells.  

#### Data Output  
The processed dataset, including RNA velocity analysis results, was saved as an AnnData object in H5AD format with gzip compression for downstream analysis and reproducibility.  

All analyses were performed using the scVelo package (version 1.0.0) in Python.","scanpy, scvelo",python,"#--------------------------------
# Import necessary modules
#--------------------------------

# Import libraries for RNA velocity analysis, data handling, and plotting
import scvelo as scv
import scanpy as sc
import matplotlib.pyplot as plt

#--------------------------------
# Script Configuration
#--------------------------------

# Print the scVelo version for reproducibility.
scv.logging.print_version()
# Set scVelo global parameters for logging and plotting aesthetics.
scv.settings.verbosity = 3
scv.settings.presenter_view = True
scv.set_figure_params('scvelo')

#--------------------------------
# Data Input
#--------------------------------

# Load the dentate gyrus dataset, a built-in example from scVelo.
# NOTE: To use your own data, you would replace this line, e.g.:
# adata = scv.read('path/to/your/file.loom', cache=True)
print(""Loading dentate gyrus dataset..."")
adata = scv.datasets.dentategyrus()

#--------------------------------
# Preprocessing
#--------------------------------

# Apply a standard scVelo preprocessing recipe. This function:
# 1. Filters genes based on a minimum number of shared counts.
# 2. Normalizes each cell by its total counts.
# 3. Selects the top 2000 highly variable genes.
# 4. Log-transforms the expression data.
print(""\nPreprocessing data..."")
scv.pp.filter_and_normalize(adata, min_shared_counts=30, n_top_genes=2000)

# Compute the first and second-order moments of expression for velocity estimation.
# This step internally performs PCA and computes the neighborhood graph.
scv.pp.moments(adata, n_pcs=30, n_neighbors=30)


#--------------------------------
# Major Analysis Task: RNA Velocity Inference
#--------------------------------

# --- Velocity Estimation ---
# Compute RNA velocities using the default stochastic model. This model infers
# the future state of individual cells based on the balance of unspliced and spliced mRNA.
print(""\nEstimating RNA velocity..."")
scv.tl.velocity(adata)

# --- Velocity Graph ---
# Construct the velocity graph, which represents likely cell state transitions
# based on the computed velocities. This captures the underlying cellular dynamics.
scv.tl.velocity_graph(adata)


#--------------------------------
# Plotting / Visualization
#--------------------------------

# --- Velocity Streamline Plot ---
# Visualize the RNA velocity field as streamlines on a UMAP embedding.
# This provides a smooth, continuous representation of the directional flow.
print(""\n--- Visualizing Results ---"")
scv.pl.velocity_embedding_stream(
    adata,
    basis='umap',
    figsize=(8, 8),
    dpi=120,
    title=""Velocity Streamlines on UMAP""
)

# --- Velocity Arrow Plot ---
# Visualize velocities as individual arrows on the UMAP embedding.
# This shows the direction and magnitude of change for local groups of cells.
scv.pl.velocity_embedding(
    adata,
    basis='umap',
    arrow_size=2,
    arrow_length=2,
    dpi=120,
    title=""Velocity Vectors on UMAP""
)

# Ensure all plots are displayed, especially when running as a script.
plt.show()


#--------------------------------
# Data Output
#--------------------------------

# Save the AnnData object containing all RNA velocity analysis results.
print(""\nSaving processed data object..."")
adata.write(""dentategyrus_scvelo_processed.h5ad"", compression='gzip')

print(""\nscVelo analysis completed!"")
",https://scvelo.readthedocs.io/en/stable/DifferentialKinetics.html,F
