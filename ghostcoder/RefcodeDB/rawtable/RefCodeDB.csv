Omics,Task,Description,Tools,Language,CodeBlock,Source
scRNA-seq,Quality control,"This script performs an integrated quality control (QC) analysis on single-cell RNA sequencing data to ensure that only high-quality cells are used for downstream analyses. The code starts by importing necessary libraries, such as Scanpy and anndata, which are essential tools for handling and visualizing high-dimensional transcriptomic data. It then loads a sample dataset??here, a built-in PBMC dataset??to simulate how experimental data might be processed. The first step in the QC workflow involves annotating genes to identify key categories that may indicate cell quality. Genes are flagged as mitochondrial, ribosomal, or hemoglobin based on specific naming conventions; for example, mitochondrial genes usually have names beginning with ""MT-"". These annotations allow the subsequent calculation of QC metrics, including the number of genes expressed per cell, the total counts per cell, and the percentage of transcripts derived from mitochondrial genes. High mitochondrial content, for instance, can serve as a marker for cellular stress or apoptosis. Finally, the script creates violin plots and scatter plots to visualize these metrics, enabling researchers to quickly identify outliers or low-quality cells by observing distributions and relationships between total counts, gene numbers, and mitochondrial percentages. This comprehensive QC process is crucial as it ensures that the data is reliable, allowing for accurate normalization, clustering, and further biological interpretation in subsequent analyses.","scanpy, anndata",python,"# Import necessary modules
import scanpy as sc
import anndata as ad

# Set figure parameters for decent plotting
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Data Input/Output: load a sample dataset
# Here we use the built-in PBMC 3k dataset from Scanpy as an example.
adata = sc.datasets.pbmc3k()

# ------------------------------
# Quality Control (QC) Processing
# ------------------------------

# Annotate genes for QC metrics:
# Mark mitochondrial genes: in many human datasets these genes start with ""MT-""
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")

# Mark ribosomal genes: these often start with ""RPS"" or ""RPL""
adata.var[""ribo""] = adata.var_names.str.startswith((""RPS"", ""RPL""))

# Mark hemoglobin genes: using regex to identify gene names starting with ""HB""
adata.var[""hb""] = adata.var_names.str.contains(""^HB[^(P)]"")

# Calculate common QC metrics and store them in adata.obs.
# The function calculates (among others):
# - the number of genes detected per cell
# - the total counts per cell
# - the percentage of counts attributed to mitochondrial, ribosomal, and hemoglobin genes
sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt"", ""ribo"", ""hb""], inplace=True, log1p=True)

# ------------------------------
# Plotting QC Metrics
# ------------------------------

# Create violin plots for key QC metrics:
# - n_genes_by_counts: number of genes expressed per cell
# - total_counts: total counts per cell (after log1p, for visualization)
# - pct_counts_mt: percentage of counts coming from mitochondrial genes
sc.pl.violin(
    adata,
    keys=[""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],
    jitter=0.4,
    multi_panel=True
)

# Create a scatter plot to jointly visualize total counts and number of genes per cell.
# The points are colored according to the percentage of mitochondrial counts.
sc.pl.scatter(adata, x=""total_counts"", y=""n_genes_by_counts"", color=""pct_counts_mt"")
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html
scRNA-seq,Quality control,"This script conducts a comprehensive quality control (QC) and doublet detection analysis on single-cell RNA sequencing data to ensure reliable downstream results. It begins by importing essential libraries and loading a built-in PBMC dataset to simulate a typical experimental workflow. Genes are annotated by flagging mitochondrial, ribosomal, and hemoglobin genes based on naming patterns??critical steps because high percentages of mitochondrial gene expression can indicate stressed or dying cells. The script then calculates per-cell QC metrics such as the total counts, number of detected genes, and the proportion of counts from these key gene categories using specialized functions. These metrics help determine the overall health and quality of the cells and inform subsequent filtering decisions. To visualize the quality of the data, the script generates violin plots that illustrate the distribution of these metrics across cells and scatter plots that display relationships between total counts and gene diversity, with additional coloring based on mitochondrial percentage. Beyond the standard QC, the code also implements doublet detection using the Scrublet algorithm; this step calculates doublet scores and predicts potential doublet cells that might confound analyses if not removed. Visualization of the doublet predictions is achieved with additional scatter plots, enabling a rigorous assessment of cell quality. Overall, the integrated QC and doublet detection workflow is pivotal for refining the dataset prior to normalization, clustering, and further biological interpretation in single-cell studies.","scanpy, anndata",python,"# Import necessary libraries for single-cell analysis and data handling
import scanpy as sc
import anndata as ad

# Set figure parameters for clear plotting
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Data Input: Load a built-in PBMC 3k dataset as an example
adata = sc.datasets.pbmc3k()

# Since this dataset is a single sample, we add a dummy 'sample' column required for batch-level doublet detection.
adata.obs['sample'] = ""sample1""

# ------------------------------
# Quality Control (QC) Analysis
# ------------------------------

# Annotate gene features by flagging genes that serve as QC indicators:
# Flag mitochondrial genes (common prefix ""MT-"" for human genes)
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")
# Flag ribosomal genes (names starting with ""RPS"" or ""RPL"")
adata.var[""ribo""] = adata.var_names.str.startswith((""RPS"", ""RPL""))
# Flag hemoglobin genes (using regex to match names starting with ""HB"" but not followed by ""P"")
adata.var[""hb""] = adata.var_names.str.contains(""^HB[^(P)]"")

# Calculate QC metrics:
# This computes per-cell metrics such as the number of genes detected, total counts,
# and the percentage of counts contributed by mitochondrial, ribosomal, and hemoglobin genes.
sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt"", ""ribo"", ""hb""], inplace=True, log1p=True)

# Visualize QC distributions with violin plots to assess cell quality.
sc.pl.violin(
    adata,
    keys=[""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],
    jitter=0.4,
    multi_panel=True
)

# Create a scatter plot to display the relationship between total counts and number of genes per cell,
# with cells colored by the percentage of mitochondrial gene expression.
sc.pl.scatter(
    adata,
    x=""total_counts"",
    y=""n_genes_by_counts"",
    color=""pct_counts_mt""
)

# ------------------------------
# Doublet Detection using Scrublet
# ------------------------------

# Apply the Scrublet algorithm to predict cell doublets.
# This function will append two new columns to adata.obs: 'doublet_score' and 'predicted_doublet'
sc.pp.scrublet(adata, batch_key=""sample"")

# Visualize potential doublets by plotting cells colored by the 'predicted_doublet' label.
sc.pl.scatter(
    adata,
    x=""total_counts"",
    y=""n_genes_by_counts"",
    color=""predicted_doublet""
)

# (Optional) You can also visualize the doublet scores to assess the prediction confidence.
sc.pl.scatter(
    adata,
    x=""total_counts"",
    y=""n_genes_by_counts"",
    color=""doublet_score""
)
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html
scRNA-seq,Quality control,"The code implements a comprehensive quality control workflow for single-cell RNA sequencing data, focusing on the removal of low-quality cells to ensure robust downstream analyses. It begins by importing essential libraries (NumPy, Scanpy, and Seaborn) and configuring visualization settings for clear diagnostic outputs. The data is then loaded from a 10x Genomics H5 file, and gene names are made unique to prevent indexing conflicts. Specific gene groups, such as mitochondrial genes (identified by the ""MT-"" prefix), ribosomal genes (e.g., starting with ""RPS"" or ""RPL""), and hemoglobin genes, are flagged through pattern matching. Using these groups, the code computes per-cell quality metrics including total counts, the number of expressed genes, and the percentage of counts attributable to these defined gene sets by leveraging Scanpy??s built-in functions. To identify aberrant cells, a custom outlier detection function based on the median absolute deviation (MAD) method is applied across key metrics??such as log-transformed total counts, log-transformed gene counts, and the percentage of counts in the top-expressed genes??with an additional mitochondrial read threshold to capture potential cell degradation. Cells identified as outliers are filtered out, and the impact of this filtering is visualized using diagnostic plots (histograms, violin plots, and scatter plots). Finally, the curated dataset is saved in AnnData format, ensuring that subsequent analyses benefit from a high-quality, refined dataset.","scanpy, numpy, seaborn, scipy",python,"# Import necessary libraries
import numpy as np
import scanpy as sc
import seaborn as sns
from scipy.stats import median_abs_deviation

# Set Scanpy parameters for better visualization
sc.settings.verbosity = 0
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

# Load the single-cell dataset
adata = sc.read_10x_h5(filename=""filtered_feature_bc_matrix.h5"")

# Ensure variable names are unique
adata.var_names_make_unique()

# Define quality control thresholds for filtering low-quality cells
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")  # Mitochondrial genes
adata.var[""ribo""] = adata.var_names.str.startswith((""RPS"", ""RPL""))  # Ribosomal genes
adata.var[""hb""] = adata.var_names.str.contains(""^HB[^(P)]"")  # Hemoglobin genes

# Compute QC metrics including mitochondrial, ribosomal, and hemoglobin gene fractions
sc.pp.calculate_qc_metrics(
    adata, qc_vars=[""mt"", ""ribo"", ""hb""], inplace=True, percent_top=[20], log1p=True
)

# Define function to identify outliers based on MAD (median absolute deviation)
def is_outlier(adata, metric: str, nmads: int):
    M = adata.obs[metric]
    outlier = (M < np.median(M) - nmads * median_abs_deviation(M)) | \
              (np.median(M) + nmads * median_abs_deviation(M) < M)
    return outlier

# Apply filtering thresholds for various QC metrics
adata.obs[""outlier""] = (
    is_outlier(adata, ""log1p_total_counts"", 5) |
    is_outlier(adata, ""log1p_n_genes_by_counts"", 5) |
    is_outlier(adata, ""pct_counts_in_top_20_genes"", 5)
)

adata.obs[""mt_outlier""] = is_outlier(adata, ""pct_counts_mt"", 3) | (adata.obs[""pct_counts_mt""] > 8)

# Print number of cells before and after filtering
print(f""Total number of cells: {adata.n_obs}"")
adata = adata[(~adata.obs.outlier) & (~adata.obs.mt_outlier)].copy()
print(f""Number of cells after filtering of low-quality cells: {adata.n_obs}"")

# Plot QC metrics to visualize filtering effectiveness
sns.displot(adata.obs[""total_counts""], bins=100, kde=False)
sc.pl.violin(adata, ""pct_counts_mt"")
sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"")

# Save the processed dataset for further analysis
adata.write(""filtered_quality_control.h5ad"")
",https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html
scRNA-seq,Quality control,"The code establishes a comprehensive single-cell RNA sequencing data preprocessing pipeline that streamlines the quality control and doublet detection processes to ensure reliable downstream analyses. It starts by importing essential libraries and loading data from a 10x Genomics H5 file while enforcing unique gene names to avoid conflicts. The pipeline computes key QC metrics, such as total counts, number of genes per cell, and the proportions of mitochondrial, ribosomal, and hemoglobin gene expressions, which help assess cell viability and identify technical artifacts. A robust outlier detection strategy based on the median absolute deviation (MAD) method is implemented to flag and filter out low-quality cells that deviate from expected quality thresholds. In addition to filtering, the code integrates a doublet detection step by calling Scanpy's Scrublet function with a specified batch key (""sample""), which assigns a doublet score to each cell by simulating artificial doublets within each batch. A series of diagnostic plots are generated, including histograms of total counts and doublet scores, violin plots for mitochondrial percentages, and scatter plots correlating total counts with gene counts, providing visual confirmation of the filtering and doublet detection outcomes. Ultimately, the refined dataset??with low-quality cells removed and high doublet scores flagged??is saved in the AnnData format, laying a solid foundation for more precise clustering and subsequent functional analyses in single-cell transcriptomics.","scanpy, numpy, seaborn, scipy, matplotlib",python,"# Import necessary libraries
import numpy as np
import scanpy as sc
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import median_abs_deviation

# Set Scanpy parameters for clear visualization
sc.settings.verbosity = 0
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

# Load the single-cell RNA-seq dataset
adata = sc.read_10x_h5(filename=""filtered_feature_bc_matrix.h5"")
adata.var_names_make_unique()

# Identify mitochondrial, ribosomal, and hemoglobin genes using string matching
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")
adata.var[""ribo""] = adata.var_names.str.startswith((""RPS"", ""RPL""))
adata.var[""hb""] = adata.var_names.str.contains(""^HB[^(P)]"")

# Compute per-cell quality control (QC) metrics including the fraction of counts
# for the above gene groups. Also compute total counts, detected genes, etc.
sc.pp.calculate_qc_metrics(
    adata, qc_vars=[""mt"", ""ribo"", ""hb""], inplace=True, percent_top=[20], log1p=True
)

# Define a function to detect outliers based on the median absolute deviation (MAD)
def is_outlier(adata, metric: str, nmads: int):
    M = adata.obs[metric]
    mad = median_abs_deviation(M)
    median_val = np.median(M)
    outlier = (M < median_val - nmads * mad) | (M > median_val + nmads * mad)
    return outlier

# Apply the outlier detection to key QC metrics
adata.obs[""outlier""] = (
    is_outlier(adata, ""log1p_total_counts"", 5) |
    is_outlier(adata, ""log1p_n_genes_by_counts"", 5) |
    is_outlier(adata, ""pct_counts_in_top_20_genes"", 5)
)
adata.obs[""mt_outlier""] = is_outlier(adata, ""pct_counts_mt"", 3) | (adata.obs[""pct_counts_mt""] > 8)

# Filter out low-quality cells based on the computed outlier flags
print(f""Total number of cells before filtering: {adata.n_obs}"")
adata = adata[(~adata.obs[""outlier""]) & (~adata.obs[""mt_outlier""])].copy()
print(f""Total number of cells after filtering: {adata.n_obs}"")

# Plot QC metrics for further inspection
sns.displot(adata.obs[""total_counts""], bins=100, kde=False)
sc.pl.violin(adata, ""pct_counts_mt"")
sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"")

# --- Begin Doublet Detection Section ---
# Ensure that a 'sample' column exists (required for batch processing); if not, create one.
if ""sample"" not in adata.obs:
    adata.obs[""sample""] = ""sample1""

# Run doublet detection using Scanpy's Scrublet wrapper.
# This function simulates doublets and calculates a doublet score for each cell.
sc.pp.scrublet(adata, batch_key=""sample"")

# Plot a histogram to visualize the distribution of doublet scores across cells.
plt.figure(figsize=(8, 4))
plt.hist(adata.obs[""doublet_score""], bins=50, color=""skyblue"", edgecolor=""black"")
plt.xlabel(""Doublet Score"")
plt.ylabel(""Frequency"")
plt.title(""Doublet Score Distribution"")
plt.show()

# Compute UMAP embedding (if not already computed) to visualize cell clustering
sc.tl.umap(adata)

# Visualize the UMAP embedding colored by doublet score and by predicted doublet status.
sc.pl.umap(adata, color=[""doublet_score"", ""predicted_doublet""], wspace=0.5)
# --- End Doublet Detection Section ---

# Save the processed AnnData object for downstream analyses.
adata.write(""filtered_quality_control_with_doublet_detection.h5ad"")
","https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html, Human added code"
scRNA-seq,Quality control,"The code is designed to perform a comprehensive quality control (QC) analysis on single-cell RNA sequencing data using the Seurat framework. It begins by loading the essential libraries for data manipulation, input/output operations, and visualization. The script reads raw 10X Genomics data to generate a count matrix and constructs a Seurat object, applying initial filtering conditions to remove cells with very low gene counts or detected in only a few instances. A critical QC metric calculated in this process is the percentage of mitochondrial gene expression, which serves as an indicator of cell stress or degradation. To assess the overall quality of the dataset, the code produces various plots, including violin plots and scatter plots, that visualize the distribution of key metrics such as the number of detected genes, total UMI counts, and mitochondrial content. These graphical outputs help in identifying potential outliers and guiding the selection of high-quality cells for further analysis. Following the visualization, the script subsets the Seurat object by retaining cells that meet predetermined quality thresholds??specifically, cells with an appropriate range of gene features and low mitochondrial percentages. Finally, the filtered dataset is saved for downstream analysis tasks like normalization, dimensional reduction, and clustering. This QC workflow is crucial in ensuring that subsequent analyses are based on robust and reliable data, ultimately leading to more accurate biological insights.","Seurat, dplyr, ggplot2",R,"# Load necessary libraries for data I/O and plotting
library(Seurat)   # For single-cell data analysis using Seurat
library(dplyr)    # For data manipulation
library(ggplot2)  # For additional plotting functions (if needed)

# Data I/O: Read in the 10X Genomics dataset (make sure to set the correct path to your data)
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""  # Replace with your data directory
pbmc.data <- Read10X(data.dir = data_dir)

# Create a Seurat object from the raw count matrix
# Using min.cells = 3 and min.features = 200 to filter out low-quality cells at input time
pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k"", min.cells = 3, min.features = 200)

# Calculate the percentage of mitochondrial genes per cell
# This metric is useful to identify stressed or dying cells (high mito percentages are usually undesirable)
pbmc[[""percent.mt""]] <- PercentageFeatureSet(pbmc, pattern = ""^MT-"")

# Plot QC metrics to visualize the distribution of gene counts, UMI counts, and mitochondrial expression
# Violin plots help to observe the spread and possible outliers
VlnPlot(pbmc, features = c(""nFeature_RNA"", ""nCount_RNA"", ""percent.mt""), ncol = 3)

# Create scatter plots to further inspect relationships between QC metrics
# Scatter plot 1: Relationship between total UMI counts and percentage of mitochondrial genes
plot1 <- FeatureScatter(pbmc, feature1 = ""nCount_RNA"", feature2 = ""percent.mt"")
# Scatter plot 2: Relationship between total UMI counts and number of detected features
plot2 <- FeatureScatter(pbmc, feature1 = ""nCount_RNA"", feature2 = ""nFeature_RNA"")
# Combine the scatter plots
plot1 + plot2

# Subset the dataset to remove low-quality cells
# Retain cells with:
#   - More than 200 features (genes) detected
#   - Fewer than 2500 features to avoid potential doublets
#   - Less than 5% mitochondrial gene expression
pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5)

# Optional: Save the QC-filtered Seurat object for downstream analysis
saveRDS(pbmc, file = ""pbmc_QC_filtered.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial
scRNA-seq,Normalization,"This script implements a robust normalization workflow for single-cell RNA sequencing data using Scanpy. Initially, it imports necessary libraries and loads a built-in example dataset, preserving the raw count matrix in a separate layer for later reference. The normalization process begins by scaling the total counts in each cell to a fixed target (e.g., 10,000), thereby harmonizing differences in sequencing depth and library size across cells. Subsequently, a logarithmic transformation (log1p) is applied to stabilize variance, reduce the influence of extreme values, and promote a more Gaussian-like distribution of expression levels. This transformation is crucial for accurately comparing gene expression across cells and preparing the dataset for downstream analyses such as dimensionality reduction, clustering, and differential expression testing. To assess the impact of normalization, the code generates visualization plots including violin plots, which display the distribution of total counts and the number of detected genes per cell, as well as scatter plots that illustrate the relationship between these two metrics. These visualizations enable researchers to quickly detect anomalies or outlier cells that might affect subsequent analyses. Overall, this normalization workflow ensures that the downstream biological interpretations are based on data that are both statistically consistent and biologically meaningful, thus laying a reliable foundation for further single-cell analyses.","scanpy, anndata",python,"# Import necessary libraries for single-cell analysis and data I/O
import scanpy as sc
import anndata as ad

# Set figure parameters for consistent and clear plotting
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Data Input: Load an example single-cell dataset (PBMC 3k)
adata = sc.datasets.pbmc3k()

# Save the raw count matrix in a separate layer for future reference
adata.layers[""counts""] = adata.X.copy()

# ------------------------------
# Data Normalization
# ------------------------------

# Normalize the total counts per cell so that each cell sums to a target value, e.g., 10,000.
# This step accounts for differences in sequencing depth among cells.
sc.pp.normalize_total(adata, target_sum=1e4)

# Log-transform the normalized counts to stabilize the variance.
# This transformation computes log(1+x) for each count.
sc.pp.log1p(adata)

# Print a glimpse of the normalized data matrix for inspection.
print(""Normalized data sample (first 5 cells, first 5 genes):"")
print(adata.X[:5, :5])

# ------------------------------
# Plotting after Normalization
# ------------------------------

# Visualize key QC metrics using violin plots to assess the distribution of total counts 
# and the number of genes detected for each cell after normalization.
sc.pl.violin(
    adata,
    keys=[""total_counts"", ""n_genes_by_counts""],
    jitter=0.4,
    multi_panel=True,
    title=""QC Metrics after Normalization""
)

# Create a scatter plot to examine the relationship between total counts and number of genes per cell.
sc.pl.scatter(
    adata,
    x=""total_counts"",
    y=""n_genes_by_counts"",
    title=""Total Counts vs Number of Genes after Normalization""
)
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html
scRNA-seq,Normalization,"The code implements a robust normalization workflow for single-cell RNA-seq data using analytic Pearson residuals to correct for technical variability and enhance downstream analysis. It begins by importing essential modules??NumPy for numerical operations, Scanpy for single-cell processing, and Seaborn and Matplotlib for plotting??and then reads a quality-controlled AnnData object containing raw UMI count data. The normalization itself is achieved by applying Scanpy??s experimental function to compute analytic Pearson residuals, which model the data using a regularized negative binomial regression that incorporates sequencing depth as a covariate. This method transforms raw counts into normalized residuals that may be positive or negative, effectively stabilizing variance and reducing artifactual noise. The normalized values are stored in a new layer within the AnnData object, ensuring that the original raw data remains intact. To validate the normalization, the code produces diagnostic plots: one histogram displaying the distribution of total counts per cell from the raw data and another histogram showing the distribution of summed Pearson residuals per cell, allowing for visual evaluation of how well technical discrepancies have been mitigated. Finally, the updated AnnData object, now enriched with the analytic Pearson residual normalization, is saved for use in subsequent analyses such as clustering, trajectory inference, or differential expression testing.","numpy, scanpy, seaborn, matplotlib, scipy",python,"# Import required libraries
import numpy as np
import scanpy as sc
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.sparse import csr_matrix

# Set verbosity and figure parameters for Scanpy plots
sc.settings.verbosity = 0
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

# Load the quality-controlled AnnData object
# Replace the filename and backup_url with your data path if necessary
adata = sc.read(""s4d8_quality_control.h5ad"", backup_url=""https://figshare.com/ndownloader/files/40014331"")
# The data contains raw UMI counts for each cell and gene

# ---------------------------------------------------------------------
# Apply Analytic Pearson Residuals Normalization
#
# This normalization method models the technical noise in scRNA-seq data
# by computing Pearson residuals from a negative binomial regression.
# It directly calculates normalized values that can be positive or negative.
# ---------------------------------------------------------------------
analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False)
# Save the normalized expression values in a new layer for downstream analyses
adata.layers[""analytic_pearson_residuals""] = csr_matrix(analytic_pearson[""X""])

# ---------------------------------------------------------------------
# Diagnostic Plotting
#
# Generate side-by-side histograms to contrast the distribution of total counts
# (raw library sizes) with the distribution of cell-wise sums of the analytic
# Pearson residuals. This provides insight into how the normalization has
# adjusted for cell-to-cell technical variability.
# ---------------------------------------------------------------------
fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# Histogram of total counts per cell (raw data)
sns.histplot(adata.obs[""total_counts""], bins=100, kde=False, ax=axes[0])
axes[0].set_title(""Total Counts per Cell"")

# Compute the sum of analytic Pearson residuals across genes for each cell
resid_sum = np.array(adata.layers[""analytic_pearson_residuals""].sum(axis=1)).flatten()

# Histogram of the summed analytic Pearson residuals per cell
sns.histplot(resid_sum, bins=100, kde=False, ax=axes[1])
axes[1].set_title(""Sum of Analytic Pearson Residuals per Cell"")

plt.tight_layout()
plt.show()

# ---------------------------------------------------------------------
# Save the updated AnnData object with the new normalization layer.
# This file can now be used for downstream analyses such as clustering
# or differential expression analysis.
# ---------------------------------------------------------------------
adata.write(""s4d8_normalization_analytic_pearson.h5ad"")
",https://www.sc-best-practices.org/preprocessing_visualization/normalization.html
scRNA-seq,Normalization,"The code is designed to carry out the essential task of normalizing single-cell RNA sequencing data as part of a preliminary data processing pipeline. It begins by importing key libraries that are critical for data manipulation, visualization, and specialized single-cell analysis, ensuring that all the necessary tools are available for robust bioinformatics workflows. The script then performs data I/O by reading raw count data from a 10X Genomics dataset and constructing a structured Seurat object that not only stores the expression matrix but also integrates metadata and preliminary filters applied during object creation. Once the data is loaded, the normalization step is executed using a global scaling method, specifically ""LogNormalize,"" which adjusts the raw gene counts by dividing by each cell??s total expression, multiplying by a constant scale factor (commonly set to 10,000), and finally applying a logarithmic transformation. This normalization process is crucial as it mitigates the variance introduced by differences in sequencing depth or library sizes, thereby enabling accurate and meaningful comparisons across individual cells. To verify that the normalization process has effectively stabilized the data distribution, the code generates violin plots that illustrate the spread of normalized RNA counts across the cells. These plots provide valuable insights into the quality of the normalization and highlight any anomalies or outliers in the dataset. Finally, the normalized Seurat object is saved, paving the way for subsequent analytic steps such as identifying variable features, data scaling, dimensionality reduction, clustering, and further downstream analyses??all of which contribute to extracting reliable biological insights from the single-cell dataset.","Seurat, dplyr, ggplot2",R,"# Import necessary libraries for single-cell RNA-seq analysis and plotting
library(Seurat)   # Main package for single-cell analysis
library(dplyr)    # For data manipulation
library(ggplot2)  # For enhanced plotting capabilities

# Data I/O: Read the raw 10X Genomics data from the specified directory.
# Replace 'path/to/filtered_gene_bc_matrices/hg19/' with the actual directory containing your data.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object using the raw count matrix.
# Cells with fewer than 200 genes and genes expressed in less than 3 cells are filtered out.
seurat_obj <- CreateSeuratObject(counts = raw_data, project = ""DataNormalization"", min.cells = 3, min.features = 200)

# Perform data normalization using a global scaling method (""LogNormalize"").
# This process normalizes the gene expression measurements for each cell by the total expression,
# multiplies the result by a scale factor (default 10,000), and log-transforms it.
seurat_obj <- NormalizeData(seurat_obj, normalization.method = ""LogNormalize"", scale.factor = 10000)

# Generate a violin plot to visualize the distribution of normalized RNA counts across cells.
# This plot helps in assessing the effect of normalization on the data.
VlnPlot(seurat_obj, features = ""nCount_RNA"", pt.size = 0.1) + 
  ggtitle(""Distribution of Normalized RNA Counts"")

# Optionally, save the normalized Seurat object for further downstream analysis.
saveRDS(seurat_obj, file = ""Normalized_Data_Object.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection
scRNA-seq,Feature selection,"This script executes a critical feature selection workflow for single-cell RNA sequencing data. It begins by importing the necessary libraries to manage and analyze high-dimensional biological data and then loads an example dataset (PBMC3k) that represents typical single-cell gene expression data. To ensure that the original expression values are preserved for reference later on, the script stores the raw counts in a separate layer. After data loading, it performs normalization by scaling the total counts in each cell to a fixed target (10,000 counts per cell) to correct for variations in sequencing depth. A log-transformation is then applied to stabilize variance and make the data more comparable across cells. The core of the feature selection process is executed using the highly variable genes (HVG) method. Here, the script employs the Seurat flavor algorithm to rank genes based on the extent of their variability and selects the top 2000 most variable genes. These selected features are considered biologically informative, as they can reveal genuine cellular heterogeneity and reduce the impact of technical noise. Finally, the script prints the number of highly variable genes detected and produces a scatter plot that visualizes the relationship between mean expression and variability of the genes. This visualization helps in evaluating the effectiveness of the feature selection step. Overall, this workflow streamlines downstream analyses by focusing on the most relevant genetic markers, which is essential for accurate clustering, differential expression analysis, and other subsequent steps in single-cell studies.","scanpy, anndata",python,"# Import necessary libraries for single-cell analysis and data I/O
import scanpy as sc
import anndata as ad

# Set figure parameters for clear and consistent plotting
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Data Input: Load the built-in PBMC3k dataset as an example of single-cell RNA-seq data
adata = sc.datasets.pbmc3k()

# Save the raw count data for future reference if needed
adata.raw = adata.copy()

# ------------------------------
# Preprocessing for Feature Selection
# ------------------------------

# Normalize the total counts per cell to account for sequencing depth differences
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply a log(1+x) transformation to the normalized data to stabilize variance
sc.pp.log1p(adata)

# ------------------------------
# Feature Selection: Identify Highly Variable Genes
# ------------------------------

# Identify highly variable genes using the Seurat (v3) method by default.
# This step selects genes whose expression varies more than expected given their average expression.
# Adjust the n_top_genes parameter to select the desired number of features.
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')

# Print the number of highly variable genes detected for a quick inspection
print(""Number of highly variable genes:"", sum(adata.var.highly_variable))

# ------------------------------
# Plotting for Feature Selection
# ------------------------------

# Display a scatter plot where each gene is plotted by its mean expression versus its dispersion.
# Highly variable genes are highlighted in the plot, aiding in visual quality assessment.
sc.pl.highly_variable_genes(adata)
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html
scRNA-seq,Feature selection,"The code performs a critical feature selection step in single-cell RNA sequencing analysis using the Seurat framework. It begins by importing essential libraries for data handling and visualization and then loads raw 10X Genomics data, constructing a Seurat object after applying initial quality filters. This object encapsulates both the raw count data and its associated metadata, providing a structured foundation for downstream analysis. After the initial processing, the code normalizes the gene expression data using a global-scaling method, which ensures that differences in sequencing depth across cells are corrected by scaling and log-transforming the raw counts. With the data normalized, the script transitions to the central feature selection task: it identifies the top 2000 highly variable genes using a variance-stabilizing transformation method. These highly variable features are presumed to capture the most significant biological signals and are crucial for reducing dimensionality before subsequent analyses like PCA or clustering. The code also extracts the top 10 variable genes and generates a plot that visually represents the variability distribution across genes, with the top features clearly labeled. This visual aid enables researchers to assess the effectiveness of the feature selection process and to spot any outliers or inconsistencies. By isolating the most informative features, the approach minimizes noise, reduces computational overhead, and enhances the interpretability of subsequent analyses, ultimately leading to more accurate identification of cellular subpopulations and deeper insights into the underlying molecular biology.","Seurat, dplyr, ggplot2",R,"# Import necessary libraries for single-cell analysis and plotting
library(Seurat)   # For comprehensive single-cell data analysis
library(dplyr)    # For streamlined data manipulation
library(ggplot2)  # For enhanced visualization capabilities

# Data I/O: Load the raw 10X Genomics data.
# Update the 'data_dir' with the correct path to your filtered gene-barcode matrices.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object from the count matrix with basic filtering.
# Cells with fewer than 200 features (genes) or genes expressed in fewer than 3 cells are excluded.
seurat_obj <- CreateSeuratObject(counts = raw_data,
                                 project = ""FeatureSelectionDemo"",
                                 min.cells = 3,
                                 min.features = 200)

# OPTIONAL: Calculate the percentage of mitochondrial genes for quality assessment.
seurat_obj[[""percent.mt""]] <- PercentageFeatureSet(seurat_obj, pattern = ""^MT-"")

# Normalize the gene expression data using a global scaling method (""LogNormalize"").
seurat_obj <- NormalizeData(seurat_obj, normalization.method = ""LogNormalize"", scale.factor = 10000)

# Feature Selection: Identify highly variable features (genes) using the 'vst' method.
# Here, we select the top 2000 most variable features for downstream analysis.
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = ""vst"", nfeatures = 2000)

# Retrieve the top 10 variable features from the identified variable genes.
top10 <- head(VariableFeatures(seurat_obj), 10)

# Plotting: Create a variable feature plot to visualize the distribution of variability across genes.
variable_feature_plot <- VariableFeaturePlot(seurat_obj)

# Add labels to highlight the top 10 most variable genes on the plot.
labeled_plot <- LabelPoints(plot = variable_feature_plot, points = top10, repel = TRUE)
print(labeled_plot)

# Optionally, save the Seurat object with the feature selection results for further analysis.
saveRDS(seurat_obj, file = ""FeatureSelection_SeuratObject.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection
scRNA-seq,Feature selection,"The code performs critical preprocessing steps for single-cell RNA sequencing analysis by integrating feature selection and data scaling, both vital for enhancing downstream biological insights. It begins by importing essential libraries and reading raw count data from a 10X Genomics dataset to construct a Seurat object that stores the expression matrix along with essential metadata. This initial dataset is normalized using the ""LogNormalize"" method, which adjusts gene counts by each cell's total expression and scales them appropriately to account for technical biases, such as varying sequencing depths. Once normalized, the script identifies the top 2000 highly variable genes using a variance-stabilizing transformation approach (the ""vst"" method), enabling researchers to focus on genes that capture the most meaningful biological variation. A variable feature plot is generated, with the top 10 genes clearly labeled, allowing for an intuitive visual assessment of the selection process. Following feature selection, the code scales the data by centering the expression values of all genes??setting the mean expression to zero??and scaling to unit variance. This standardization process is crucial because it mitigates the impact of highly expressed genes overshadowing others and ensures that all selected features have equal weight in subsequent analyses such as principal component analysis (PCA), clustering, or differential expression testing. Overall, this preprocessing pipeline optimizes the dataset by reducing noise, standardizing gene expression, and isolating the most informative features for robust downstream bioinformatics analysis.","Seurat, dplyr, ggplot2",R,"# Import necessary libraries for single-cell RNA-seq analysis and visualization
library(Seurat)   # Provides tools for single-cell analysis
library(dplyr)    # For data manipulation
library(ggplot2)  # For enhanced plotting capabilities

# Data I/O: Load the raw 10X Genomics data.
# Replace the directory below with the path to your data.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""
raw_counts <- Read10X(data.dir = data_dir)

# Create a Seurat object from the count matrix.
# Cells with fewer than 200 features or genes expressed in fewer than 3 cells are filtered out.
seurat_object <- CreateSeuratObject(counts = raw_counts, 
                                    project = ""FeatureScalingDemo"", 
                                    min.cells = 3, 
                                    min.features = 200)

# Normalize the data using a global scaling method (""LogNormalize"").
# This normalizes each cell's gene counts by the total expression, scales by a factor (10,000),
# and log-transforms the result.
seurat_object <- NormalizeData(seurat_object, 
                               normalization.method = ""LogNormalize"", 
                               scale.factor = 10000)

# Feature Selection: Identify highly variable features (genes) using the variance-stabilizing transformation (""vst"") method.
# We select the top 2000 features which capture the major biological signal in the dataset.
seurat_object <- FindVariableFeatures(seurat_object, 
                                      selection.method = ""vst"", 
                                      nfeatures = 2000)

# Retrieve the top 10 variable features for labeling in the plot.
top10_features <- head(VariableFeatures(seurat_object), 10)

# Plot the variable features to visualize the distribution of gene variability.
# Label the top 10 most variable genes for clarity.
variable_feature_plot <- VariableFeaturePlot(seurat_object)
variable_feature_plot <- LabelPoints(plot = variable_feature_plot, 
                                     points = top10_features, 
                                     repel = TRUE)
print(variable_feature_plot)

# Scaling the Data: Apply a linear transformation to scale the data.
# This step centers the expression of each gene (mean = 0) and scales it (variance = 1),
# thereby reducing technical noise before downstream analyses.
all_genes <- rownames(seurat_object)
seurat_object <- ScaleData(seurat_object, features = all_genes)

# Generate a heatmap of the scaled data using the top variable features.
# This helps in visualizing the relative expression patterns across cells.
scaled_heatmap <- DoHeatmap(seurat_object, features = top10_features)
print(scaled_heatmap)

# Optionally, save the processed Seurat object to disk for downstream analysis.
saveRDS(seurat_object, file = ""Processed_SeuratObject_FeatureSelection_Scaling.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection
scRNA-seq,Dimensionality reduction,"This script performs an extensive dimensionality reduction analysis on single-cell RNA sequencing data to simplify and visualize complex gene expression patterns. It initiates by importing essential libraries and loading a built-in PBMC3k dataset, which serves as a representative example of real experimental data. The workflow begins with data preprocessing where total counts per cell are normalized to a preset target, ensuring that differences in sequencing depth are minimized, and a log-transformation is applied to stabilize the variance across cells. This preprocessing step is crucial as it reduces technical noise and enhances the biological signal. To focus the analysis on the most informative features, the script selects highly variable genes and scales the resulting data so that each gene is expressed with zero mean and unit variance. Thereafter, Principal Component Analysis (PCA) is employed to project the high-dimensional data into a lower-dimensional latent space, with the explained variance ratio plotted to highlight the contribution of each principal component. A scatter plot of the cells, based on the first two principal components and optionally colored by marker gene expression, offers an initial visual overview of the data structure. To further capture complex, non-linear relationships within the dataset, the script computes a neighborhood graph followed by Uniform Manifold Approximation and Projection (UMAP), resulting in a two-dimensional embedding that clearly delineates cell clusters. This integrated dimensionality reduction pipeline not only facilitates intuitive visualization and exploration of intrinsic cellular heterogeneity but also lays a solid foundation for subsequent clustering and downstream analyses.","scanpy, anndata, matplotlib",python,"# Import necessary libraries for single-cell data analysis and plotting
import scanpy as sc
import anndata as ad
import matplotlib.pyplot as plt

# Set up global plotting parameters for clear visualization
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Data I/O: Load the built-in PBMC 3k dataset from Scanpy.
# This dataset provides an example single-cell RNA sequencing data matrix.
adata = sc.datasets.pbmc3k()

# ------------------------------
# Preprocessing and Feature Selection
# ------------------------------

# Normalize total counts per cell to correct for differences in sequencing depth
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply logarithm transformation to stabilize the variance of gene expression levels
sc.pp.log1p(adata)

# Identify highly variable genes (HVGs) that are most informative for downstream analysis.
# Here we select the top 2000 variable genes using the Seurat method.
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')

# Subset the data to include only highly variable genes
adata = adata[:, adata.var.highly_variable]

# Scale the data so that each gene has zero mean and unit variance
sc.pp.scale(adata)

# ------------------------------
# Dimensionality Reduction via PCA
# ------------------------------

# Perform Principal Component Analysis (PCA) on the scaled data.
# This projects high-dimensional gene expression into a lower-dimensional latent space.
sc.tl.pca(adata, svd_solver='arpack')

# Plot the explained variance ratio to understand how much variance each PC explains.
# The log scale helps in visualizing both large and small contributions.
sc.pl.pca_variance_ratio(adata, log=True)

# Create a scatter plot of the cells in the space defined by the first two principal components.
# Optionally, color the cells based on the expression levels of one or more marker genes.
sc.pl.pca(adata, color=['CST3', 'NKG7'])

# ------------------------------
# Alternative Dimensionality Reduction: UMAP
# ------------------------------

# Compute the neighborhood graph of cells based on the PCA representation.
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)

# Run UMAP to obtain a non-linear embedding that preserves both local and global structure.
sc.tl.umap(adata)

# Visualize the UMAP embedding, coloring the cells by the expression of a chosen gene.
sc.pl.umap(adata, color='CST3')
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html
scRNA-seq,Dimensionality reduction,"The code implements a comprehensive dimensionality reduction workflow as part of a single-cell RNA sequencing analysis pipeline, focusing on reducing the complexity of high-dimensional gene expression data while preserving the underlying biological structure. It begins by importing essential libraries such as Scanpy, Seaborn, and Matplotlib, then reads in a preprocessed AnnData object containing normalized gene expression data. To prepare the data for dimensionality reduction, the normalized log-transformed values are set as the primary expression matrix, ensuring that only the informative features contribute to the analysis. The pipeline first employs Principal Component Analysis (PCA) on highly variable genes using an ARPACK solver, which transforms the data into a set of orthogonal components that capture the greatest variance. A scatter plot of the first two principal components is created, with cell points colored by total counts to evaluate technical variations. Next, a neighborhood graph is constructed based on the PCA results, which serves as a foundation for non-linear methods. t-SNE is then applied on this PCA representation to generate a two-dimensional embedding that reveals potential cell clustering patterns or batch effects, and a corresponding t-SNE plot is generated for visual assessment. Subsequently, the code employs UMAP to further project the high-dimensional data into a low-dimensional space, facilitating the visualization of the cellular landscape with preserved local and global structure. Finally, the enhanced AnnData object, now containing the PCA, t-SNE, and UMAP embeddings, is saved for downstream analyses such as clustering, trajectory inference, or differential expression studies.","scanpy, seaborn, matplotlib",python,"# Import necessary libraries
import scanpy as sc
import seaborn as sns
import matplotlib.pyplot as plt

# Set Scanpy verbosity and figure parameters for clear plots
sc.settings.verbosity = 0
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

# Load the preprocessed AnnData object (feature selection has been performed)
# Replace the filename and backup URL with your dataset if needed
adata = sc.read(""s4d8_feature_selection.h5ad"", backup_url=""https://figshare.com/ndownloader/files/40016014"")

# Use the normalized log1p data for dimensionality reduction.
# This layer is expected to store the normalized expression values.
adata.X = adata.layers[""log1p_norm""]

# ------------------------ PCA ------------------------
# Perform Principal Component Analysis (PCA) to reduce the dimensions.
# We use only the highly variable genes and an appropriate solver.
sc.pp.pca(adata, svd_solver=""arpack"", use_highly_variable=True)

# Visualize the PCA results by plotting the first two principal components.
# The scatter plot is colored by 'total_counts' to give a quality assessment.
sc.pl.pca_scatter(adata, color=""total_counts"", title=""PCA: First 2 Components"")

# ------------------------ t-SNE ------------------------
# Compute a neighborhood graph of cells based on the PCA representation.
sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)

# Run t-distributed Stochastic Neighbor Embedding (t-SNE) using the PCA space.
sc.tl.tsne(adata, use_rep=""X_pca"")

# Plot the t-SNE embedding colored by total counts for quality inspection.
sc.pl.tsne(adata, color=""total_counts"", title=""t-SNE Embedding"")

# ------------------------ UMAP ------------------------
# Compute the UMAP embedding from the neighborhood graph.
sc.tl.umap(adata)

# Plot the UMAP embedding, again colored by total counts.
sc.pl.umap(adata, color=""total_counts"", title=""UMAP Embedding"")

# ------------------------ Save Results ------------------------
# Save the updated AnnData object with the dimensionality reduction results.
adata.write(""s4d8_dimensionality_reduction.h5ad"")
",https://www.sc-best-practices.org/preprocessing_visualization/dimensionality_reduction.html
scRNA-seq,Dimensionality reduction,"The code is designed to reduce the complexity of single-cell RNA sequencing data by first preprocessing and then applying dimensionality reduction techniques while simultaneously determining the optimal number of dimensions to retain. Initially, it imports essential libraries and performs data I/O to load raw 10X Genomics data into a Seurat object, ensuring that the dataset is properly normalized and scaled after filtering out low-quality cells. The normalization process adjusts for sequencing depth differences, and scaling standardizes gene expression so that each gene has a mean expression of zero and unit variance. The core of the analysis involves applying Principal Component Analysis (PCA) to the subset of highly variable genes, transforming the high-dimensional data into a set of orthogonal principal components that capture the most significant sources of variation. To decide on the number of principal components that are biologically informative, the code generates an ElbowPlot, which visualizes the variance explained by each component; the ??elbow?? point in this plot serves as a heuristic for selecting the intrinsic dimensionality of the dataset. Finally, based on this determination, the code uses a non-linear dimensionality reduction technique (such as UMAP) to project the data into a two-dimensional space for visualization, effectively capturing both local and global relationships among cells. The enriched Seurat object, now containing PCA, UMAP embeddings, and the dimensionality evaluation, is then saved for further downstream analyses like clustering or trajectory inference.","Seurat, ggplot2, patchwork",R,"# Load required libraries for single-cell analysis and plotting
library(Seurat)      # Main package for single-cell workflows
library(ggplot2)     # For custom plotting
library(patchwork)   # For combining multiple plots

# Data I/O: Read the raw 10X Genomics count data from the specified directory.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""  # Update with your actual path
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object using the count matrix.
# Filters are applied to remove cells with very low gene counts.
seurat_obj <- CreateSeuratObject(counts = raw_data, 
                                 project = ""DimRed_DimDetermination"", 
                                 min.cells = 3, 
                                 min.features = 200)

# Data Preprocessing:
# 1. Normalize the data with a global scaling method (""LogNormalize"").
seurat_obj <- NormalizeData(seurat_obj, normalization.method = ""LogNormalize"", scale.factor = 10000)

# 2. Identify the highly variable features for capturing biological variability.
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = ""vst"", nfeatures = 2000)

# 3. Scale the data so that each gene has a mean of 0 and a variance of 1.
all_genes <- rownames(seurat_obj)
seurat_obj <- ScaleData(seurat_obj, features = all_genes)

# Dimensionality Reduction: Run PCA 
# This step finds the major axes (principal components) of variation using the highly variable genes.
seurat_obj <- RunPCA(seurat_obj, features = VariableFeatures(seurat_obj))

# Plot 1: Visualize the first two principal components in a scatter plot.
# Cells are colored by the 'nCount_RNA' metric to inspect technical variation.
pca_plot <- DimPlot(seurat_obj, reduction = ""pca"", group.by = ""nCount_RNA"") + 
  ggtitle(""PCA: PC1 vs PC2 (colored by nCount_RNA)"")

# Determine the 'dimensionality' of the dataset:
# The ElbowPlot displays the percentage of variance explained by each principal component.
# A clear 'elbow' in the plot can be used as a heuristic to choose the number of significant PCs.
elbow_plot <- ElbowPlot(seurat_obj, ndims = 50) + 
  ggtitle(""Elbow Plot: Variance Explained vs. PC"")

# Optionally, run non-linear dimensionality reduction (e.g., UMAP) using a chosen number of PCs.
# Here we use the first 10 PCs (as an example based on the elbow plot heuristic).
seurat_obj <- FindNeighbors(seurat_obj, dims = 1:10)
seurat_obj <- RunUMAP(seurat_obj, dims = 1:10)
umap_plot <- DimPlot(seurat_obj, reduction = ""umap"") + 
  ggtitle(""UMAP Embedding (Using PCs 1-10)"")

# Combine and display the PCA, Elbow, and UMAP plots side-by-side for easy comparison.
(pca_plot | elbow_plot) / umap_plot

# Save the processed Seurat object (with PCA, UMAP embeddings, etc.) for downstream analyses.
saveRDS(seurat_obj, file = ""DimRed_DimDetermined_SeuratObject.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection
scRNA-seq,Clustering,"This script performs a comprehensive clustering analysis on single-cell RNA sequencing data to reveal biologically meaningful subpopulations. It starts by importing essential libraries and loading a built-in PBMC3k dataset, ensuring that the raw count data is preserved for later reference. The pipeline then proceeds with key preprocessing steps: it normalizes the total counts per cell to mitigate differences in sequencing depth and applies a log-transformation to stabilize variance across the data. Highly variable genes are identified to concentrate on the most informative features, and the data is subsequently subsetted and scaled to standardize each gene's expression levels. Following these preparatory steps, principal component analysis (PCA) is performed to reduce the data's dimensionality and capture the primary axes of variation. The script then constructs a nearest-neighbor graph from the PCA-reduced data, forming the basis for both nonlinear dimensionality reduction and clustering. A UMAP embedding is computed to provide a clear, two-dimensional visualization of the cellular landscape, where the spatial distribution reflects intrinsic similarities among cells. Finally, the Leiden algorithm is applied to this neighbor graph to group cells into distinct clusters, which are then visualized on the UMAP plot by coloring each cluster uniquely. This integrated workflow is critical for identifying and characterizing heterogeneous cell groups, which in turn supports more detailed downstream analyses such as differential gene expression and cell type annotation, ultimately contributing to a deeper understanding of the underlying biological processes.",scanpy,python,"# Import necessary libraries for single-cell analysis and visualization
import scanpy as sc

# Set global plotting parameters for consistency and clarity
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Data I/O: Load the built-in PBMC3k dataset as an example of single-cell RNA-seq data
adata = sc.datasets.pbmc3k()

# Save the raw data for future reference
adata.raw = adata.copy()

# ------------------------------
# Preprocessing for Clustering
# ------------------------------
# Normalize total counts per cell to adjust for sequencing depth differences
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply a logarithmic transformation (log1p) to stabilize variance across cells
sc.pp.log1p(adata)

# Identify highly variable genes (feature selection) using the Seurat method
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')

# Subset the data matrix to include only the highly variable genes
adata = adata[:, adata.var.highly_variable]

# Scale the data so that each gene has zero-mean and unit variance
sc.pp.scale(adata)

# Perform Principal Component Analysis (PCA) to reduce dimensionality
sc.tl.pca(adata, svd_solver='arpack')

# Compute the neighborhood graph of cells based on the PCA representation
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)

# Generate a UMAP embedding from the neighbors graph for visualization purposes
sc.tl.umap(adata)

# ------------------------------
# Clustering Using the Leiden Algorithm
# ------------------------------
# Apply the Leiden clustering algorithm on the neighbor graph
# The flavor 'igraph' and a fixed number of iterations are used for speed and reproducibility.
sc.tl.leiden(adata, flavor='igraph', n_iterations=2)

# Visualize the UMAP embedding, where cells are colored by their assigned Leiden cluster
sc.pl.umap(adata, color=['leiden'], title=""Leiden Clustering on PBMC3k"", size=20)
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html
scRNA-seq,Clustering,"The code implements an unsupervised clustering pipeline specifically designed for single-cell RNA sequencing data, aiming to identify distinct cell populations based on their gene expression profiles. It begins by importing the necessary libraries and reading a preprocessed AnnData object containing dimensionality-reduced data from prior normalization steps. The workflow then computes a neighborhood graph using a specified number of nearest neighbors and principal components, which helps capture the local relationships among cells. Utilizing this graph, the code applies the Leiden clustering algorithm??a robust method that optimizes community structure on the graph??to partition the cells into discrete clusters, with the resolution parameter allowing fine-tuning of clustering granularity. For effective visualization and interpretation, the code generates a UMAP embedding that projects the high-dimensional data into a two-dimensional space, where cells are color-coded based on their assigned cluster labels, facilitating the visual assessment of the clustering structure. Diagnostic plots such as the UMAP scatter plot are produced to verify the integrity of the clusters, ensuring that clusters are not only statistically meaningful but also biologically interpretable. Finally, the enhanced AnnData object??including the clustering results and UMAP coordinates??is saved for subsequent analyses, such as differential gene expression or trajectory inference. This entire process provides a solid foundation for exploring cellular heterogeneity and uncovering underlying biological processes in complex single-cell datasets.","scanpy, matplotlib",python,"# Import necessary libraries
import scanpy as sc
import matplotlib.pyplot as plt

# Set Scanpy settings for improved plot aesthetics and reduced verbosity
sc.settings.verbosity = 0
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

# Load the preprocessed AnnData object that contains dimensionally reduced data.
# Replace the filename and backup URL as needed.
adata = sc.read(""s4d8_dimensionality_reduction.h5ad"", backup_url=""https://figshare.com/ndownloader/files/40016014"")
# The dataset is expected to have been processed with normalization and dimensionality reduction previously.

# Compute the neighborhood graph using PCA to capture local cell relationships.
# Here we use 15 nearest neighbors and 30 principal components.
sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30)

# Run the Leiden clustering algorithm to partition cells into distinct clusters.
# The 'resolution' parameter controls the granularity of the clustering.
sc.tl.leiden(adata, resolution=1.0, key_added=""leiden"")

# Compute the UMAP embedding for visualization (if not already computed).
sc.tl.umap(adata)

# Visualize the UMAP embedding and color the cells by their assigned Leiden cluster.
sc.pl.umap(adata, color=[""leiden""], title=""Leiden Clustering"", legend_loc='on data')

# Save the updated AnnData object containing the clustering results for downstream analysis.
adata.write(""s4d8_clustering.h5ad"")
",https://www.sc-best-practices.org/cellular_structure/clustering.html
scRNA-seq,Clustering,"The code executes a comprehensive clustering analysis for single-cell RNA sequencing data using the Seurat framework, with the goal of partitioning cells into distinct groups that capture their underlying biological differences. It begins by importing essential libraries, such as Seurat for analysis, dplyr for data manipulation, and ggplot2 along with patchwork for visualization, ensuring all necessary tools are available. Next, the script reads raw count data from a 10X Genomics dataset and constructs a Seurat object, applying preliminary quality filters to remove cells with low gene counts and to control for technical artifacts such as high mitochondrial RNA content. The data is then normalized to compensate for sequencing depth variations, and highly variable features are identified to focus on biologically informative genes. Following normalization and feature selection, the code performs Principal Component Analysis (PCA) on the identified variable genes to reduce the dimensionality of the dataset, capturing its major sources of variation in orthogonal components; a PCA plot is generated to visualize these trends. Subsequently, it constructs a k-nearest neighbor graph based on the first ten principal components, which lays the groundwork for identifying cell communities. Using a graph-based clustering algorithm with a specified resolution, the script partitions the cells into clusters, effectively distinguishing cell populations with similar expression profiles. Finally, non-linear dimensionality reduction via UMAP is applied to project the high-dimensional data into two dimensions for intuitive visualization of the clusters, and the updated Seurat object containing the clustering results is saved for further downstream analysis.","Seurat, dplyr, ggplot2, patchwork",R,"# Load required libraries for single-cell analysis, data manipulation, and plotting
library(Seurat)      # Main package for single-cell RNA-seq analysis
library(dplyr)       # For data manipulation
library(ggplot2)     # For enhanced plotting capabilities
library(patchwork)   # For combining plots

# Data I/O: Read raw count data from a 10X Genomics folder.
# Replace the path with the directory containing your filtered_gene_bc_matrices.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object from the raw count matrix.
# Low-quality cells are filtered by requiring a minimum number of cells and features.
seurat_obj <- CreateSeuratObject(counts = raw_data, project = ""ClusteringDemo"",
                                 min.cells = 3, min.features = 200)

# Calculate the percentage of mitochondrial genes as a quality control metric
seurat_obj[[""percent.mt""]] <- PercentageFeatureSet(seurat_obj, pattern = ""^MT-"")

# Visualize QC metrics (optional) with violin plots for basic inspection.
VlnPlot(seurat_obj, features = c(""nFeature_RNA"", ""nCount_RNA"", ""percent.mt""), ncol = 3)

# Normalize the data using a global scaling method to account for sequencing depth differences.
seurat_obj <- NormalizeData(seurat_obj, normalization.method = ""LogNormalize"", scale.factor = 10000)

# Identify highly variable features that capture the major biological signals.
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = ""vst"", nfeatures = 2000)

# Scale the data so that each gene is centered (mean=0) and has unit variance.
seurat_obj <- ScaleData(seurat_obj, features = rownames(seurat_obj))

# Perform Principal Component Analysis (PCA) on the variable features for initial dimensionality reduction.
seurat_obj <- RunPCA(seurat_obj, features = VariableFeatures(seurat_obj))
# Plot a PCA scatter plot to visualize the major sources of variation.
DimPlot(seurat_obj, reduction = ""pca"") + ggtitle(""PCA Plot"")

# Build a K-nearest neighbor graph based on the first 10 principal components.
seurat_obj <- FindNeighbors(seurat_obj, dims = 1:10)

# Perform clustering using a graph-based approach: adjust the resolution to change granularity.
seurat_obj <- FindClusters(seurat_obj, resolution = 0.5)
# The cluster identity is stored in the Seurat object and can be viewed via Idents(seurat_obj)

# Run UMAP for non-linear dimensionality reduction to visualize clusters in 2D space.
seurat_obj <- RunUMAP(seurat_obj, dims = 1:10)
# Generate a UMAP plot with cluster labels
umap_plot <- DimPlot(seurat_obj, reduction = ""umap"", label = TRUE, pt.size = 0.8) +
             ggtitle(""UMAP Plot with Cluster Labels"")
print(umap_plot)

# Optionally, save the processed Seurat object (with clustering results) for later downstream analysis.
saveRDS(seurat_obj, file = ""Clustering_SeuratObject.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection
scRNA-seq,Annotation,"This script performs a comprehensive cell-type annotation workflow on single-cell RNA sequencing data, aiming to assign biological identities to individual cells based on their gene expression profiles. It begins by importing essential libraries and loading a representative dataset of human peripheral blood mononuclear cells, thereby establishing a realistic experimental context. The data undergoes standard preprocessing steps, including normalization to adjust for sequencing depth and log-transformation to stabilize variance. Highly variable genes are identified to capture the most informative features, and dimensionality reduction is achieved using PCA and UMAP, which collectively reveal intrinsic patterns within the dataset. Clustering is carried out using the Leiden algorithm to group cells with similar expression characteristics. To annotate these clusters, the script defines a set of canonical marker genes for typical immune cell types??such as T cells, B cells, NK cells, and monocytes??and visualizes their expression using dot plots. These plots facilitate the manual interpretation of marker patterns across clusters, enabling the assignment of specific cell-type labels to each cluster. The cell-type annotations are then integrated into the dataset??s metadata, and a final UMAP plot displays the cells color-coded by their assigned identities. This systematic approach not only leverages known biological markers to decipher cellular heterogeneity but also provides a reliable foundation for subsequent downstream analyses, such as differential gene expression and pathway enrichment studies, thereby deepening our understanding of the immune cell landscape.","scanpy, annodata",python,"# Import necessary libraries for single-cell analysis and plotting
import scanpy as sc
import anndata as ad

# Set global plotting parameters for clear visualization
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Data I/O: Load the built-in PBMC3k dataset as an example of single-cell RNA-seq data
adata = sc.datasets.pbmc3k()

# ------------------------------
# Preprocessing and Clustering
# ------------------------------

# Normalize total counts for each cell to correct for sequencing depth
sc.pp.normalize_total(adata, target_sum=1e4)

# Apply a logarithmic transformation (log1p) to stabilize variance in the data
sc.pp.log1p(adata)

# Identify highly variable genes in the dataset (feature selection)
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')

# Subset the data to include only the highly variable genes
adata = adata[:, adata.var.highly_variable]

# Scale the data so that each gene has zero mean and unit variance
sc.pp.scale(adata)

# Perform principal component analysis (PCA) for dimensionality reduction
sc.tl.pca(adata, svd_solver='arpack')

# Compute the neighborhood graph of cells based on the PCA results
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)

# Generate a UMAP embedding from the neighbor graph for visualization
sc.tl.umap(adata)

# Cluster cells using the Leiden algorithm to identify groups for annotation
sc.tl.leiden(adata)

# ------------------------------
# Cell-Type Annotation
# ------------------------------

# Define a dictionary of marker genes for common cell types in peripheral blood.
# These markers are used for manual annotation of cell types.
marker_genes = {
    'B cells': ['MS4A1', 'CD79A'],
    'T cells': ['CD3D', 'CD3E'],
    'NK cells': ['NKG7', 'GNLY'],
    'Monocytes': ['CD14', 'LYZ']
}

# Generate a dot plot to visualize the expression of marker genes across Leiden clusters.
# This helps to determine which cluster corresponds to which cell type.
sc.pl.dotplot(adata, marker_genes, groupby='leiden', standard_scale='var',
              title='Marker Expression by Leiden Clusters')

# Based on the marker gene expression patterns observed in the dot plot,
# manually map clusters (Leiden labels) to cell type annotations.
# (The mapping below is an example; adjust based on the specific expression patterns.)
cluster_to_cell_type = {
    '0': 'T cells',
    '1': 'Monocytes',
    '2': 'NK cells',
    '3': 'B cells',
    '4': 'T cells'
}

# Create a new observation column 'cell_type' in the AnnData object using the above mapping.
adata.obs['cell_type'] = adata.obs['leiden'].map(cluster_to_cell_type).astype('category')

# ------------------------------
# Plotting Annotated Cell Types
# ------------------------------

# Visualize the UMAP embedding colored by the manually assigned cell-type annotations.
sc.pl.umap(adata, color='cell_type', title='Cell Type Annotation', legend_loc='on data')
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html
scRNA-seq,Annotation,"The code implements a manual annotation workflow for single-cell RNA sequencing data analysis by integrating biological expertise with computational methods to assign cell type labels. It begins by importing essential libraries for single-cell analysis and visualization and loading a preprocessed AnnData object that contains clustering results (e.g., derived from Leiden clustering). Using a predefined dictionary, the code maps cluster identifiers to cell type labels based on known marker genes and prior biological knowledge, thereby translating algorithmically defined clusters into biologically meaningful cell type annotations. This manual mapping is stored in a new observation column within the AnnData object, allowing users to interpret and validate the cell identities directly. The code also prints a summary of the annotated cell types to provide a quick overview of the dataset composition. To facilitate visual inspection and quality control, a UMAP embedding is generated (if not already available) to project the high-dimensional data into two dimensions, with cells color-coded according to their manual annotations. This visualization helps ensure that similar cell types cluster together and align with expected biological patterns. Finally, the updated AnnData object containing the manual annotations is saved for subsequent analyses such as differential expression, trajectory inference, or further integrative analyses. Overall, this workflow bridges computational clustering and expert-driven annotation, enabling the transformation of unsupervised clusters into validated biological categories, which is critical for accurate downstream interpretation of single-cell transcriptomic data.","scanpy, matplotlib",python,"# Import necessary libraries for single-cell analysis and plotting
import scanpy as sc
import matplotlib.pyplot as plt

# Set Scanpy settings to control verbosity and ensure high-quality figure output
sc.settings.verbosity = 0
sc.settings.set_figure_params(dpi=80, facecolor=""white"", frameon=False)

# Load the preprocessed and clustered AnnData object from file.
# This object is expected to have clustering results (e.g., in the ""leiden"" column).
adata = sc.read(""s4d8_clustering.h5ad"", backup_url=""https://figshare.com/ndownloader/files/40016014"")

# Define a dictionary mapping cluster IDs (as stored in adata.obs['leiden'])
# to manually curated cell type annotations.
manual_labels = {
    ""0"": ""B cell"",
    ""1"": ""T cell"",
    ""2"": ""Myeloid cell"",
    ""3"": ""NK cell"",
    ""4"": ""Dendritic cell""
    # Additional clusters will be marked as ""Unknown"" if not explicitly mapped.
}

# Create a new column in the AnnData object for manual cell type annotation.
# For any cluster not present in the dictionary, default to ""Unknown"".
adata.obs[""manual_annotation""] = adata.obs[""leiden""].map(lambda x: manual_labels.get(x, ""Unknown""))

# Print a summary of how many cells are assigned to each annotated cell type.
print(""Manual annotation summary:"")
print(adata.obs[""manual_annotation""].value_counts())

# Compute a UMAP embedding if not already available in the AnnData object.
if ""X_umap"" not in adata.obsm.keys():
    sc.tl.umap(adata)

# Visualize the UMAP embedding colored by the manually annotated cell types.
sc.pl.umap(adata, color=""manual_annotation"", title=""Manual Cell Type Annotation"", legend_loc=""on data"")

# Save the updated AnnData object with the manual annotations for downstream analyses.
adata.write(""s4d8_manual_annotation.h5ad"")
",https://www.sc-best-practices.org/cellular_structure/annotation.html
scRNA-seq,Annotation,"The code is designed to identify and validate cluster-specific biomarkers through differential expression analysis, and then to use these features for the annotation of cell type identities within a single-cell RNA sequencing dataset. It begins by importing the necessary libraries and reading in the raw data from a 10X Genomics source, constructing a Seurat object with minimal quality control filters to retain high-quality cells. The data is subsequently normalized and scaled, and highly variable genes are selected to focus on the most informative features. Principal component analysis (PCA) is performed to reduce the dataset??s dimensionality, after which a graph-based clustering algorithm groups cells based on their expression profiles. The core of the analysis involves running differential expression tests using functions like FindAllMarkers, which systematically compare each cluster against all other cells to identify genes with significant expression differences. These differentially expressed genes serve as candidate biomarkers that characterize the distinct clusters. To translate these computational findings into biological insight, the code then assigns cell type identities to each cluster based on the expression of well-known canonical markers. This annotation step is critical because it bridges the gap between unsupervised cluster detection and known biological cell types. The final results, including UMAP plots with overlaid cluster and cell type labels and heatmaps of marker gene expression, allow for intuitive visual verification of the clustering outcome and the accuracy of the cell type assignments, setting the stage for further downstream analysis.","Seurat, dplyr, ggplot2, patchwork",R,"# Load necessary libraries for single-cell analysis, data manipulation, and plotting
library(Seurat)      # Core package for single-cell RNA-seq analysis
library(dplyr)       # For data manipulation
library(ggplot2)     # For plotting
library(patchwork)   # For combining multiple plots

# Data I/O: Read raw 10X Genomics data from a specified folder.
# Replace the path with the directory containing your filtered gene/barcode matrices.
data_dir <- ""path/to/filtered_gene_bc_matrices/hg19/""
raw_data <- Read10X(data.dir = data_dir)

# Create a Seurat object from the raw count matrix, filtering out low-quality cells.
seurat_obj <- CreateSeuratObject(counts = raw_data, project = ""ClusterBiomarkers"",
                                 min.cells = 3, min.features = 200)

# (Optional) Calculate the percentage of mitochondrial gene expression for QC purposes.
seurat_obj[[""percent.mt""]] <- PercentageFeatureSet(seurat_obj, pattern = ""^MT-"")

# Normalize the data using LogNormalize and identify highly variable features.
seurat_obj <- NormalizeData(seurat_obj, normalization.method = ""LogNormalize"", scale.factor = 10000)
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = ""vst"", nfeatures = 2000)

# Scale all genes in the dataset.
all_genes <- rownames(seurat_obj)
seurat_obj <- ScaleData(seurat_obj, features = all_genes)

# Run PCA on the highly variable features to reduce dimensionality.
seurat_obj <- RunPCA(seurat_obj, features = VariableFeatures(seurat_obj))

# Construct a k-nearest neighbors graph based on the first 10 PCs and perform clustering.
seurat_obj <- FindNeighbors(seurat_obj, dims = 1:10)
seurat_obj <- FindClusters(seurat_obj, resolution = 0.5)

# Run UMAP for non-linear dimensionality reduction and visualization.
seurat_obj <- RunUMAP(seurat_obj, dims = 1:10)
umap_plot <- DimPlot(seurat_obj, reduction = ""umap"", label = TRUE, pt.size = 0.8) +
             ggtitle(""UMAP Plot: Clusters before Cell Type Assignment"")
print(umap_plot)

# ---- Finding Differentially Expressed Features (Cluster Biomarkers) ----
# Find markers that distinguish each cluster from all other cells;
# only positive markers with minimum expression in at least 25% of cells and a log fold-change threshold of 0.25 are selected.
cluster_markers <- FindAllMarkers(seurat_obj, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)
# Print the top few markers to inspect the results.
print(head(cluster_markers))

# Visualize marker expression using a heatmap.
# Here, we extract top markers per cluster (e.g., top 2 by avg_log2FC) and plot them.
top_markers <- cluster_markers %>%
               group_by(cluster) %>%
               slice_max(order_by = avg_log2FC, n = 2)
heatmap_plot <- DoHeatmap(seurat_obj, features = top_markers$gene) + NoLegend()
print(heatmap_plot)

# ---- Assigning Cell Type Identity to Clusters ----
# Based on canonical markers from literature, manually define new cell type names corresponding to clusters.
# (Adjust the names and their order based on the number and nature of clusters in your data.)
new.cluster.ids <- c(""Naive CD4 T"", ""CD14+ Monocytes"", ""Memory CD4 T"", ""B"", 
                     ""CD8 T"", ""NK"", ""Dendritic"", ""Platelets"")
# The names must match the levels (cluster IDs) in the Seurat object.
names(new.cluster.ids) <- levels(seurat_obj)
# Assign the new identities.
seurat_obj <- RenameIdents(seurat_obj, new.cluster.ids)

# Visualize the clusters with their new cell type identities on the UMAP plot.
celltype_umap <- DimPlot(seurat_obj, reduction = ""umap"", label = TRUE, pt.size = 0.8) +
                 ggtitle(""UMAP Plot: Cell Type Identities"")
print(celltype_umap)

# Optionally, save the updated Seurat object for downstream analysis.
saveRDS(seurat_obj, file = ""ClusterBiomarkers_CellType_SeuratObject.rds"")
",https://satijalab.org/seurat/articles/pbmc3k_tutorial#identification-of-highly-variable-features-feature-selection
scRNA-seq,Annotation,"The code implements an automated cell type annotation pipeline for single-cell RNA sequencing data using CellTypist. It begins by importing essential libraries??Scanpy for single-cell data processing, CellTypist for annotation, and Matplotlib for visualization??ensuring the analytical environment is properly set up. The workflow loads a preprocessed AnnData object containing 2,000 cells and prints its dimensions to confirm data integrity. It then proceeds to download the most recent CellTypist models, ensuring that the annotation is based on up-to-date reference information. In this example, the built-in model ""Immune_All_Low.pkl"" is chosen, which is specifically optimized for fine resolution annotation of immune cell populations. The script applies the CellTypist annotation function using a majority voting approach, automatically assigning each cell a predicted label and calculating an associated confidence score. These results are stored directly within the AnnData object, integrating the predictions with existing metadata. To facilitate visual evaluation, the code computes a neighborhood graph and subsequently generates a UMAP embedding, where cells are colored by their predicted labels in one plot and by annotation confidence in another. This dual visualization allows users to assess both the biological relevance of the assignments and the reliability of the predictions. Ultimately, the annotated dataset is saved in AnnData format for further downstream analysis, such as clustering or differential expression studies, making this pipeline an efficient approach to integrate automated machine learning-based annotation into standard single-cell RNA-seq workflows.","scanpy, celltypist, matplotlib",python,"# Import required libraries
import scanpy as sc
import celltypist
from celltypist import models
import matplotlib.pyplot as plt

# Set Scanpy settings for clear plotting and informative logging
sc.settings.verbosity = 2
sc.settings.set_figure_params(dpi=80, facecolor='white', frameon=False)

# Load a preprocessed single-cell dataset (AnnData object)
# Replace the file path and backup URL as needed.
adata = sc.read(""demo_2000_cells.h5ad"",
                backup_url=""https://celltypist.cog.sanger.ac.uk/Notebook_demo_data/demo_2000_cells.h5ad"")
print(""Data shape:"", adata.shape)

# Download the latest CellTypist models
# force_update=True will ensure that the latest models are fetched.
models.download_models(force_update=True)

# Load a built-in CellTypist model; here we use ""Immune_All_Low.pkl"" for fine resolution immune annotation.
model = models.Model.load(model=""Immune_All_Low.pkl"")

# Run the CellTypist automatic annotation using majority voting.
# The function returns a predictions object that contains the predicted labels and confidence scores.
print(""Starting automatic annotation using CellTypist..."")
predictions = celltypist.annotate(adata, model=model, majority_voting=True)

# Save predictions to the AnnData object for later reference.
adata.obs[""celltypist_cell_label""] = predictions.predicted_labels
adata.obs[""celltypist_confidence""] = predictions.confidence

# Generate a UMAP embedding for visualization.
# First, compute the neighborhood graph (if not already done), then compute UMAP.
sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)
sc.tl.umap(adata)

# Plot the UMAP embedding with cells colored by predicted cell labels and with a separate plot for annotation confidence.
sc.pl.umap(adata, color=[""celltypist_cell_label"", ""celltypist_confidence""],
           wspace=0.4, title=[""CellTypist: Predicted Labels"", ""Annotation Confidence""])

# Save the annotated AnnData object for downstream analyses.
adata.write(""celltypist_annotated.h5ad"")
",https://www.sc-best-practices.org/cellular_structure/annotation.html
scRNA-seq,Annotation,"This code performs cell type annotation on single-cell RNA sequencing data using the CellAssign probabilistic model. The workflow begins by importing essential libraries for file management, data analysis, and visualization, such as os, tempfile, matplotlib, pandas, scanpy, scvi, seaborn, and torch. It then creates a temporary directory and downloads a follicular lymphoma dataset along with a marker gene matrix that contains prior knowledge about gene markers for specific cell types. After loading the dataset into an AnnData object via Scanpy and ensuring unique gene and observation names, the code subsets the data to include only the genes present in the marker matrix. It computes library sizes for each cell and normalizes them into a ??size_factor,?? which is critical for adjusting differences in sequencing depth across cells. The AnnData object is then set up for CellAssign integration using the size factor, and the CellAssign model is initialized with the marker matrix. Training the model over a specified number of epochs allows it to learn soft probabilistic assignments of cells to the pre-defined cell types based on the observed expression patterns. Convergence of the training process is monitored by plotting the validation ELBO curve. Finally, the code visualizes the soft assignment probabilities using a heatmap and projects the annotated cells onto a UMAP embedding, with cells colored by their predicted cell types. This comprehensive pipeline facilitates accurate annotation of cellular heterogeneity in complex biological samples.","os, tempfile, matplotlib, pandas, scanpy, scvi, seaborn, torch",python,"# Import necessary libraries
import os
import tempfile
import matplotlib.pyplot as plt
import pandas as pd
import scanpy as sc
import scvi
import seaborn as sns
import torch
from scvi.external import CellAssign

# Set plotting parameters and computation precision
sc.set_figure_params(figsize=(6, 6), frameon=False)
sns.set_theme()
torch.set_float32_matmul_precision(""high"")

# Create a temporary directory for data storage
save_dir = tempfile.TemporaryDirectory()

# Define file paths for the dataset and the marker gene matrix
adata_path = os.path.join(save_dir.name, ""sce_follicular.h5ad"")
marker_path = os.path.join(save_dir.name, ""FL_celltype.csv"")

# Download the follicular lymphoma dataset and marker gene CSV (if not available locally)
os.system(f""wget -q https://ndownloader.figshare.com/files/27458798 -O {adata_path}"")
os.system(f""wget -q https://ndownloader.figshare.com/files/27458831 -O {marker_path}"")

# Load the dataset as an AnnData object using Scanpy
adata = sc.read(adata_path)
adata.var_names_make_unique()
adata.obs_names_make_unique()

# Load the marker gene matrix using pandas (marker genes should be in rows)
marker_gene_mat = pd.read_csv(marker_path, index_col=0)

# Subset the AnnData object to include only the genes present in the marker matrix
adata_subset = adata[:, marker_gene_mat.index].copy()

# Compute per-cell library sizes and add a normalized size factor to the observations
library_sizes = adata_subset.X.sum(1)
adata_subset.obs[""size_factor""] = library_sizes / library_sizes.mean()

# Setup the AnnData object for CellAssign using the calculated size factors
scvi.external.CellAssign.setup_anndata(adata_subset, size_factor_key=""size_factor"")

# Initialize the CellAssign model with the marker gene matrix
model = CellAssign(adata_subset, marker_gene_mat)

# Train the CellAssign model (here, using 400 epochs as an example)
model.train(max_epochs=400)

# Plot the validation ELBO convergence curve to inspect model training
model.history[""elbo_validation""].plot()
plt.xlabel(""Epoch"")
plt.ylabel(""Validation ELBO"")
plt.title(""CellAssign Convergence"")
plt.show()

# Predict soft cell type assignment probabilities for each cell
predictions = model.predict()

# Visualize the probability matrix with a heatmap (each row: a cell, each column: a",https://docs.scvi-tools.org/en/stable/tutorials/notebooks/scrna/cellassign_tutorial.html
scRNA-seq,Integration,"The code implements a robust batch integration workflow for single-cell RNA sequencing data by leveraging batch-aware feature selection coupled with BBKNN integration. It starts by importing essential libraries such as Scanpy, BBKNN, and Matplotlib, and then reads in cell expression data stored in an AnnData object. To minimize confounding technical variations across batches, the script performs batch-aware highly variable gene selection using a specified batch key, ensuring that only consistently variable genes across different batches are retained. The data is then subsetted to these informative features and further normalized by adjusting for total counts, log-transforming, and scaling the expression values. Principal Component Analysis (PCA) is applied next to reduce the dimensionality of the data and capture the major sources of variation. Building on this reduced space, BBKNN is used to construct a batch-balanced k-nearest neighbor graph, where nearest neighbors are identified within each batch individually, then merged to establish a corrected connectivity matrix that effectively mitigates batch effects. A UMAP embedding is subsequently computed based on the BBKNN graph, providing a two-dimensional visualization that enables the evaluation of integration quality??cells are colored by their batch labels to assess whether different batches mix appropriately. Finally, the integrated dataset, now corrected for batch-specific biases, is saved for downstream analyses such as clustering and trajectory inference, ensuring reliable biological interpretations across combined datasets.","numpy, scanpy, bbknn, matplotlib",python,"# Import necessary libraries
import numpy as np
import scanpy as sc
import bbknn
import matplotlib.pyplot as plt

# Set logging level and figure parameters for clear visualization
sc.settings.verbosity = 3
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Load your single-cell AnnData object from file.
# Replace ""your_data.h5ad"" with your actual data file path.
adata = sc.read(""your_data.h5ad"")

# ---------------------------
# Batch-aware Feature Selection
# ---------------------------
# Select highly variable genes (HVGs) using a batch-aware approach.
# This uses the 'batch' column in adata.obs to compute HVGs per batch.
sc.pp.highly_variable_genes(
    adata,
    n_top_genes=2000,
    flavor=""cell_ranger"",   # or another flavor as appropriate
    batch_key=""batch""
)
# Subset the data to contain only the selected HVGs.
adata = adata[:, adata.var.highly_variable].copy()

# ---------------------------
# Preprocessing and Dimensionality Reduction
# ---------------------------
# Normalize total counts per cell, apply log transformation, and scale the data.
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)
sc.pp.scale(adata)

# Compute Principal Component Analysis (PCA) for dimensionality reduction.
sc.tl.pca(adata, n_comps=50, svd_solver='arpack')

# ---------------------------
# Batch-aware Integration with BBKNN
# ---------------------------
# Run BBKNN to compute a balanced k-nearest neighbor graph.
# BBKNN identifies neighbors within each batch separately (using the 'batch' key)
# and then merges these results to produce a batch-corrected connectivity graph.
bbknn.bbknn(adata, batch_key='batch', neighbors_within_batch=3)

# ---------------------------
# Visualization
# ---------------------------
# Compute the UMAP embedding based on the BBKNN-corrected neighbor graph.
sc.tl.umap(adata)

# Create a UMAP plot colored by batch to assess the effectiveness of integration.
sc.pl.umap(adata, color=['batch'], title=""UMAP after BBKNN Integration"", show=True)

# ---------------------------
# Save Integrated Data
# ---------------------------
# Write the updated AnnData object (now containing integration corrections)
# to a file for downstream analysis.
adata.write(""bbknn_integrated_data.h5ad"")
",https://www.sc-best-practices.org/cellular_structure/integration.html
scRNA-seq,Integration,"This script performs an ingest-based integration task to map a query single-cell RNA sequencing dataset onto a well-annotated reference dataset, facilitating consistent downstream analyses. It begins by importing essential libraries??Scanpy, Anndata, and Matplotlib??and loading two datasets: a reference dataset with precomputed PCA, neighbor graph, UMAP embedding, and clustering (using the Louvain algorithm), and a separate query dataset that requires annotation. To ensure compatibility, the script intersects the gene lists of both datasets so that the integration occurs over a common set of features. After preprocessing the reference dataset, including PCA and UMAP computation to capture its intrinsic structure, the core of the integration is performed using Scanpy??s `ingest` function. This function projects the query dataset into the PCA space learned from the reference and maps the cluster labels (e.g., ??louvain??) and UMAP coordinates from the reference onto the query data. For clarity in visualization, the reference??s color scheme for clusters is carried over to the query. Finally, the script generates separate UMAP plots for the integrated query dataset and a combined UMAP of both reference and query datasets, allowing for a direct visual comparison of cell distribution across batches. This integration pipeline is crucial for transferring established annotations to new datasets, thereby harmonizing different experiments, minimizing batch effects, and enabling more robust interpretation of cellular heterogeneity in subsequent analyses.","anndata, scanpy, matplotlib",python,"# Import necessary libraries for single-cell analysis and plotting
import anndata
import scanpy as sc
import matplotlib.pyplot as plt

# Set global settings for clear plotting and logging information
sc.settings.verbosity = 2  # Set verbosity level for detailed logging
sc.settings.set_figure_params(dpi=80, facecolor='white', figsize=(4, 4))

# ------------------------------
# Data Input: Load Reference and Query Datasets
# ------------------------------
# Load a preprocessed reference dataset (PBMC3k) which already has clustering and UMAP computed.
adata_ref = sc.datasets.pbmc3k_processed()

# Load a query dataset (PBMC68k reduced) for which we wish to map annotations.
adata = sc.datasets.pbmc68k_reduced()

# Ensure both datasets share the same set of genes by intersecting their variable names
var_names = adata_ref.var_names.intersection(adata.var_names)
adata_ref = adata_ref[:, var_names].copy()
adata = adata[:, var_names].copy()

# ------------------------------
# Preprocessing and Embedding on the Reference Dataset
# ------------------------------
# If not already computed, perform PCA on the reference dataset.
sc.pp.pca(adata_ref, n_comps=50)

# Compute a neighbors graph based on the PCA results.
sc.pp.neighbors(adata_ref, n_neighbors=15, n_pcs=50)

# Compute UMAP embedding on the reference data.
sc.tl.umap(adata_ref)

# Perform clustering on the reference dataset using the Louvain algorithm.
sc.tl.louvain(adata_ref)

# Visualize the reference UMAP colored by Louvain clusters.
sc.pl.umap(adata_ref, color='louvain', title='Reference UMAP with Louvain Clusters')

# ------------------------------
# Integrate Query Data Using Ingest
# ------------------------------
# The ingest function maps labels (here, ""louvain"") and embeddings from adata_ref onto adata.
sc.tl.ingest(adata, adata_ref, obs='louvain')

# To ensure consistent color mapping on plots, copy the reference??s cluster colors.
adata.uns['louvain_colors'] = adata_ref.uns['louvain_colors']

# Visualize the integrated query dataset using the ingested UMAP embedding.
sc.pl.umap(adata, color=['louvain'], title='Query UMAP with Ingested Annotations', size=30)

# ------------------------------
# (Optional) Combined Visualization of Reference and Query Data
# ------------------------------
# Concatenate the reference and query datasets for a joint UMAP visualization.
adata_concat = anndata.concat([adata_ref, adata], label='batch', keys=['reference', 'query'])
sc.pl.umap(adata_concat, color=['batch', 'louvain'],
           title='Combined UMAP: Reference and Query', wspace=0.5, size=20)
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/integrating-data-using-ingest.html
scRNA-seq,Integration,"This code performs the integration and analysis of single-cell RNA sequencing (scRNA-seq) data using scVI, a deep generative model designed for handling batch effects and extracting meaningful biological variation. The pipeline starts by importing necessary libraries and loading a lung atlas dataset, ensuring the data is properly preprocessed by selecting highly variable genes. The data is then registered for scVI analysis, where a model is trained to learn a latent representation of the cells. This latent space allows for clustering cells based on biological similarities, independent of batch effects. After training, the model produces a structured representation that preserves biological signals while minimizing technical artifacts. Finally, the data is visualized using UMAP to reveal cellular organization, batch mixing, and potential biological insights, such as identifying distinct cell types or subpopulations. This approach enables researchers to analyze complex multi-sample datasets in a unified framework, facilitating biological discovery and improving the accuracy of downstream analyses such as differential expression or lineage inference.","os, tempfile, scanpy, scvi, seabor, torch",python,"# Import necessary libraries
import os
import tempfile
import scanpy as sc
import scvi
import seaborn as sns
import torch

# Set parameters for visualization
sc.set_figure_params(figsize=(6, 6), frameon=False)
sns.set_theme()
torch.set_float32_matmul_precision(""high"")

# Define directory for saving the dataset
save_dir = tempfile.TemporaryDirectory()

# Load dataset
adata_path = os.path.join(save_dir.name, ""lung_atlas.h5ad"")
adata = sc.read(
    adata_path,
    backup_url=""https://figshare.com/ndownloader/files/24539942"",
)

# Check dataset structure
print(adata)

# Preprocess dataset: Select highly variable genes for integration
adata.raw = adata  # Store full dimension data
sc.pp.highly_variable_genes(
    adata,
    flavor=""seurat_v3"",
    n_top_genes=2000,
    layer=""counts"",
    batch_key=""batch"",
    subset=True,
)

# Register data with scVI
scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""batch"")

# Initialize scVI model
model = scvi.model.SCVI(adata, n_layers=2, n_latent=30, gene_likelihood=""nb"")

# Train model
model.train()

# Extract latent representation
SCVI_LATENT_KEY = ""X_scVI""
adata.obsm[SCVI_LATENT_KEY] = model.get_latent_representation()

# Perform clustering
sc.pp.neighbors(adata, use_rep=SCVI_LATENT_KEY)
sc.tl.leiden(adata)

# Apply UMAP for visualization
sc.tl.umap(adata, min_dist=0.3)

# Plot UMAP with batch and clustering information
sc.pl.umap(adata, color=[""batch"", ""leiden""],",https://docs.scvi-tools.org/en/stable/tutorials/notebooks/scrna/harmonization.html
scRNA-seq,Integration,"This code performs an integrated analysis of single-cell RNA sequencing data using scVI, a deep generative model specifically designed to address batch effects and extract biologically relevant latent features. The workflow begins by importing essential packages for data handling and visualization, ensuring that the plotting environment is preconfigured for clear output. It then loads a lung atlas dataset into an AnnData object using Scanpy??s input/output routines, which serves as the foundation for subsequent analysis. During preprocessing, the code selects the top 2000 highly variable genes to capture the most informative signals while reducing noise from technical variations. Next, the AnnData object is registered for scVI, specifying the raw count data and batch identifiers, which is crucial for accurate batch effect correction. The scVI model is initialized with a specific architecture and trained, learning a compressed latent representation of the high-dimensional gene expression data that integrates samples from different batches. This latent space is then extracted and stored back in the AnnData object. To further explore the data, a nearest-neighbor graph is computed on the refined latent space, followed by unsupervised clustering via the Leiden algorithm. Finally, UMAP, a powerful dimensionality reduction technique, is employed to produce two-dimensional visualizations that clearly distinguish cellular clusters and batch effects. Overall, this pipeline enables researchers to harmonize complex multi-sample single-cell datasets, facilitating downstream analyses such as cluster annotation, differential expression, and trajectory inference while ensuring that both technical and biological variations are appropriately balanced.","os, tempfile, scanpy, scvi, seabor, torch",python,"# Import necessary libraries
import os
import tempfile
import scanpy as sc
import scvi
import seaborn as sns
import torch

# Set parameters for plotting and computation precision
sc.set_figure_params(figsize=(6, 6), frameon=False)
sns.set_theme()
torch.set_float32_matmul_precision(""high"")

# Define a temporary directory for data storage
save_dir = tempfile.TemporaryDirectory()

# Load the lung atlas dataset.
# The backup_url parameter allows automatic download if the file is not found locally.
adata_path = os.path.join(save_dir.name, ""lung_atlas.h5ad"")
adata = sc.read(adata_path, backup_url=""https://figshare.com/ndownloader/files/24539942"")
print(adata)

# Store the full dataset in the .raw attribute for backup/reference
adata.raw = adata

# Preprocess the dataset by selecting the top 2000 highly variable genes.
# This reduces noise and focuses on biological signal by intersecting variable genes across batches.
sc.pp.highly_variable_genes(
    adata,
    flavor=""seurat_v3"",
    n_top_genes=2000,
    layer=""counts"",
    batch_key=""batch"",
    subset=True,
)

# Register the AnnData object for scVI analysis.
# Here, 'counts' is the layer with raw count data and 'batch' is used to identify different batches.
scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""batch"")

# Initialize the scVI model.
# The model is configured with 2 hidden layers and a latent space of 30 dimensions.
# The gene likelihood is set to Negative Binomial to model the count data.
model = scvi.model.SCVI(adata, n_layers=2, n_latent=30, gene_likelihood=""nb"")

# Train the scVI model, which learns a latent representation that corrects for batch effects.
model.train()

# Retrieve the latent representation learned by scVI and store it in the AnnData object.
SCVI_LATENT_KEY = ""X_scVI""
adata.obsm[SCVI_LATENT_KEY] = model.get_latent_representation()

# Compute the nearest-neighbor graph using the scVI latent space.
# This serves as a basis for clustering and visualization.
sc.pp.neighbors(adata, use_rep=SCVI_LATENT_KEY)

",https://docs.scvi-tools.org/en/stable/tutorials/notebooks/scrna/harmonization.html
scRNA-seq,Integration,"This code performs an integration task for single-cell RNA sequencing data using scANVI, focusing exclusively on leveraging cell type annotations to refine the latent space. The script begins by importing essential libraries for computation and visualization, then loads a lung atlas dataset into an AnnData object using Scanpy. It continues by preprocessing the data through the selection of the top 2000 highly variable genes, thereby emphasizing biological signals and reducing potential technical noise. The AnnData object is set up specifically for scANVI with designated cell type labels and batch identifiers, which allows the model to use supervised information during training. The model is initialized, marking any missing cell type annotations as ""Unknown"", and is then trained for a specified number of epochs with controlled sampling??ensuring a balanced representation across different labels. Once training is complete, the script extracts a refined latent representation that captures the underlying biological variation more accurately. This latent space is then used to compute a nearest-neighbor graph, which forms the foundation for UMAP, a dimensionality reduction technique employed to project high-dimensional data into a two-dimensional space. Finally, the integrated, low-dimensional coordinates are visualized with UMAP plots where cells are colored according to their annotated cell types, providing a clear visual representation of cellular heterogeneity and aiding in the identification of distinct cell populations within the lung tissue samples.","os, tempfile, scanpy, scvi, seabor, torch",python,"# Import necessary libraries
import os
import tempfile
import scanpy as sc
import scvi
import seaborn as sns
import torch

# Set parameters for plotting and computation precision
sc.set_figure_params(figsize=(6, 6), frameon=False)
sns.set_theme()
torch.set_float32_matmul_precision(""high"")

# Define a temporary directory to store or download the dataset
save_dir = tempfile.TemporaryDirectory()

# Load the lung atlas dataset.
# The backup URL allows for automatic download if the file is not found locally.
adata_path = os.path.join(save_dir.name, ""lung_atlas.h5ad"")
adata = sc.read(adata_path, backup_url=""https://figshare.com/ndownloader/files/24539942"")
print(adata)

# Save the full unmodified data in adata.raw for later reference
adata.raw = adata

# Preprocess the dataset by selecting the top 2000 highly variable genes,
# which helps focus on biologically relevant variation and reduce technical noise.
sc.pp.highly_variable_genes(
    adata,
    flavor=""seurat_v3"",
    n_top_genes=2000,
    layer=""counts"",
    batch_key=""batch"",
    subset=True,
)

# Setup the AnnData object for scANVI.
# Specify 'cell_type' as the label key and 'batch' as the batch key.
scvi.model.SCANVI.setup_anndata(adata, labels_key=""cell_type"", batch_key=""batch"")

# Initialize the scANVI model.
# Cells with missing labels are designated with the category ""Unknown"".
scanvi_model = scvi.model.SCANVI(adata, unlabeled_category=""Unknown"")

# Train the scANVI model for additional refinement of the latent space.
# Here, training runs for 20 epochs, sampling 100 cells per label.
scanvi_model.train(max_epochs=20, n_samples_per_label=100)

# Extract the refined latent representation from scANVI.
SCANVI_LATENT_KEY = ""X_scANVI""
adata.obsm[SCANVI_LATENT_KEY] = scanvi_model.get_latent_representation()

# Compute the nearest neighbor graph using the scANVI latent space,
# which is a prerequisite for downstream clustering and visualization.
sc.pp.neighbors(adata, use_rep=SCANVI_LATENT_KEY)

# Generate UMAP embeddings to visualize the integrated latent space.
sc.tl.umap(adata, min_dist=0.3)

# Plot the UMAP embedding, coloring cells according to their annotated cell types.
sc.pl.umap(adata, color=[""cell_type""], frameon=False, ncols=1)
",https://www.sc-best-practices.org/cellular_structure/integration.html
scRNA-seq,Integration,"This script performs an integration and batch effect correction analysis on single-cell RNA sequencing data using the BBKNN method. It begins by importing essential libraries such as Scanpy, BBKNN, NumPy, and Matplotlib, and then loads a built-in PBMC3k dataset as an example. To simulate batch effects, the code assigns half of the cells to one batch and the remaining half to a second batch, storing these labels in the dataset??s metadata. After data input, the analysis proceeds with standard preprocessing steps that include normalizing total counts per cell to account for variations in sequencing depth, applying a log-transformation to stabilize the variance, and selecting the top 2000 highly variable genes. The selected genes are then scaled to ensure comparability across features, and PCA is computed to reduce the dimensionality of the data while capturing primary variation components. The core of the integration involves running BBKNN, which constructs a batch-balanced k-nearest neighbor graph by finding top neighbors within each batch separately rather than across the combined dataset. This approach effectively minimizes technical differences between batches while preserving underlying biological structures. Finally, the script computes UMAP and t-SNE embeddings based on the BBKNN-corrected neighborhood graph and generates scatter plots to visualize the integrated data, with cells colored by their batch identities. These visualizations help assess the success of the batch correction process, ensuring that integration has harmonized the data for more reliable downstream analyses such as clustering and differential expression studies.","scanpy, bbknn, numpy, matplotlib",python,"# Import necessary libraries for single-cell analysis, batch correction, and plotting
import scanpy as sc
import bbknn
import numpy as np
import matplotlib.pyplot as plt

# Set global plotting parameters for clear visualization
sc.settings.set_figure_params(dpi=80, facecolor='white')
sc.settings.verbosity = 2  # set log verbosity

# Data I/O: Load the built-in PBMC3k dataset as an example
adata = sc.datasets.pbmc3k()

# Simulate two batches by splitting the cells into two groups
num_cells = adata.n_obs
# Initialize a batch array with 'batch1' and 'batch2'
batch_labels = np.array([""batch1""] * num_cells)
batch_labels[int(num_cells/2):] = ""batch2""
adata.obs[""batch""] = batch_labels

# ------------------------------
# Preprocessing
# ------------------------------
# Normalize each cell so that total counts equal 10,000 and log-transform the data
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)

# Identify highly variable genes and subset the data to these features for downstream analysis
sc.pp.highly_variable_genes(adata, n_top_genes=2000, flavor='seurat')
adata = adata[:, adata.var.highly_variable]

# Scale the data so that each gene has zero mean and unit variance (limiting extreme values)
sc.pp.scale(adata, max_value=10)

# Compute PCA for dimensionality reduction and to build the batch-corrected neighbor graph
sc.tl.pca(adata, svd_solver='arpack', n_comps=50)

# ------------------------------
# Batch Integration using BBKNN
# ------------------------------
# Use BBKNN to construct a batch-balanced nearest neighbor graph.
# This corrects for batch effects by finding neighbors within each batch.
bbknn.bbknn(adata, batch_key='batch', n_pcs=50, neighbors_within_batch=3)

# Compute UMAP embedding on the BBKNN corrected neighborhood graph
sc.tl.umap(adata)

# Additionally, compute t-SNE for alternative visualization
sc.tl.tsne(adata)

# ------------------------------
# Plotting Integrated Data
# ------------------------------
# Plot UMAP with cells colored by their batch label to assess integration
sc.pl.umap(adata, color=[""batch""], title=""UMAP: BBKNN Integrated"", size=30)

# Plot t-SNE with cells colored by batch
sc.pl.tsne(adata, color=[""batch""], title=""t-SNE: BBKNN Integrated"", size=30)
",https://scanpy.readthedocs.io/en/stable/tutorials/basics/integrating-data-using-ingest.html
scRNA-seq,Integration,"This code is designed to integrate single-cell RNA sequencing data from two simulated batches using the Mutual Nearest Neighbors (MNN) method, thereby reducing technical batch effects that can confound biological interpretation. Initially, the script imports the required libraries, including Scanpy for handling single-cell data and matplotlib for plotting, and then loads a built-in PBMC dataset. An artificial batch variable is created by randomly assigning each cell to one of two batches, after which the dataset is split into separate AnnData objects for each batch. The code applies standard preprocessing procedures to each batch individually: normalization to adjust for library size differences, log-transformation to stabilize variance, and the selection of the top 2000 highly variable genes to capture the most informative biological signals while minimizing noise. The core integration is performed by the MNN correction method, which identifies mutual nearest neighbors between the batches and corrects for batch-specific discrepancies to output a harmonized dataset. Afterward, the integrated data is subjected to principal component analysis, followed by the construction of a nearest-neighbor graph and the application of UMAP for dimensionality reduction. The final UMAP visualization, colored by the original batch labels, demonstrates the successful overlap of cells from different batches, indicating effective removal of batch effects. This streamlined workflow enables researchers to focus on true biological variability in downstream analyses such as clustering, cell-type annotation, and trajectory inference.","scanpy, matplotlib, numpy",python,"# Import necessary libraries
import scanpy as sc
import scanpy.external as sce
import matplotlib.pyplot as plt
import numpy as np

# Load an example dataset (PBMC 3k) provided by Scanpy
adata = sc.datasets.pbmc3k()

# Create an artificial batch variable by randomly assigning cells into two batches
np.random.seed(42)
adata.obs['batch'] = np.random.choice(['batch1', 'batch2'], size=adata.n_obs)

# Split the dataset into two separate AnnData objects based on the batch assignment
adata_batch1 = adata[adata.obs['batch'] == 'batch1'].copy()
adata_batch2 = adata[adata.obs['batch'] == 'batch2'].copy()

# Preprocess each batch individually:
# 1. Normalize total counts per cell to account for library size differences
# 2. Log-transform the data
# 3. Select the top 2000 highly variable genes
for ad in [adata_batch1, adata_batch2]:
    sc.pp.normalize_total(ad, target_sum=1e4)
    sc.pp.log1p(ad)
    sc.pp.highly_variable_genes(ad, n_top_genes=2000, subset=True)

# Integrate the two batches using MNN correction.
# The function returns an integrated AnnData object where batch effects are reduced.
adata_corrected, _ = sce.pp.mnn_correct(adata_batch1, adata_batch2, batch_key='batch')

# Perform principal component analysis (PCA) on the corrected data
sc.tl.pca(adata_corrected, svd_solver='arpack')

# Construct the neighborhood graph and compute a UMAP embedding based on the PCA space
sc.pp.neighbors(adata_corrected, n_pcs=50)
sc.tl.umap(adata_corrected)

# Plot the UMAP embedding, coloring cells according to their original batch assignments,
# to assess how well the integration using MNN has aligned the batches.
sc.pl.umap(adata_corrected, color='batch', title='MNN Integrated UMAP', show=True)
plt.show()
",https://www.sc-best-practices.org/cellular_structure/integration.html
scRNA-seq,Integration,"This code implements an integration workflow using the Harmony algorithm to correct for batch effects in single-cell RNA sequencing data. The process begins by importing essential libraries??Scanpy, its external module for Harmony integration, NumPy, and Matplotlib??and then loading a built-in PBMC3k dataset, which serves as an example. To mimic common technical variations seen across experimental batches, the script simulates batch effects by assigning the first half of the cells to ""batch1"" and the remaining half to ""batch2."" Following this, the Harmony integration is applied via the `sce.pp.harmony_integrate` function, which processes the PCA embeddings of the data to adjust them for batch-related discrepancies. The corrected embeddings are stored in a separate field (`X_pca_harmony`), ensuring that subsequent analyses leverage a harmonized representation of the data. Using these integrated embeddings, the script computes a neighborhood graph with `sc.pp.neighbors` and then generates a UMAP embedding to capture the intrinsic structure of the cell populations in a low-dimensional space. Furthermore, the script utilizes the Leiden clustering algorithm to delineate distinct cellular communities based on the corrected neighborhood graph. Finally, two UMAP plots are produced??one colored by the batch labels to assess the effectiveness of the integration and another by the Leiden clusters to reveal underlying biological heterogeneity. Overall, this workflow effectively demonstrates how to mitigate batch effects and integrate single-cell datasets, thereby enabling more accurate visualization and downstream analysis of cellular heterogeneity.","scanpy, matplotlib, numpy",python,"# Import necessary libraries for single-cell analysis and plotting
import scanpy as sc
import scanpy.external as sce  # Contains Harmony integration functionality
import matplotlib.pyplot as plt
import numpy as np

# Set global plotting parameters for clear visualization
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Data I/O: Load the built-in PBMC3k dataset (example data)
adata = sc.datasets.pbmc3k()


# ------------------------------
# Simulate Batch Effects
# ------------------------------
# For demonstration, we artificially generate a batch variable.
# We assign the first half of the cells to 'batch1' and the remaining to 'batch2'.
num_cells = adata.n_obs  # total number of cells
adata.obs['batch'] = np.array(['batch1'] * num_cells)
adata.obs.loc[adata.obs.index[int(num_cells / 2):], 'batch'] = 'batch2'

# ------------------------------
# Integration using Harmony
# ------------------------------
# Run Harmony to adjust the PCA embeddings and remove batch effects.
# The adjusted embeddings are stored in adata.obsm['X_pca_harmony'].
sce.pp.harmony_integrate(adata, key='batch')

# ------------------------------
# Downstream Analysis: Neighbors and UMAP
# ------------------------------
# Compute the neighborhood graph using the integrated embeddings.
sc.pp.neighbors(adata, use_rep='X_pca_harmony', n_neighbors=15)

# Compute the UMAP embedding based on the batch-corrected neighbors.
sc.tl.umap(adata)

# Optionally, perform clustering (e.g., using the Leiden algorithm) for further analysis.
sc.tl.leiden(adata, resolution=0.5)

# ------------------------------
# Plotting the Results
# ------------------------------
# Plot UMAP where cells are colored by their batch label.
# This helps to assess whether the batch effect has been minimized.
sc.pl.umap(adata, color=['batch'], title='UMAP after Harmony Integration')

# Plot UMAP colored by the Leiden clusters to visualize underlying cellular heterogeneity.
sc.pl.umap(adata, color=['leiden'], title='UMAP with Leiden Clusters after Harmony Integration')
",https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.pp.harmony_integrate.html#scanpy.external.pp.harmony_integrate
scRNA-seq,Integration,"The code performs an integration workflow for single-cell RNA sequencing data using the Seurat framework. It begins by importing the necessary libraries and loading two separate 10X Genomics datasets??representing distinct experimental conditions, such as ""Control"" and ""Stimulated""??into individual Seurat objects after applying basic quality control filters to remove low-quality cells. Each dataset is then preprocessed separately by normalizing the data with a global scaling method and identifying highly variable features that capture the most informative biological signals. Once the individual Seurat objects are ready, they are combined into a list for integration. Using an anchor-based integration approach, the code identifies corresponding features between the datasets, thus mitigating potential batch effects and aligning shared cell types across conditions. The integrated dataset is then stored in a unified Seurat object, where the integrated assay becomes the basis for further analysis. To visualize the results, the code scales the integrated data, performs Principal Component Analysis (PCA) for dimensionality reduction, and then applies UMAP to create a two-dimensional embedding. This UMAP plot is generated with cells colored by their original dataset, providing an intuitive view of how well the datasets have been merged. Finally, the integrated Seurat object is saved for downstream analyses, such as clustering or differential expression testing, enabling researchers to draw comprehensive biological conclusions from a consolidated view of multiple experimental conditions.","Seurat, dplyr, ggplot2, patchwork",R,"# Load necessary libraries for single-cell analysis, data manipulation, and plotting
library(Seurat)      # For single-cell RNA-seq analysis and integration
library(dplyr)       # For data manipulation
library(ggplot2)     # For plotting and visualization
library(patchwork)   # For combining multiple plots

# ----------------------------
# Data I/O and Object Creation
# ----------------------------

# Define file paths for the Control and Stimulated datasets.
data_dir_control <- ""path/to/control_data/""      # Replace with the actual Control dataset directory
data_dir_stim    <- ""path/to/stimulated_data/""   # Replace with the actual Stimulated dataset directory

# Read the raw 10X Genomics data for each condition.
data_control <- Read10X(data.dir = data_dir_control)
data_stim    <- Read10X(data.dir = data_dir_stim)

# Create Seurat objects for each dataset with basic filtering
control <- CreateSeuratObject(counts = data_control, project = ""Control"", min.cells = 3, min.features = 200)
stim    <- CreateSeuratObject(counts = data_stim, project = ""Stimulated"", min.cells = 3, min.features = 200)

# ----------------------------
# Preprocessing Individual Datasets
# ----------------------------

# Normalize and find variable features for the Control dataset.
control <- NormalizeData(control, normalization.method = ""LogNormalize"", scale.factor = 10000)
control <- FindVariableFeatures(control, selection.method = ""vst"", nfeatures = 2000)

# Normalize and find variable features for the Stimulated dataset.
stim <- NormalizeData(stim, normalization.method = ""LogNormalize"", scale.factor = 10000)
stim <- FindVariableFeatures(stim, selection.method = ""vst"", nfeatures = 2000)

# ----------------------------
# Integration Workflow
# ----------------------------

# Combine the two Seurat objects into a list for integration.
object_list <- list(control, stim)

# Identify integration anchors across the datasets based on the first 20 principal components.
anchors <- FindIntegrationAnchors(object.list = object_list, dims = 1:20)

# Integrate the datasets using the identified anchors.
integrated_data <- IntegrateData(anchorset = anchors, dims = 1:20)

# Set the default assay to the integrated data to use it in downstream tasks.
DefaultAssay(integrated_data) <- ""integrated""

# ----------------------------
# Post-integration Processing and Visualization
# ----------------------------

# Scale the integrated data and run PCA to reduce dimensionality.
integrated_data <- ScaleData(integrated_data, verbose = FALSE)
integrated_data <- RunPCA(integrated_data, npcs = 30, verbose = FALSE)

# Run UMAP on the PCA-reduced data to create a low-dimensional visualization.
integrated_data <- RunUMAP(integrated_data, reduction = ""pca"", dims = 1:20)

# Optionally perform clustering on the integrated data.
integrated_data <- FindNeighbors(integrated_data, reduction = ""pca"", dims = 1:20)
integrated_data <- FindClusters(integrated_data, resolution = 0.5)

# Generate a UMAP plot that shows cells by their original condition (Control vs Stimulated)
umap_plot <- DimPlot(integrated_data, reduction = ""umap"", group.by = ""orig.ident"", label = TRUE) +
  ggtitle(""UMAP Plot: Integrated Data by Condition"")
print(umap_plot)

# ----------------------------
# Save the Integrated Seurat Object
# ----------------------------

# Save the integrated Seurat object for future downstream analyses.
saveRDS(integrated_data, file = ""Integrated_Seurat_Object.rds"")
",https://satijalab.org/seurat/articles/integration_introduction#perform-integration
scRNA-seq,Trajectory inference,"This code performs trajectory inference on single-cell RNA sequencing data using the PAGA (Partition-based Graph Abstraction) algorithm to reveal the underlying cellular dynamics and differentiation pathways. It begins by importing essential libraries??including Scanpy and Matplotlib??and loading an example dataset. The data is first cast to a higher numerical precision to ensure robust downstream analysis. Next, the script applies standard preprocessing steps, encompassing normalization and log-transformation, to correct for technical variability, followed by principal component analysis (PCA) to reduce the high-dimensional data into a manageable form. A k-nearest neighbor graph is then computed to capture the local similarities among cells, and the Louvain algorithm is employed to partition the dataset into meaningful clusters. The key step involves running PAGA on these clusters, which abstracts the complex cellular network into a simplified graph representing the connectivity between cell groups. By assessing the strength and confidence of connections, PAGA identifies potential branching points and transitions among the clusters. This abstracted graph is visualized through dedicated PAGA plots, where edges below a defined threshold are pruned to emphasize significant interactions. Additionally, the script uses the PAGA-initialized graph to generate a UMAP layout (via draw_graph) that embeds single cells in a low-dimensional space, colored by their cluster assignments. This visualization not only clarifies the overall topology of cellular trajectories but also aids in interpreting how discrete cell states evolve along continuous developmental paths.","scanpy, matplotlib",python,"# Import necessary libraries for single-cell analysis and plotting
import scanpy as sc
import matplotlib.pyplot as plt

# Set global settings for clear visualization and increased verbosity for logging
sc.settings.verbosity = 3  # 0: errors, 1: warnings, 2: info, 3: hints
sc.settings.set_figure_params(dpi=80, facecolor='white')

# Data I/O: Load the Paul15 dataset (a typical example for trajectory inference)
adata = sc.datasets.paul15()

# For consistency, convert the data matrix to float64
adata.X = adata.X.astype('float64')

# ------------------------------
# Preprocessing
# ------------------------------
# Apply a standard preprocessing recipe: normalization, log transformation, and feature selection
sc.pp.recipe_zheng17(adata)  # This normalizes per cell, selects highly variable genes etc.

# Perform PCA (which is required for downstream neighbor computation)
sc.tl.pca(adata, svd_solver='arpack')

# Compute the k-nearest neighbor graph using a limited number of PCs (here, 20 PCs with 10 neighbors)
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20)

# ------------------------------
# Clustering
# ------------------------------
# Cluster cells using the Louvain algorithm (the default groups here will be stored in adata.obs['louvain'])
sc.tl.louvain(adata, resolution=1.0)

# ------------------------------
# PAGA (Partition-based Graph Abstraction)
# ------------------------------
# Compute the PAGA graph using the clustering results. The 'groups' parameter specifies which categorical annotation to use.
sc.tl.paga(adata, groups='louvain')

# Optionally, draw the single-cell graph initialized at the PAGA positions.
# This initialization uses the coarse-grained structure inferred by PAGA.
sc.tl.draw_graph(adata, init_pos='paga')

# ------------------------------
# Plotting
# ------------------------------
# Plot the PAGA abstracted graph.
# The threshold parameter prunes low-confidence edges to simplify the graph visualization.
sc.pl.paga(adata, color=['louvain'], threshold=0.03, title='PAGA Graph for Trajectory Inference')

# Plot the UMAP (draw_graph) layout initialized using PAGA positions to better reflect the global topology.
sc.pl.draw_graph(adata, color='louvain', legend_loc='on data', title='Trajectory Inference via PAGA Initialization')
",https://scanpy.readthedocs.io/en/stable/tutorials/trajectories/paga-paul15.html
scRNA-seq,Quality control,"This code performs essential **quality control** analysis on single-cell RNA sequencing (scRNA-seq) data, ensuring the reliability of the dataset before downstream analysis. First, it loads raw UMI count data and computes basic quality control metrics, such as the number of detected genes per cell, total RNA counts, and the percentage of mitochondrial genes. These metrics help identify low-quality cells that may skew biological interpretations. The code then visualizes these distributions using violin plots to highlight outliers. Next, it applies filters to remove cells with excessively high mitochondrial RNA content or abnormal gene expression levels, reducing potential technical noise. Additionally, it selects **highly variable genes**, which are most informative for distinguishing cell populations, and plots their mean expression against residual variance to confirm selection quality. This step ensures that key biological signals are retained while minimizing technical artifacts. Finally, by preprocessing the data with Scanpy, the pipeline sets up a robust foundation for subsequent dimensionality reduction, clustering, and differential gene expression analysis in single-cell studies, enabling accurate identification of cellular subpopulations.","numpy, matplotlib, scanpy",python,"# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
import scanpy as sc

# Set scanpy settings for better visualization
sc.settings.verbosity = 3  # Set verbosity level
sc.settings.set_figure_params(dpi=80, facecolor=""white"")

# Load the dataset from 10X Genomics (example dataset)
adata = sc.read_10x_mtx(""tutorial_data/pbmc3k_v1/"", cache=True)

# Compute basic quality control metrics
adata.var[""mt""] = adata.var_names.str.startswith(""MT-"")  # Identify mitochondrial genes
sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], percent_top=None, log1p=False, inplace=True)

# Plot quality control metrics to check distributions
sc.pl.violin(
    adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],
    jitter=0.4, multi_panel=True
)

# Define outlier cells based on quality control metrics
adata.obs[""outlier_mt""] = adata.obs.pct_counts_mt > 5
adata.obs[""outlier_total""] = adata.obs.total_counts > 5000
adata.obs[""outlier_ngenes""] = adata.obs.n_genes_by_counts > 2500

# Print the number of outliers detected
print(f""{sum(adata.obs['outlier_mt'])} cells with high % of mitochondrial genes"")
print(f""{sum(adata.obs['outlier_total'])} cells with large total counts"")
print(f""{sum(adata.obs['outlier_ngenes'])} cells with large number of genes"")

# Remove outliers from the dataset
adata = adata[~adata.obs[""outlier_mt""], :]
adata = adata[~adata.obs[""outlier_total""], :]
adata = adata[~adata.obs[""outlier_ngenes""], :]
sc.pp.filter_genes(adata, min_cells=1)

# Plot gene selection: mean expression vs residual variance
fig, ax = plt.subplots(figsize=(6, 6))
hvgs = adata.var[""highly_variable""]
ax.scatter(adata.var[""mean_counts""], adata.var[""residual_variances""], s=3, edgecolor=""none"")
ax.scatter(adata.var[""mean_counts""][hvgs], adata.var[""residual_variances""][hvgs],
           c=""tab:red"", label=""selected genes"", s=3, edgecolor=""none"")
ax.set_xscale(""log"")
ax.set_yscale(""log"")
ax.set_xlabel(""Mean Expression"")
ax.set_ylabel(""Residual Variance"")
ax.set_title(""Highly Variable Genes"")
plt.legend()
plt.show()
",https://scanpy.readthedocs.io/en/stable/tutorials/experimental/pearson_residuals.html
scRNA-seq,Feature selection,"This code is designed to perform a critical feature selection task within a single-cell RNA sequencing (scRNA-seq) analysis workflow, leveraging the Scanpy framework to ensure that the most biologically informative genes are identified for downstream analyses. Initially, the code imports essential libraries and sets up proper visualization settings before loading a 10X Genomics-formatted dataset. It then identifies mitochondrial genes by checking if gene names start with ""MT-"", a common quality control step that helps to flag potential cell stress or apoptosis. After computing standard quality control metrics??such as total counts, number of detected genes, and the percentage of mitochondrial gene expression??the script focuses on selecting highly variable genes. It employs the Pearson residuals method, which models the inherent technical noise in the data and isolates the genes that significantly deviate from this noise, thereby capturing true biological variability. The code specifically selects the top 2000 genes that exhibit high residual variance. To help the user visually assess the effectiveness of this selection, a scatter plot is generated that depicts mean gene expression against residual variance, with the highly variable genes clearly highlighted in red. This visualization not only confirms the successful capture of the most variable features but also provides a solid foundation for subsequent analyses, such as dimensionality reduction and clustering, ultimately leading to more accurate cell type identification and biological insight.","numpy, matplotlib, scanpy",python,"# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
import scanpy as sc

# Set Scanpy settings for better visualization and logging
sc.settings.verbosity = 3  # Show detailed logging
sc.settings.set_figure_params(dpi=80, facecolor=""white"")

# Load the dataset from a 10X Genomics formatted directory
# Change the path below to point to your dataset directory
adata = sc.read_10x_mtx(""data/10x_genomics_directory/"", cache=True)

# Identify mitochondrial genes (if any) useful for potential quality control steps
adata.var['mt'] = adata.var_names.str.startswith(""MT-"")

# Calculate basic quality control metrics for each cell, including total counts and number of genes
sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], percent_top=None, inplace=True)

# Feature Selection:
# Identify highly variable genes using the Pearson residuals method.
# This function computes the residuals to model the technical variability and selects the top 2000 variable genes.
sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000)

# Output the number of highly variable genes selected
print(""Number of highly variable genes:"", sum(adata.var[""highly_variable""]))

# Plot the feature selection results:
# The scatter plot shows the mean expression (x-axis) vs. residual variance (y-axis) for all genes,
# with the selected highly variable genes highlighted in red.
fig, ax = plt.subplots(figsize=(6, 6))
hvgs = adata.var[""highly_variable""]
ax.scatter(adata.var[""mean_counts""], adata.var[""residual_variances""],
           s=3, c='gray', label='All genes', alpha=0.5)
ax.scatter(adata.var[""mean_counts""][hvgs], adata.var[""residual_variances""][hvgs],
           s=3, c='red', label='Highly variable genes')
ax.set_xscale(""log"")
ax.set_yscale(""log"")
ax.set_xlabel(""Mean Expression"")
ax.set_ylabel(""Residual Variance"")
ax.set_title(""Feature Selection: Highly Variable Genes"")
plt.legend()
plt.show()
# Apply gene selection
adata = adata[:, adata.var[Highly variable genes]]",https://scanpy.readthedocs.io/en/stable/tutorials/experimental/pearson_residuals.html
scRNA-seq,Trajectory inference,"The provided code performs pseudotime analysis on single-cell RNA sequencing (scRNA-seq) data using diffusion maps and diffusion pseudotime (DPT) methodology. The primary objective is to infer the developmental trajectory of cells based on their gene expression profiles, enabling the ordering of cells along a continuous scale representing biological progression. The script first preprocesses the dataset by filtering genes, normalizing expression values, and performing dimensionality reduction through PCA. It then constructs a nearest-neighbor graph to capture cell relationships and applies diffusion mapping to create a low-dimensional representation. The root cell??representing the beginning of the developmental hierarchy??is determined, allowing for the computation of pseudotime. This inferred pseudotime is visualized in a t-SNE space to illustrate the progression of cellular states, and violin plots further compare pseudotime distributions across clusters. The analysis helps identify key transitional states and uncover gene expression dynamics that drive differentiation processes, such as hematopoietic development, making it a powerful tool for studying lineage specification and cellular heterogeneity in biological systems.
","scampy, pathlib",python,"# Import necessary libraries
import scanpy as sc
from pathlib import Path

# Define data directory and file name
DATA_DIR = Path(""./data/"")
DATA_DIR.mkdir(parents=True, exist_ok=True)
FILE_NAME = DATA_DIR / ""bone_marrow.h5ad""

# Load the dataset
adata = sc.read(filename=FILE_NAME, backup_url=""https://figshare.com/ndownloader/files/35826944"")

# Preprocessing: filter genes, normalize, log-transform, and identify highly variable genes
sc.pp.filter_genes(adata, min_counts=20)  # Remove genes expressed in few cells
sc.pp.normalize_total(adata)  # Normalize cell size
sc.pp.log1p(adata)  # Log transform to reduce outlier effects
sc.pp.highly_variable_genes(adata)  # Identify highly variable genes
sc.tl.pca(adata)  # Perform PCA
sc.pp.neighbors(adata, n_pcs=10)  # Compute nearest neighbor graph

# Visualization of clusters using t-SNE
sc.pl.scatter(adata, basis=""tsne"", color=""clusters"")

# Compute diffusion pseudotime (DPT)
sc.tl.diffmap(adata)  # Compute diffusion map

# Identify the root cell for pseudotime ordering based on diffusion components
root_ixs = adata.obsm[""X_diffmap""][:, 3].argmin()
adata.uns[""iroot""] = root_ixs

# Compute pseudotime using DPT
sc.tl.dpt(adata)

# Visualization of pseudotime in t-SNE space
sc.pl.scatter(adata, basis=""tsne"", color=[""dpt_pseudotime""], color_map=""gnuplot2"")

# Violin plot to compare pseudotime distributions among clusters
sc.pl.violin(adata, keys=[""dpt_pseudotime""], groupby=""clusters"", rotation=45)

print(""Pseudotime analysis completed!"")
", https://www.sc-best-practices.org/trajectories/pseudotemporal.html
scRNA-seq,Trajectory inference,"This R script employs the Monocle2 framework to carry out an end-to-end single-cell RNA-Seq analysis workflow. It begins by loading essential libraries and reading in the gene expression matrix, cell metadata, and gene annotation files, which are then combined into a unified CellDataSet object. The code first normalizes the data by estimating size factors and gene dispersions, ensuring that technical variations are minimized. It then detects and filters genes based on a minimum expression threshold, retaining only those expressed in a sufficient number of cells. To uncover the key drivers of cellular variation, the script performs differential expression testing between experimental conditions (e.g., different media) to identify ordering genes with significant changes, which subsequently guide the trajectory inference process. Using the DDRTree dimensionality reduction method, the analysis projects the high-dimensional data into two dimensions, facilitating the construction of a developmental trajectory along which cells are ordered in pseudotime. This pseudotime ordering reflects the progression of cells through a biological process, such as differentiation. Moreover, the code conducts a differential expression analysis along pseudotime to capture dynamically regulated genes and applies the BEAM algorithm to carry out branch analysis, pinpointing genes that diverge at key branch points in the trajectory. Throughout this workflow, various plots are generated to visualize the cell trajectories, gene expression changes over pseudotime, and branch-specific patterns, thereby providing an intuitive framework to study the continuous and bifurcating nature of cellular differentiation.","monocle, ggplot2, Matrix",R,"# Load required libraries
library(monocle)   # Monocle2 for single-cell trajectory analysis
library(ggplot2)   # For additional plotting customization
library(Matrix)    # To handle sparse matrices if needed

# --------------------------
# Data I/O: Import Input Data
# --------------------------
# Read the gene expression matrix (rows: genes, columns: cells)
expr_matrix <- read.table(""fpkm_matrix.txt"", header = TRUE, row.names = 1)

# Read the cell sample sheet with cell metadata (make sure 'Media' column exists)
sample_sheet <- read.delim(""cell_sample_sheet.txt"", header = TRUE, row.names = 1)

# Read the gene annotation file (e.g., gene names, biotypes)
gene_annotation <- read.delim(""gene_annotations.txt"", header = TRUE, row.names = 1)

# Create AnnotatedDataFrame objects for phenotype (cell) data and feature (gene) data
pd <- new(""AnnotatedDataFrame"", data = sample_sheet)
fd <- new(""AnnotatedDataFrame"", data = gene_annotation)

# --------------------------
# Construct the CellDataSet Object
# --------------------------
# Convert the expression matrix to a matrix (if not already) and create a CellDataSet.
# Here, we use a negative binomial model with a lower detection limit of 0.5.
cds <- newCellDataSet(as.matrix(expr_matrix),
                      phenoData = pd,
                      featureData = fd,
                      lowerDetectionLimit = 0.5,
                      expressionFamily = negbinomial.size())

# Estimate size factors (for normalization across cells)
cds <- estimateSizeFactors(cds)

# Estimate gene dispersions
cds <- estimateDispersions(cds)

# --------------------------
# Filtering and Detecting Expressed Genes
# --------------------------
# Detect genes expressed above the threshold (min_expr=0.1)
cds <- detectGenes(cds, min_expr = 0.1)

# Select genes expressed in at least 10 cells (this threshold is adjustable)
expressed_genes <- row.names(subset(fData(cds), num_cells_expressed >= 10))

# --------------------------
# Selecting Ordering Genes via Differential Expression
# --------------------------
# Perform differential expression analysis comparing experimental conditions.
# Here we assume there is a ""Media"" column in the sample sheet comparing conditions (e.g., GM vs. DM).
diff_test_res <- differentialGeneTest(cds[expressed_genes, ], fullModelFormulaStr = ""~Media"")

# Select ordering genes with significant changes (q-value < 0.01).
ordering_genes <- row.names(subset(diff_test_res, qval < 0.01))

# Set the ordering filter (i.e., these genes will guide the trajectory inference)
cds <- setOrderingFilter(cds, ordering_genes)

# Optionally, visualize the dispersion of ordering genes
plot_ordering_genes(cds)

# --------------------------
# Trajectory Construction (Pseudotime Ordering)
# --------------------------
# Reduce data dimensionality using the DDRTree method which is well-suited for trajectory analysis.
cds <- reduceDimension(cds, max_components = 2, method = ""DDRTree"")

# Order the cells along a trajectory (assign pseudotime values)
cds <- orderCells(cds)

# Plot the trajectory colored by pseudotime
plot_cell_trajectory(cds, color_by = ""Pseudotime"")

# You may also choose to color by experimental conditions (e.g., ""Media"")
plot_cell_trajectory(cds, color_by = ""Media"")

# --------------------------
# Differential Expression Analysis Along Pseudotime
# --------------------------
# Here, we test for genes that change as a function of pseudotime.
# The model uses a smoothing spline (sm.ns) on pseudotime.
diff_genes <- differentialGeneTest(cds[expressed_genes, ], fullModelFormulaStr = ""~sm.ns(Pseudotime)"")
sig_genes <- subset(diff_genes, qval < 0.1)

# Print the top significant genes (ordered by q-value)
print(head(sig_genes[order(sig_genes$qval), ]))

# --------------------------
# Branch Analysis (BEAM)
# --------------------------
# Identify branch-dependent genes using BEAM (Branch Expression Analysis Modeling)
# Here, we use branch_point = 1, but adjust this according to your trajectory branching.
branch_point <- 1
beam_res <- BEAM(cds, branch_point = branch_point, cores = 1)

# Select branch-dependent genes with a stringent significance threshold (q-value < 1e-4)
beam_sig_genes <- row.names(subset(beam_res, qval < 1e-4))

# Plot genes with branch-dependent expression patterns along pseudotime
plot_genes_branched_pseudotime(cds[beam_sig_genes, ], branch_point = branch_point, color_by = ""Pseudotime"")
",https://cole-trapnell-lab.github.io/monocle-release/docs/#constructing-single-cell-trajectories
scRNA-seq,Trajectory inference,"This code performs a comprehensive single-cell RNA sequencing analysis using Monocle 3 to reconstruct cellular trajectories and identify differentially expressed genes. It begins by loading expression data, cell metadata, and gene annotations to construct a `cell_data_set` (CDS), which serves as the foundation for downstream analysis. The data is preprocessed and batch-corrected before undergoing dimensionality reduction via UMAP. Cells are then clustered to group similar populations. The trajectory graph is learned, mapping cellular states along a dynamic biological process, and cells are ordered in pseudotime??an abstract measure of their progression. The code visualizes this trajectory using `plot_cells()`, coloring cells based on pseudotime to illustrate differentiation patterns. Additionally, it applies differential expression analysis (`graph_test()`) to detect genes whose expression varies significantly along the trajectory, helping to pinpoint key regulatory genes. The most significantly changing genes are extracted and their trends are visualized in pseudotime. Finally, the differential expression results are saved for further interpretation, providing insights into gene regulation and cellular transitions. This workflow is crucial for studying processes like development, differentiation, and disease progression at the single-cell level.","monocle3, ggplot2",R,"# Load required libraries
library(monocle3)
library(ggplot2)

# Load dataset (Modify paths based on your own data)
expression_matrix <- readRDS(url(""https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_expression.rds""))
cell_metadata <- readRDS(url(""https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_colData.rds""))
gene_annotation <- readRDS(url(""https://depts.washington.edu:/trapnell-lab/software/monocle3/celegans/data/packer_embryo_rowData.rds""))

# Create a cell data set (CDS)
cds <- new_cell_data_set(expression_matrix, cell_metadata = cell_metadata, gene_metadata = gene_annotation)

# Preprocess the data
cds <- preprocess_cds(cds, num_dim = 50)

# Perform batch correction if applicable
cds <- align_cds(cds, alignment_group = ""batch"")

# Reduce dimensionality using UMAP
cds <- reduce_dimension(cds)

# Cluster the cells
cds <- cluster_cells(cds)

# Learn the trajectory graph
cds <- learn_graph(cds)

# Select a root node for pseudotime ordering
cds <- order_cells(cds)

# Plot trajectory
plot_cells(cds, color_cells_by = ""pseudotime"", label_cell_groups = FALSE, label_leaves = FALSE, label_branch_points = FALSE)

# Perform differential gene expression analysis along pseudotime
graph_test_res <- graph_test(cds, neighbor_graph = ""principal_graph"", cores = 4)

# Select significantly changing genes
significant_genes <- subset(graph_test_res, q_value < 0.05)

# Plot expression trends of significant genes
plot_genes_in_pseudotime(cds, genes = rownames(significant_genes)[1:6], min_expr = 0.5)

# Save results
write.csv(significant_genes, ""differential_expression_results.csv"")
",https://cole-trapnell-lab.github.io/monocle3/docs/trajectories/
scRNA-seq,Compositional analysis,"This script is designed to perform a comprehensive compositional analysis on single-cell RNA sequencing data by investigating differences in cell type distributions under various biological conditions. It begins by importing essential Python libraries for data manipulation, statistical analysis, and visualization, and then loads a curated dataset of small intestinal epithelial cells, complete with metadata such as batch, condition, and cell type annotations. Initially, the code demonstrates the concept of compositionality through a simplified example that compares the cell counts of three hypothetical cell types between healthy and diseased tissues, using bar plots to highlight differences in both absolute and relative abundances. The core part of the script employs the scCODA model from the pertpy library, which implements a Bayesian framework tailored for compositional data where total cell counts are constrained; this helps in identifying genuine biological shifts while accounting for the inherent negative correlations among cell types. The analysis pipeline aggregates cell-level counts to the sample level, visualizes the distributions via boxplots and stacked bar plots, and sets up a statistical model using a formula with condition as the covariate and a pre-defined reference cell type. It then runs a Bayesian MCMC sampler (NUTS) to infer log-fold changes, adjusts for false discovery rate, and ultimately visualizes statistically credible changes in cell type abundances using an effects bar plot. This approach aids in uncovering subtle changes in cellular composition that may arise due to biological perturbations such as disease or infection.","pandas, numpy, matplotlib, seaborn, scanpy, pertpy",python,"# Import required packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scanpy as sc
import pertpy as pt  # Pertpy includes tools for compositional analysis (scCODA)

# -----------------------------------------------------------------------------
# Data I/O: Load the Haber 2017 dataset of small intestinal epithelial cells.
# -----------------------------------------------------------------------------
adata = pt.dt.haber_2017_regions()
print(""Loaded data shape:"", adata.shape)
# adata.obs contains metadata such as 'batch', 'barcode', 'condition', and 'cell_label'

# -----------------------------------------------------------------------------
# Example: Illustrate the compositional nature of cell count data.
#
# This demo considers a healthy and a diseased tissue sample with three cell types.
# -----------------------------------------------------------------------------
healthy_tissue = [2000, 2000, 2000]
diseased_tissue = [4000, 2000, 2000]

# Create a DataFrame with total cell counts for healthy and diseased tissues
example_data_global = pd.DataFrame(
    data=np.array([healthy_tissue, diseased_tissue]),
    index=[""Healthy"", ""Diseased""],
    columns=[""A"", ""B"", ""C""]
)

# Reshape the DataFrame for plotting with seaborn
plot_data_global = example_data_global.reset_index().melt(
    id_vars=""index"", value_vars=[""A"", ""B"", ""C""],
    var_name=""Cell type"", value_name=""count""
)

# Plot barplots showing global abundances
fig, ax = plt.subplots(1, 2, figsize=(12, 6))
sns.barplot(data=plot_data_global, x=""index"", y=""count"", hue=""Cell type"", ax=ax[0])
ax[0].set_title(""Global abundances, by status"")
sns.barplot(data=plot_data_global, x=""Cell type"", y=""count"", hue=""index"", ax=ax[1])
ax[1].set_title(""Global abundances, by cell type"")
plt.tight_layout()
plt.show()

# -----------------------------------------------------------------------------
# Compositional Analysis Using scCODA (with Labeled Clusters)
#
# The following steps model the compositional changes in cell type data:
#   1. Preparing sample-level data.
#   2. Visualizing cell type distributions.
#   3. Configuring a Bayesian compositional model.
# -----------------------------------------------------------------------------

# Instantiate the scCODA model from pertpy
sccoda_model = pt.tl.Sccoda()

# Load the data for compositional analysis.
# Use 'cell_label' for cell types, 'batch' for sample IDs, and 'condition' as the covariate.
sccoda_data = sccoda_model.load(
    adata,
    type=""cell_level"",
    generate_sample_level=True,
    cell_type_identifier=""cell_label"",
    sample_identifier=""batch"",
    covariate_obs=[""condition""],
)
print(""scCODA data modalities:"", sccoda_data)

# -----------------------------------------------------------------------------
# Plotting: Visualize cell type distributions
#
# a) Boxplots per condition (with red dots for individual data points)
# b) Stacked barplot of cell type proportions by condition.
# -----------------------------------------------------------------------------

# Boxplot visualization of cell type counts across conditions
sccoda_model.plot_boxplots(
    sccoda_data,
    modality_key=""coda"",
    feature_name=""condition"",
    figsize=(12, 5),
    add_dots=True,
    args_swarmplot={""palette"": [""red""]},
)
plt.show()

# Stacked barplot visualization of cell type proportions per condition
sccoda_model.plot_stacked_barplot(
    sccoda_data,
    modality_key=""coda"",
    feature_name=""condition"",
    figsize=(4, 2)
)
plt.show()

# -----------------------------------------------------------------------------
# Prepare and Run the scCODA Model
#
# The model is configured with a formula (here ""condition"") and a designated reference cell type.
# -----------------------------------------------------------------------------

# Prepare the data by specifying the formula and the reference cell type (""Endocrine"")
sccoda_data = sccoda_model.prepare(
    sccoda_data,
    modality_key=""coda"",
    formula=""condition"",
    reference_cell_type=""Endocrine""
)

# Run the Bayesian inference sampler (using a fixed seed for reproducibility)
sccoda_model.run_nuts(sccoda_data, modality_key=""coda"", rng_key=1234)

# Set the False Discovery Rate (FDR) threshold; here it is set to 0.2.
sccoda_model.set_fdr(sccoda_data, 0.2)

# Print the binary credible effects for each cell type and condition.
credible_effects = sccoda_model.credible_effects(sccoda_data, modality_key=""coda"")
print(""Credible Effects:\n"", credible_effects)

# -----------------------------------------------------------------------------
# Final Plot: Bar Plot of Effects
#
# The plot displays log-fold changes relative to the reference cell type along with
# a binary indication of significant (credible) changes.
# -----------------------------------------------------------------------------

sccoda_model.plot_effects_barplot(sccoda_data, ""coda"", ""condition"")
plt.show()
",https://www.sc-best-practices.org/conditions/compositional.html
scRNA-seq,Compositional analysis,"This script performs an advanced bioinformatics analysis to detect compositional changes in single-cell RNA sequencing data without relying on predefined cell-type labels. Initially, it loads the Haber dataset, processes the raw count data using a log transformation, and then identifies highly variable genes before running PCA for dimensionality reduction. This is followed by constructing a k-nearest neighbor graph, which serves as the basis not only for UMAP visualization but also for defining overlapping cell neighborhoods via the Milo algorithm from the Pertpy package. The core goal is to redefine cellular abundance in the absence of explicit labels, targeting subtle shifts in the local cell neighborhood composition. After forming these neighborhoods based on the KNN graph, the script computes the size distribution of each neighborhood to ensure statistical robustness before tallying the number of cells from each experimental sample (or batch) within them. A differential abundance test is then executed using a generalized linear model framework, akin to the edgeR approach, to identify neighborhoods that exhibit significant changes between conditions of interest, such as infected versus control states. Multiple plots??including histograms of neighborhood sizes, a constructed neighborhood graph, and beeswarm plots of test statistics??are generated to visualize the complex spatial and statistical patterns present in the data. Ultimately, this workflow allows researchers to uncover biologically relevant shifts in cellular composition, revealing subtle changes that might indicate transitional states or responses to perturbations, thereby providing a robust, label-free alternative to traditional cell-type-specific analyses.","pandas, numpy, matplotlib, seaborn, scanpy, pertpy",python,"# Import required packages
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scanpy as sc
import seaborn as sns
import pertpy as pt  # Pertpy provides both scCODA and Milo for compositional analysis

# -----------------------------------------------------------------------------
# Data I/O and Preprocessing
#
# Load the Haber dataset of single-cell RNA-seq data and set up the data 
# for downstream analysis. In this example, we create a log-transformed count matrix,
# compute highly variable genes, PCA, KNN graph, and UMAP for visualization.
# -----------------------------------------------------------------------------

adata = pt.dt.haber_2017_regions()  # Load dataset
print(""Loaded data shape:"", adata.shape)

# Save raw counts into a new layer and create log-transformed counts
adata.layers[""counts""] = adata.X.copy()
# Compute log-transformed counts using numpy??s log1p (alternative to sc.pp.log1p)
adata.layers[""logcounts""] = np.log1p(adata.layers[""counts""])
adata.X = adata.layers[""logcounts""].copy()  # update the main data matrix with logcounts

# Select highly variable genes (using the top 3000 genes for clustering/visualization)
sc.pp.highly_variable_genes(adata, n_top_genes=3000, subset=False)
# Perform PCA on the highly variable features
sc.pp.pca(adata)
# Construct the k-nearest neighbor graph based on the first 30 PCs (with k=10)
sc.pp.neighbors(adata, n_neighbors=10, n_pcs=30)
# Compute the UMAP embedding for visualization
sc.tl.umap(adata)
# Visualize UMAP colored by condition and batch (ignoring cell labels here)
sc.pl.umap(adata, color=[""condition"", ""batch""], ncols=2, wspace=0.4)

# -----------------------------------------------------------------------------
# Compositional Analysis Without Labeled Clusters Using Milo
#
# Instead of relying on pre-defined cell-type annotations, we set up Milo to 
# examine differential abundance (DA) in cell neighborhoods that are defined from
# the KNN graph. This is useful for detecting changes in transitional or subclustered 
# states.
# -----------------------------------------------------------------------------

# Initialize Milo from Pertpy
milo = pt.tl.Milo()

# Load the preprocessed AnnData object into the Milo framework.
# This creates a MuData object (mdata) that contains both the RNA modality and the Milo modality.
mdata = milo.load(adata)

# Define cell neighborhoods based on the KNN graph.
# Here, we select 10% of the cells as index cells to define overlapping neighborhoods.
milo.make_nhoods(mdata, prop=0.1)

# -----------------------------------------------------------------------------
# Neighborhood Size Distribution
#
# Examine the number of cells in each neighborhood and plot the distribution.
# Due to the fixed sampling proportion, the sizes of the neighborhoods may vary.
# -----------------------------------------------------------------------------

# Compute the total cell counts in each neighborhood stored in adata.obsm[""nhoods""]
nhood_size = adata.obsm[""nhoods""].toarray().sum(axis=0)
plt.figure(figsize=(6, 4))
plt.hist(nhood_size, bins=20, edgecolor=""black"")
plt.xlabel(""# cells in each neighborhood"")
plt.ylabel(""Number of neighborhoods"")
plt.title(""Distribution of Neighborhood Sizes"")
plt.show()

# -----------------------------------------------------------------------------
# Count Cells per Neighborhood Per Sample
#
# Use the 'batch' column in the data as the sample identifier to tally 
# the number of cells per neighborhood.
# -----------------------------------------------------------------------------

milo.count_nhoods(mdata, sample_col=""batch"")

# -----------------------------------------------------------------------------
# Build and Plot Neighborhood Graph
#
# Create a graph showing the spatial arrangement of the neighborhoods.
# This graph is built from the overlapping KNN neighborhoods.
# -----------------------------------------------------------------------------

milo.build_nhood_graph(mdata)
with plt.rc_context({""figure.figsize"": [10, 10]}):
    milo.plot_nhood_graph(mdata, alpha=0.1, min_size=5, plot_edges=False)
plt.show()

# -----------------------------------------------------------------------------
# Differential Abundance Testing in Neighborhoods
#
# Here, we perform the DA test to compare two conditions.
# In this example, we contrast ""Salmonella"" infection with ""Control"".
# The design is specified in R-style formula notation, and a model contrast is provided.
# -----------------------------------------------------------------------------

# Run the DA test using a design formula and contrast (e.g. Salmonella vs. Control)
milo.da_nhoods(mdata, design=""~condition"", model_contrasts=""conditionSalmonella-conditionControl"")

# Retrieve the DA results from the Milo modality (stored in mdata[""milo""].obs)
milo_results = mdata[""milo""].obs.copy()
print(""Differential Abundance (DA) results (first 5 neighborhoods):"")
print(milo_results.head())

# -----------------------------------------------------------------------------
# Plot Differential Abundance Results with Beeswarm Plot
#
# A beeswarm plot provides a way to visualize the distribution of test statistics 
# (such as the log-fold change and adjusted p-values) across all neighborhoods.
# -----------------------------------------------------------------------------

milo.plot_da_beeswarm(mdata)
plt.show()

# -----------------------------------------------------------------------------
# Optional: Visualize UMAP of RNA modality with condition labels
#
# Although this analysis does not depend on labeled clusters,
# visualizing the original UMAP can help connect the DA results to the biological context.
# -----------------------------------------------------------------------------

sc.pl.umap(mdata[""rna""], color=""condition"", title=""UMAP of Haber Data - Condition"", legend_loc=""on data"")
plt.show()
",https://www.sc-best-practices.org/conditions/compositional.html
scRNA-seq,Enrichment analysis,"This code implements a comprehensive gene set enrichment and pathway analysis workflow tailored for single-cell RNA sequencing data. It begins by importing essential libraries such as Scanpy for data I/O and preprocessing, Decoupler for enrichment analysis, and Matplotlib/Seaborn for visualization. The script reads an AnnData object containing raw PBMC counts, preserves a copy of the original counts, and then performs standard normalization and log-transformation to ensure that the data is comparable across cells. After identifying the top highly variable genes, the code applies dimensionality reduction techniques??PCA and UMAP??to visualize cell clusters and assess potential biological heterogeneity. It then constructs combined experimental groups by merging condition and cell type annotations, and runs a t-test for differential gene expression to rank genes for a specific target group. The t-statistics from this differential analysis are extracted to serve as input for the subsequent gene set enrichment analysis. In parallel, the workflow handles external pathway information by parsing a Reactome GMT file, filtering gene sets based on size criteria to retain only those with an optimal number of genes. Using the Decoupler package, the script correlates the differential expression statistics with the curated pathway gene sets, generating scores, normalized scores, and p-values to identify significantly enriched pathways. Finally, it visualizes the top twenty enriched pathways in a horizontal bar plot, with the bar lengths corresponding to the negative log-transformed p-values, thereby summarizing the key biological processes predominantly affected by the experimental condition.","numpy, pandas, scanpy, decoupler, matplotlib, seaborn",python,"#!/usr/bin/env python
""""""
Example script for gene set enrichment and pathway analysis for single?\cell RNA?\seq data.
This script reads an AnnData object, preprocesses the data, performs a t?\test to rank genes,
extracts DE t-statistics for a selected cell type/condition, loads a Reactome GMT file, runs GSEA via decoupler,
and plots the top enriched pathways.
""""""

#------------------------------------------------------------------------------#
#                           IMPORT NECESSARY PACKAGES                          #
#------------------------------------------------------------------------------#
from __future__ import annotations
import os
from pathlib import Path
import numpy as np
import pandas as pd
import scanpy as sc
import decoupler
import matplotlib.pyplot as plt
import seaborn as sns

# Set plotting style and scanpy figure parameters
sns.set(style=""whitegrid"")
sc.settings.set_figure_params(dpi=200, frameon=False, figsize=(4, 4))

#------------------------------------------------------------------------------#
#                              DATA INPUT/OUTPUT                               #
#------------------------------------------------------------------------------#
# Read the PBMC dataset from a .h5ad file. A backup URL is provided for reproducibility.
adata = sc.read(""kang_counts_25k.h5ad"", backup_url=""https://figshare.com/ndownloader/files/34464122"")

# Save the raw counts in a separate layer for later use
adata.layers[""counts""] = adata.X.copy()

# Rename the ""label"" column to ""condition"" for clarity
adata.obs = adata.obs.rename(columns={""label"": ""condition""})

#------------------------------------------------------------------------------#
#                           DATA PREPROCESSING                                 #
#------------------------------------------------------------------------------#
# Normalize the total counts per cell and log-transform the data
sc.pp.normalize_total(adata)
sc.pp.log1p(adata)

# Identify the top 4000 highly variable genes using the ""seurat_v3"" method;
# note that we use the untransformed counts for this purpose.
sc.pp.highly_variable_genes(
    adata, 
    n_top_genes=4000, 
    flavor=""seurat_v3"", 
    subset=False, 
    layer=""counts""
)

# Compute PCA, build a neighbor graph, and generate a UMAP representation
sc.pp.pca(adata)
sc.pp.neighbors(adata)
sc.tl.umap(adata)

# Plot UMAP embeddings colored by condition and cell type
sc.pl.umap(adata, color=[""condition"", ""cell_type""], frameon=False, ncols=2)

#------------------------------------------------------------------------------#
#                        DIFFERENTIAL EXPRESSION ANALYSIS                      #
#------------------------------------------------------------------------------#
# Create a combined group column (e.g., ""stim_FCGR3A+ Monocytes"") by concatenating condition and cell_type
adata.obs[""group""] = adata.obs[""condition""].astype(str) + ""_"" + adata.obs[""cell_type""]

# Run a t-test to rank genes based on differential expression across groups.
sc.tl.rank_genes_groups(adata, groupby=""group"", method=""t-test"", key_added=""t-test"")

# Define the target group for which we want to extract the differential expression ranking.
target_group = ""stim_FCGR3A+ Monocytes""

# Extract DE results for the target group using the t-test key.
de_df = sc.get.rank_genes_groups_df(adata, group=target_group, key=""t-test"")

# Only keep genes that are marked as highly variable and sort by the absolute t-statistic.
hvg_genes = adata.var_names[adata.var[""highly_variable""]]
de_df = de_df.set_index(""names"").loc[hvg_genes].sort_values(""scores"", key=np.abs, ascending=False)[[""scores""]]
# Rename the column to the target group name for clarity.
de_df = de_df.rename(columns={""scores"": target_group})
t_stats = de_df  # DataFrame of DE t-statistics

#------------------------------------------------------------------------------#
#                   PREPARING PATHWAY GENE SETS (Reactome GMT)                   #
#------------------------------------------------------------------------------#
# Define the path for the GMT file containing Reactome pathways.
gmt_path = Path(""c2.cp.reactome.v7.5.1.symbols.gmt"")
if not gmt_path.is_file():
    # Download the GMT file if it does not exist locally.
    os.system(""wget -O c2.cp.reactome.v7.5.1.symbols.gmt https://figshare.com/ndownloader/files/35233771"")

def gmt_to_decoupler(pth: Path) -> pd.DataFrame:
    """"""
    Parse a GMT file into a DataFrame compatible with decoupler.
    Each row contains a gene set and a gene symbol.
    """"""
    pathways = {}
    with pth.open(""r"") as f:
        for line in f:
            parts = line.strip().split(""\t"")
            # The first element is the gene set name; second element is ignored (description)
            name = parts[0]
            genes = parts[2:]  # genes start from the third column
            pathways[name] = genes
    # Convert the dictionary into a DataFrame (one row per gene in the set)
    data = []
    for gene_set, genes in pathways.items():
        for gene in genes:
            data.append((gene_set, gene))
    return pd.DataFrame(data, columns=[""geneset"", ""genesymbol""])

# Parse the GMT file into a DataFrame.
reactome = gmt_to_decoupler(gmt_path)

# Filter gene sets to only keep those with more than 15 and less than 500 genes
geneset_size = reactome.groupby(""geneset"").size()
gsea_genesets = geneset_size.index[(geneset_size > 15) & (geneset_size < 500)]

#------------------------------------------------------------------------------#
#                          RUNNING GSEA WITH DECOUPLER                         #
#------------------------------------------------------------------------------#
# Run gene set enrichment analysis using decoupler.
# The input is defined as a DataFrame of gene-level t-statistics, transposed so that genes are rows.
scores, norm, pvals = decoupler.run_gsea(
    t_stats.T, 
    reactome[reactome[""geneset""].isin(gsea_genesets)],
    source=""geneset"",
    target=""genesymbol""
)

# Combine the GSEA results into a single DataFrame and sort by p-value.
gsea_results = pd.concat({
    ""score"": scores.T,
    ""norm"": norm.T,
    ""pval"": pvals.T
}, axis=1).droplevel(level=1, axis=1).sort_values(""pval"")

# Name the index as 'Pathway' for clarity
gsea_results.index.name = ""Pathway""

#------------------------------------------------------------------------------#
#                              PLOTTING THE RESULTS                            #
#------------------------------------------------------------------------------#
# Plot the top 20 enriched pathways as a horizontal bar plot.
top20 = gsea_results.head(20).reset_index()
# Compute the negative log10 p-values (larger values indicate higher significance)
top20[""-log10(pval)""] = -np.log10(top20[""pval""])

plt.figure(figsize=(10, 8))
sns.barplot(data=top20, x=""-log10(pval)"", y=""Pathway"", palette=""viridis"")
plt.xlabel(""-log10(adjusted p-value)"")
plt.ylabel(""Pathway"")
plt.title(""Top 20 Enriched Pathways in "" + target_group)
plt.tight_layout()
plt.show()
",https://www.sc-best-practices.org/conditions/gsea_pathway.html
scRNA-seq,Cell-cell communication,"This analysis pipeline performs a **cell-cell communication (CCC) inference** from single-cell RNA sequencing data, identifying and visualizing ligand-receptor interactions between different cell types. It begins by preprocessing transcriptomic data, including quality control, normalization, and log transformation, to ensure accurate expression profiling. The pipeline defines sender and receiver cell types to investigate their potential signaling roles. Using **LIANA** and **CellPhoneDB**, it systematically infers significant **ligand-receptor interactions**, filtering based on expression levels and statistical significance. The results are then visualized in a dot plot, where interactions with strong ligand-receptor expression and low p-values are prioritized. This approach allows researchers to dissect cellular crosstalk mechanisms in biological systems, such as immune responses or tissue development, enabling hypotheses about how different cell types influence each other. Additionally, the workflow integrates prior knowledge databases to improve prediction robustness, helping identify biologically meaningful interactions. Ultimately, this computational strategy provides insights into **dynamic intercellular communication**, guiding further experimental validation and deepening our understanding of cellular coordination in health and disease.","scanpy, liana, decoupler, matplotlib, seaborn, pandas, numpy",python,"# Import required libraries
import scanpy as sc  # For single-cell RNA sequencing data analysis
import liana as li  # For ligand-receptor interaction inference
import decoupler as dc  # For computational methods on biological networks
import matplotlib.pyplot as plt  # Visualization
import seaborn as sns  # Advanced statistical graphics
import pandas as pd  # Data manipulation
import numpy as np  # Numerical operations

# Load single-cell transcriptomics data
adata = sc.read(""kang_counts_25k.h5ad"", backup_url=""https://figshare.com/ndownloader/files/34464122"")

# Store raw counts before normalization
adata.layers[""counts""] = adata.X.copy()

# Quality Control: Filter low-quality cells and genes
sc.pp.filter_cells(adata, min_genes=200)
sc.pp.filter_genes(adata, min_cells=3)

# Normalize and log-transform data
sc.pp.normalize_total(adata)
sc.pp.log1p(adata)

# Define source (sender) and target (receiver) cell types
source_cell_types = [""CD4 T cells"", ""B cells"", ""FCGR3A+ Monocytes""]
target_cell_types = [""CD8 T cells"", ""NK cells""]

# Run ligand-receptor interaction analysis using CellPhoneDB via LIANA
from liana.method import cellphonedb
cellphonedb(adata, groupby=""cell_type"", use_raw=False, return_all_lrs=True, verbose=True)

# Extract results
results = adata.uns[""liana_res""]

# Filter significant ligand-receptor interactions (p-value threshold)
significant_results = results[results[""cellphone_pvals""] <= 0.01]

# Visualize ligand-receptor interactions using dot plot
li.pl.dotplot(
    adata=adata,
    colour=""lr_means"",
    size=""cellphone_pvals"",
    inverse_size=True,
    source_labels=source_cell_types,
    target_labels=target_cell_types,
    filterby=""cellphone_pvals"",
    filter_lambda=lambda x: x <= 0.01,
    orderby=""lr_means"",
    orderby_ascending=False,
    top_n=20,
    figure_size=(9, 5),
    size_range=(1, 6)
)

# Show plot
plt.show()
",https://www.sc-best-practices.org/mechanisms/cell_cell_communication.html
scRNA-seq,Cell-cell communication,"This code performs a comprehensive cell?Ccell communication analysis on single-cell RNA sequencing data by integrating data processing, statistical inference, and visualization. Initially, the script imports essential modules such as Scanpy for managing single-cell data, LIANA for identifying ligand?Creceptor interactions, and Matplotlib for plotting. It begins by loading an example dataset??specifically a reduced PBMC dataset??using Scanpy, and generating a UMAP plot to visually confirm the cellular clusters based on predefined labels. Following the visualization of the cell populations, the code employs the LIANA package??s implementation of the CellPhoneDB method to infer significant ligand?Creceptor interactions among different cell types. This inference is based on the expression levels of ligands and receptors, and the algorithm evaluates the statistical significance of these interactions using permutation testing, storing the results within the AnnData object. To facilitate interpretation, the script produces two types of visualizations: a dotplot and a tileplot. The dotplot graphically represents the magnitude of interactions and their significance (p-values) by adjusting dot colors and sizes, while the tileplot provides a detailed view of the mean expression levels and the proportion of cells expressing the relevant genes. Overall, this code establishes a reproducible, end-to-end workflow that takes preprocessed single-cell data through to advanced intercellular communication analysis, yielding insights into how different cell clusters may interact via specific ligand?Creceptor pairs in a biological context.","scanpy, liana, matplotlib",python,"# Import necessary packages
import scanpy as sc           # for single-cell data handling and visualization
import liana as li            # for cell-cell communication analysis
import matplotlib.pyplot as plt  # for general plotting (if needed)

# -----------------------------
# Data I/O: Load an example dataset
# -----------------------------
# Here we use the pbmc68k_reduced dataset from Scanpy's built-in datasets.
adata = sc.datasets.pbmc68k_reduced()

# Plot a UMAP to visualize the cell clusters (using the cell identities stored in 'bulk_labels')
sc.pl.umap(adata, color='bulk_labels', title='UMAP of PBMC68k', frameon=False)

# -----------------------------
# Run Cell?CCell Communication Analysis with LIANA
# -----------------------------
# LIANA??s functions expect an AnnData object with processed single-cell transcriptomics data.
# In this example we use the CellPhoneDB method to infer ligand?Creceptor interactions.
li.cellphonedb(
    adata,
    groupby='bulk_labels',      # group cells by defined cell type labels in adata.obs['bulk_labels']
    resource_name='consensus',  # resource for ligand-receptor pairs (using consensus)
    expr_prop=0.1,              # minimum fraction of cells required to express ligand/receptor
    verbose=True,               # print additional information during processing
    key_added='cpdb_res'        # results are stored in adata.uns under this key
)

# Print out the first few rows of the result to inspect the output
print(""CellPhoneDB Results (first 5 rows):"")
print(adata.uns['cpdb_res'].head())

# -----------------------------
# Plotting: Dotplot of Ligand-Receptor Interactions
# -----------------------------
# In this dotplot, the dot color is scaled by the interaction magnitude (lr_means)
# and the dot size is scaled by the p-values (cellphone_pvals), where smaller p-values produce larger dots.
li.pl.dotplot(
    adata=adata,
    colour='lr_means',          # ligand-receptor mean score for color scaling
    size='cellphone_pvals',     # permutation-based p-values for size scaling
    inverse_size=True,          # invert size so that lower p-values (more significant) are larger
    source_labels=['CD34+', 'CD56+ NK', 'CD14+ Monocyte'],  # example list of source cell types
    target_labels=['CD34+', 'CD56+ NK'],                     # example list of target cell types
    figure_size=(8, 7),
    filter_fun=lambda x: x['cellphone_pvals'] <= 0.05,   # filter to include only significant interactions
    uns_key='cpdb_res'          # specify the key in adata.uns where LIANA results are stored
)

# Show the dotplot figure
plt.show()

# -----------------------------
# Plotting: Tileplot to Visualize Expression Statistics
# -----------------------------
# This tileplot visualizes the mean expression and the proportion of cells expressing
# the ligand or receptor. The fill color corresponds to the mean expression and the label
# shows the proportion (formatted to 2 decimal places). Only the top 10 interactions are plotted.
tile_plot = li.pl.tileplot(
    adata=adata,
    fill='means',               # use the mean expression values as the tile fill
    label='props',              # use the proportion of expressing cells as the tile label
    label_fun=lambda x: f'{x:.2f}',  # format the labels to 2 decimal places
    top_n=10,                   # display only the top 10 ligand-receptor interactions
    orderby='cellphone_pvals',  # order interactions based on p-values
    orderby_ascending=True,     # sort in ascending order (more significant interactions first)
    source_labels=['CD34+', 'CD56+ NK', 'CD14+ Monocyte'],
    target_labels=['CD34+', 'CD56+ NK'],
    uns_key='cpdb_res',         # use the CellPhoneDB result stored in adata.uns
    source_title='Ligand',      # title for source cell axes
    target_title='Receptor',    # title for target cell axes
    figure_size=(8, 7)
)

# Display the tileplot figure
plt.show()
",https://liana-py.readthedocs.io/en/latest/notebooks/basic_usage.html
scRNA-seq,Cell-cell communication,"This Python script executes a cell-cell communication analysis pipeline using **LIANA** and **Tensor-cell2cell**, focusing on ligand-receptor interactions to uncover intercellular signaling mechanisms. It begins with loading and preprocessing single-cell RNA sequencing data, ensuring proper normalization and filtering for robust downstream analysis. Using **LIANA**, the script identifies significant ligand-receptor interactions by ranking them across cell types and conditions. The results are formatted into a tensor structure, where each dimension represents communication contexts, ligand-receptor pairs, sender cells, and receiver cells. The tensor decomposition method implemented via **Tensor-cell2cell** then extracts latent communication patterns across conditions, allowing for a deeper understanding of context-driven signaling changes. UMAP plots visualize cellular distributions, while network plots highlight specific intercellular interactions enriched in distinct factors. Additionally, **decoupler** is employed for pathway enrichment analysis, revealing biological processes linked to inferred communication networks. This workflow enables the characterization of dynamic cellular interactions in complex biological environments, providing insights into condition-specific communication shifts and potential regulatory mechanisms underlying cellular responses.","pandas, scanpy, liana, decoupler, cell2cell, seaborn, matplotlib",python,"# Import required libraries
import pandas as pd
import scanpy as sc
import liana as li
import decoupler as dc
import cell2cell as c2c
import seaborn as sns
import matplotlib.pyplot as plt
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Load sample dataset (replace this with your own data)
adata = li.testing.datasets.kang_2018()

# Basic quality control and preprocessing
sc.pp.filter_cells(adata, min_genes=200)
sc.pp.filter_genes(adata, min_cells=3)
sc.pp.normalize_total(adata)
sc.pp.log1p(adata)

# Define sample and condition keys
sample_key = 'sample'
condition_key = 'condition'
groupby = 'cell_type'

# Run LIANA for ligand-receptor inference
liana_results = li.mt.rank_aggregate.by_sample(
    adata,
    groupby=groupby,
    resource_name='consensus',  # Use consensus ligand-receptor interactions
    sample_key=sample_key,
    use_raw=False,
    verbose=True,
    n_perms=None,
    return_all_lrs=True
)

# Store results in AnnData object
adata.uns[""liana_res""] = liana_results

# Display the first few results
print(adata.uns[""liana_res""].sort_values(""magnitude_rank"").head())

# Plot UMAP visualization of cell types and conditions
sc.pl.umap(adata, color=[condition_key, groupby], frameon=False)

# Construct a tensor for communication analysis
tensor = li.multi.to_tensor_c2c(
    adata,
    sample_key=sample_key,
    score_key=""magnitude_rank"",
    how=""outer_cells""
)

# Perform tensor decomposition analysis
tensor = c2c.analysis.run_tensor_cell2cell_pipeline(
    tensor,
    copy_tensor=True,
    rank=6,  # Adjust rank as needed
    tf_optimization='regular',
    random_state=0,
    device=""cpu"",
    elbow_metric='error',
    smooth_elbow=False,
    upper_rank=20,
    tf_init='random',
    tf_svd='numpy_svd',
    output_fig=False
)

# Visualize factor decomposition results
factors, axes = c2c.plotting.tensor_factors_plot(
    interaction_tensor=tensor,
    fontsize=10
)

# Show enriched communication networks
c2c.plotting.ccc_networks_plot(factors, included_factors=['Factor 6'])

# Save plots
plt.savefig(""cell_cell_communication_analysis.png"", dpi=300)
plt.show()
",https://liana-py.readthedocs.io/en/latest/notebooks/liana_c2c.html
scRNA-seq,Cell-cell communication,"This bioinformatics pipeline performs differential gene expression analysis and downstream signaling pathway inference based on cell-cell communication (CCC) events. First, it processes single-cell RNA sequencing data to filter and normalize gene expression profiles, ensuring high-quality input for analysis. Using pseudobulk aggregation, it reconstructs expression patterns across different cell types and conducts differential expression analysis (DEA) with DESeq2, identifying genes whose expression is significantly altered between experimental conditions. The pipeline then integrates these results into a ligand-receptor framework using LIANA, pinpointing deregulated interactions that influence intercellular communication. Key interactions are visualized and prioritized based on statistical significance. To explore their biological implications, the workflow applies transcription factor activity inference via Decoupler, mapping gene perturbations to regulatory networks. Finally, enriched pathways and intracellular signaling networks are inferred, revealing potential molecular mechanisms linking CCC disruptions to cellular responses. The approach combines statistical rigor, network biology, and interactive visualization, allowing researchers to interpret CCC-mediated changes in gene regulation and identify potential therapeutic targets or biomarkers within complex biological systems.","numpy, pandas, scanpy, plotnine, liana, decoupler, omnipath, pydeseq2",python,"# Import necessary libraries
import numpy as np
import pandas as pd
import scanpy as sc
import plotnine as p9
import liana as li
import decoupler as dc
import omnipath as op
from pydeseq2.dds import DeseqDataSet
from pydeseq2.ds import DeseqStats

# Load the dataset (Example dataset from LIANA)
adata = li.testing.datasets.kang_2018()

# Define metadata columns of interest
sample_key = 'sample'
groupby = 'cell_abbr'
condition_key = 'condition'

# Perform basic quality control filtering
sc.pp.filter_cells(adata, min_genes=200)
sc.pp.filter_genes(adata, min_cells=3)

# Plot UMAP for visualization
sc.pl.umap(adata, color=[condition_key, sample_key, 'cell_type', groupby], frameon=False, ncols=2)

# Generate pseudobulk profiles for each cell type
pdata = dc.get_pseudobulk(
    adata, sample_col=sample_key, groups_col=groupby, layer='counts',
    mode='sum', min_cells=10, min_counts=10000
)

# Perform differential expression analysis (DEA) using PyDESeq2
dea_results = {}
for cell_group in pdata.obs[groupby].unique():
    ctdata = pdata[pdata.obs[groupby] == cell_group].copy()
    
    # Filter genes based on expression thresholds
    genes = dc.filter_by_expr(ctdata, group=condition_key, min_count=5, min_total_count=10)
    ctdata = ctdata[:, genes].copy()
    
    # Build DESeq2 object
    dds = DeseqDataSet(
        adata=ctdata, design_factors=condition_key, ref_level=[condition_key, 'ctrl'],
        refit_cooks=True, quiet=True
    )
    dds.deseq2()
    
    # Compute differential expression statistics
    stat_res = DeseqStats(dds, contrast=[condition_key, 'stim', 'ctrl'])
    stat_res.summary()
    stat_res.lfc_shrink(coeff='condition_stim_vs_ctrl')
    
    dea_results[cell_group] = stat_res.results_df

# Concatenate results across cell types
dea_df = pd.concat(dea_results).reset_index().rename(columns={'level_0': groupby, 'level_1': 'index'}).set_index('index')

# Identify deregulated ligand-receptor interactions using LIANA
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)

lr_res = li.multi.df_to_lr(
    adata, dea_df=dea_df, resource_name='consensus',
    expr_prop=0.1, groupby=groupby, stat_keys=['stat', 'pvalue', 'padj'],
    use_raw=False, complex_col='stat', return_all_lrs=False
)

# Sort ligand-receptor interactions by statistical significance
lr_res = lr_res.sort_values(""interaction_stat"", ascending=False)

# Plot top interactions using LIANA's tileplot function
li.pl.tileplot(
    liana_res=lr_res, fill='expr', label='padj',
    label_fun=lambda x: '*' if x < 0.05 else np.nan,
    top_n=15, orderby='interaction_stat', orderby_ascending=False,
    source_title='Ligand', target_title='Receptor'
)

# Perform pathway enrichment analysis using Decoupler's TF activity inference
net = dc.get_collectri()
dea_wide = dea_df[[groupby, 'stat']].reset_index(names='genes').pivot(index=groupby, columns='genes', values='stat').fillna(0)

# Run enrichment analysis
estimates, pvals = dc.run_ulm(mat=dea_wide, net=net)

# Select top transcription factors associated with deregulated pathways
top_tfs = estimates.T.sort_values('CD14', key=abs, ascending=False).head()
print(top_tfs)
",https://liana-py.readthedocs.io/en/latest/notebooks/targeted.html
scRNA-seq,Enrichment analysis,"This Python script performs pathway enrichment analysis on single-cell RNA sequencing (scRNA-seq) data, allowing researchers to infer biological activity from gene expression profiles. The process begins with loading a dataset of peripheral blood mononuclear cells (PBMCs), followed by clustering visualization using UMAP. Then, predefined gene sets from PROGENy, which correspond to known signaling pathways, are used to compute enrichment scores via a univariate linear model (ULM). This model evaluates whether specific pathways are overrepresented or underrepresented in individual cells, providing insights into their functional states. The computed scores are extracted and visualized through UMAP projections, violin plots, and matrix plots, enabling comparisons across different cell types. These visualizations reveal pathway activity variations, such as TNF?? signaling strength across different cell populations. The workflow facilitates biological interpretation by connecting transcriptional profiles to cellular functions, making complex gene expression data more accessible and actionable for understanding molecular mechanisms driving cell behavior. This approach is useful for studying differentiation processes, disease mechanisms, and therapeutic targets in single-cell genomics.","scanpy, decoupler, matplotlib",python,"# Import necessary libraries
import scanpy as sc
import decoupler as dc
import matplotlib.pyplot as plt

# Set default figure parameters for visualization
sc.set_figure_params(figsize=(5, 5), frameon=False)

# Load the dataset (PBMCs example)
adata = dc.ds.pbmc3k()

# Display dataset summary
print(adata)

# Perform basic UMAP visualization of clusters
sc.pl.umap(adata, color='leiden')

# Load pathway gene sets (e.g., Reactome or PROGENy)
progeny = dc.op.progeny(organism='human')

# Compute pathway enrichment scores using univariate linear model
dc.mt.ulm(data=adata, net=progeny)

# Extract computed enrichment scores
score = dc.pp.get_obsm(adata, key='score_ulm')

# Plot enrichment scores for a selected pathway (e.g., TNF?? signaling)
sc.pl.umap(score, color=['TNFa'], cmap='RdBu_r', vcenter=0)
sc.pl.violin(score, keys=['TNFa'], groupby='celltype', rotation=90)

# Show top predicted pathways per cell type using matrix plot
sc.pl.matrixplot(adata=score, var_names=score.var_names, groupby='celltype', 
                 dendrogram=True, standard_scale='var', colorbar_title='Z-scaled scores',
                 cmap='RdBu_r')

plt.show()
",https://decoupler-py.readthedocs.io/en/latest/notebooks/scell/rna_sc.html
scRNA-seq,Enrichment analysis,"This Python script carries out an enrichment analysis workflow on single-cell RNA sequencing data, integrating preprocessing, differential expression analysis, and pathway enrichment. The process begins with loading the dataset and conducting pseudobulking, aggregating gene expression per cell type to reduce noise and enhance statistical robustness. Following quality control filtering, the script normalizes and transforms the data, performing PCA to explore variability across biological samples. Differential expression analysis is then conducted using DESeq2 to identify significant gene expression changes between disease and control conditions. These results form the basis for enrichment analysis, where pathway deregulation is inferred using PROGENy, highlighting key cellular signaling pathways impacted by the condition. The final output includes visualization steps such as UMAP projections, PCA variance plots, volcano plots for differential expression, and pathway activity bar plots, ensuring the results are both interpretable and actionable. This workflow enables researchers to systematically investigate transcriptional responses and biological mechanisms underlying disease progression in a clear and structured manner.
","numpy, scanpy, pandas,decoupler",python,"# Import necessary libraries
import numpy as np
import pandas as pd
import scanpy as sc
import decoupler as dc

# Set figure parameters for better visualization
sc.set_figure_params(figsize=(4, 4), frameon=False)

# Load example dataset: Single-cell RNA sequencing data
adata = dc.ds.covid5k()

# Display basic dataset information
print(adata)

# Visualize UMAP plot to check the cell-type distribution
sc.pl.umap(adata, color=['celltype', 'disease'], ncols=1)

# Perform pseudobulking: Aggregating expression per cell type
pdata = dc.pp.pseudobulk(adata=adata, sample_col='individual', groups_col='celltype', mode='sum')

# Apply quality control filtering for low-quality samples
dc.pp.filter_samples(pdata, min_cells=10, min_counts=1000)

# Visualize filtered samples to confirm cell-type composition
dc.pl.obsbar(adata=pdata, y='celltype', hue='disease', figsize=(6, 3))

# Normalize and preprocess data for variability analysis
pdata.layers['counts'] = pdata.X.copy()
sc.pp.normalize_total(pdata, target_sum=1e4)
sc.pp.log1p(pdata)
sc.pp.scale(pdata, max_value=10)

# Perform PCA analysis to explore variability across samples
sc.tl.pca(pdata)
dc.pl.obsm(adata=pdata, return_fig=True, nvar=5, titles=['PC scores', 'Adjusted p-values'], figsize=(10, 5))

# Perform differential expression analysis using DESeq2
from pydeseq2.dds import DeseqDataSet, DefaultInference
from pydeseq2.ds import DeseqStats

# Define the DESeq2 model
inference = DefaultInference(n_cpus=8)
dds = DeseqDataSet(adata=pdata, design_factors=['disease', 'sex'], refit_cooks=True, inference=inference)

# Compute log-fold changes (LFCs) for differential expression
dds.deseq2()

# Extract statistical results
stat_res = DeseqStats(dds, contrast=['disease', 'COVID-19', 'normal'], inference=inference)
stat_res.summary()

# Extract results and visualize a volcano plot
results_df = stat_res.results_df
dc.pl.volcano(results_df, x='log2FoldChange', y='pvalue')

# Perform enrichment analysis using PROGENy pathways
progeny = dc.op.progeny(organism='human')
pw_acts, pw_padj = dc.mt.ulm(data=results_df[['stat']].T.rename(index={'stat': 'disease.vs.normal'}), net=progeny)

# Filter enrichment results by adjusted p-value significance
msk = (pw_padj.T < 0.05).iloc[:, 0]
pw_acts = pw_acts.loc[:, msk]

# Visualize pathway enrichment results
dc.pl.barplot(data=pw_acts, name='disease.vs.normal', figsize=(3, 3))
",https://decoupler-py.readthedocs.io/en/latest/notebooks/scell/rna_psbk.html
scRNA-seq,Enrichment analysis,"This code executes a comprehensive single-cell RNA sequencing (scRNA-seq) analysis to dissect dynamic biological processes during mouse gastrulation. It begins by importing essential Python libraries, such as NumPy for numerical operations, Scanpy for single-cell data processing and visualization, and Decoupler for enrichment analysis. The workflow loads a preprocessed scRNA dataset that contains log-normalized transcript counts along with detailed cell metadata, and it initially visualizes the data using UMAP plots to reveal the distribution of cells across different types and developmental stages. To capture the continuity of the differentiation process, the code calculates pseudotime by identifying a root cell population and applying diffusion maps and diffusion pseudotime methods, thereby ordering the cells along a developmental trajectory. Following this, the analysis focuses on functional enrichment; it utilizes the univariate linear model (ULM) method to compute enrichment scores for transcription factors and pathways from established networks such as CollecTRI (for TF activity) and PROGENy (for pathway activity). The enrichment scores facilitate the detection of key regulatory elements??like the transcription factor 'Klf3'??and the activity of critical pathways, exemplified by 'PI3K', across the pseudotime trajectory. Furthermore, the pipeline includes detailed plotting steps, generating informative UMAP and violin plots that illustrate how these regulatory signals vary among different cell types. In essence, the code elegantly integrates data I/O, dimensionality reduction, pseudotime inference, enrichment scoring, and robust visualization to provide insight into the regulatory mechanisms that drive cellular progression in developmental biology.","numpy, scanpy, pandas,decoupler",python,"# Import necessary packages
import numpy as np
import scanpy as sc
import decoupler as dc

# Set default figure parameters for Scanpy plots
sc.set_figure_params(figsize=(5, 5), frameon=False)

# -----------------------
# Data I/O and Preprocessing
# -----------------------
# Load a sample single-cell RNA-seq dataset (mouse gastrulation dataset)
# The dataset contains log-normalized transcript counts and cell metadata.
adata = dc.ds.erygast1k()

# Visualize the raw data in UMAP space by coloring cells by 'celltype' and 'stage'
sc.pl.umap(adata, color=['celltype', 'stage'], ncols=1)

# -----------------------
# Pseudotime Inference (Optional but useful for ordering cells in continuous processes)
# -----------------------
# Identify the root cell type (starting point of the trajectory).
root_celltype = ""Blood progenitors 1""

# Compute neighbors using PCA representation
sc.pp.neighbors(adata, use_rep='X_pca')

# Compute a diffusion map for non-linear embedding.
sc.tl.diffmap(adata)

# Recompute neighbors using the diffusion map representation
sc.pp.neighbors(adata, use_rep='X_diffmap')

# Run Partition-based Graph Abstraction (PAGA) to visualize cell group connectivity.
sc.tl.paga(adata, groups='celltype')

# Get the index of the first cell in the defined root population
iroot = np.flatnonzero(adata.obs['celltype'] == root_celltype)[0]
adata.uns['iroot'] = iroot

# Compute diffusion pseudotime (DPT) to order cells along the continuous trajectory
sc.tl.dpt(adata)

# Optional: Visualize the pseudotime ordering on UMAP
sc.pl.umap(adata, color=['celltype', 'dpt_pseudotime'], legend_loc='on data')

# -----------------------
# Enrichment Analysis -- Transcription Factor (TF) Scoring
# -----------------------
# Retrieve the CollecTRI network for the mouse. This network contains TFs and their target genes.
collectri = dc.op.collectri(organism='mouse')

# Run enrichment analysis using the univariate linear model (ULM) method.
# This computes a score per cell for each TF (or regulon) in the network.
dc.mt.ulm(data=adata, net=collectri)

# Extract the computed enrichment scores from the AnnData object's obsm attribute.
score_tf = dc.pp.get_obsm(adata, key='score_ulm')
print(""TF enrichment score object:"", score_tf)

# Choose a transcription factor to visualize, e.g. ""Klf3""
tf = 'Klf3'

# Plot a UMAP colored by the TF enrichment score and cell type.
sc.pl.umap(score_tf, color=[tf, 'celltype'], cmap='RdBu_r', vcenter=0)

# Plot a violin plot to show the distribution of the TF score across cell types.
sc.pl.violin(score_tf, keys=[tf], groupby='celltype', rotation=90, ylabel=f'{tf} score')

# -----------------------
# Enrichment Analysis -- Pathway Scoring
# -----------------------
# Retrieve the PROGENy pathway gene set for the mouse.
progeny = dc.op.progeny(organism='mouse')

# Compute pathway enrichment scores using the ULM method.
dc.mt.ulm(data=adata, net=progeny)

# Extract the computed pathway scores.
score_pathway = dc.pp.get_obsm(adata, key='score_ulm')
print(""Pathway enrichment score object:"", score_pathway)

# Visualize the enrichment score for a selected pathway, for example ""PI3K""
sc.pl.umap(score_pathway, color=['PI3K', 'celltype'], cmap='RdBu_r', vcenter=0)

# Generate a violin plot for the pathway score across different cell types.
sc.pl.violin(score_pathway, keys=['PI3K'], groupby='celltype', rotation=90, ylabel='PI3K score')
",https://decoupler-py.readthedocs.io/en/latest/notebooks/scell/rna_pstime.html
scRNA-seq,Gene regulatory networks analysis,"This Python script is designed to analyze gene regulatory networks (GRNs) from single?\cell RNA sequencing data. It begins by importing essential libraries for data processing, visualization, and I/O operations, and then loads an AnnData object containing gene expression counts. The script filters for RNA-specific features, applies a log-transformation, and identifies highly variable genes to focus on the most informative features. It also provides quality control by visualizing cellular heterogeneity using UMAP embeddings that highlight both cell-type and batch effects, and further subsets the data to concentrate on a specific donor or batch for more focused regulatory analysis. A key aspect of the workflow is converting the processed single-cell expression data into a loom file??a format required for the SCENIC pipeline. Although the actual GRN inference with SCENIC is performed externally (typically via command-line execution), the resulting output (a CSV file of TF?Ctarget associations) is then read back into the script. The code proceeds to plot the distribution of importance scores from the GRN analysis, providing insight into the strength of predicted regulatory interactions. Additionally, it calculates the number of genes detected per cell, using histogram plots to assess data coverage and further inform subsequent analyses. Overall, the script integrates comprehensive data preprocessing, visualization, and formatting steps to facilitate the deciphering of complex regulatory relationships in heterogeneous cell populations, ultimately aiding in the discovery of key transcription factors and their downstream targets in a biologically meaningful context.","pyscenic, loompy, matplotlib, numpy, pandas, scanpy, seaborn","python, bash","# Import necessary libraries
import warnings
from pathlib import Path
import loompy
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scanpy as sc
import seaborn as sns

# Suppress warnings for cleaner output
warnings.filterwarnings(""ignore"")

# =============================================================================
# Step 1: Data Input and Preprocessing
# =============================================================================

# Load the single-cell RNA-seq data (h5ad file)
# Replace the file path with your actual data file
adata = sc.read_h5ad(""path/to/your_openproblems_bmmc_multiome_genes_filtered.h5ad"")
print(""Dataset shape:"", adata.shape)

# Filter for RNA-only features.
# Here we assume that the 'feature_types' column in adata.var classifies features; GEX stands for gene expression.
rna = adata[:, adata.var[""feature_types""] == ""GEX""]
del adata  # free up memory from the original data object

# Apply a log-transformation to the data
sc.pp.log1p(rna)

# Print batch distribution and dimension information for quality control
print(""Batch distribution:\n"", rna.obs[""batch""].value_counts())
print(""RNA data shape:"", rna.shape)

# Identify highly variable genes (HVGs) to focus on informative features
sc.pp.highly_variable_genes(rna, batch_key=""batch"", flavor=""seurat"")
sc.set_figure_params(facecolor=""white"")

# Visualize the UMAP embedding (UMAP coordinates should be precomputed or stored in rna.obs)
sc.pl.embedding(rna, ""GEX_X_umap"", color=[""cell_type"", ""batch""], title=""UMAP: All Cells"")

# =============================================================================
# Step 2: Subset Data for a Specific Batch (e.g., donor 's1d1')
# =============================================================================

# Subset the data to only include cells from donor 's1d1'
adata_batch = rna[rna.obs[""batch""] == ""s1d1"", :]

# Visualize the subset using the same UMAP coordinates
sc.pl.embedding(adata_batch, ""GEX_X_umap"", color=[""cell_type"", ""batch""], title=""UMAP: Donor s1d1"")

# =============================================================================
# Step 3: Creating a Loom File for SCENIC (GRN Analysis)
# =============================================================================

# SCENIC requires a loom file as input. Prepare row and column attributes.
loom_path = ""data/neurips_processed_input.loom""  # adjust path as needed

row_attributes = {
    ""Gene"": np.array(adata_batch.var.index)
}

col_attributes = {
    ""CellID"": np.array(adata_batch.obs.index),
    ""nGene"": np.array(np.sum(adata_batch.X.transpose() > 0, axis=0)).flatten(),
    ""nUMI"": np.array(np.sum(adata_batch.X.transpose(), axis=0)).flatten()
}

# Create the loom file (note that the expression matrix is transposed)
loompy.create(loom_path, adata_batch.X.transpose(), row_attributes, col_attributes)
print(""Loom file created at:"", loom_path)

# =============================================================================
# Step 4: Running SCENIC GRN Inference (External Step)
# =============================================================================

# -------------------------------------------------------------------------------
# The GRN inference in SCENIC is typically executed via a command line tool.
# For example, one would run the following shell command:
#
#   pyscenic grn data/neurips_processed_input.loom allTFs_hg38.txt \
#          -o adj.csv --num_workers 3
#
# In this script we assume that the GRN output has been saved in a CSV file named 'adj.csv'.
# -------------------------------------------------------------------------------

# =============================================================================
# Step 5: Load GRN Associations and Visualize Importance Scores
# =============================================================================

# Read the GRN associations output from the pyscenic pipeline (adj.csv)
results_adjacencies = pd.read_csv(""adj.csv"", sep="","")
print(f""Number of GRN associations found: {results_adjacencies.shape[0]}"")
print(results_adjacencies.head())

# Plot a histogram of the log10-transformed importance scores from the GRN analysis.
plt.figure(figsize=(8, 5))
plt.hist(np.log10(results_adjacencies[""importance""]), bins=50, color=""skyblue"", edgecolor=""black"")
plt.xlabel(""Log10(Importance Score)"")
plt.ylabel(""Frequency"")
plt.title(""Distribution of GRN Importance Scores"")
plt.xlim([-10, 10])
plt.show()

# =============================================================================
# Step 6: Additional Plotting Example ?C Genes Detected per Cell
# =============================================================================

# Calculate the number of genes detected per cell (i.e., count of non-zero expression values)
# If adata_batch.X is a sparse matrix, convert it to a dense format before flattening.
n_genes_detected_per_cell = np.sum(adata_batch.X > 0, axis=1)

# Flatten the count data to create a Pandas Series (use .A.flatten() for sparse matrices)
n_genes_series = pd.Series(n_genes_detected_per_cell.A.flatten())

# Compute quantiles to help set thresholds (e.g., for downstream AUCell analysis)
percentiles = n_genes_series.quantile([0.01, 0.05, 0.10, 0.50, 1])
print(""Quantiles of genes detected per cell:\n"", percentiles)

# Plot the distribution of detected genes per cell using Seaborn
fig, ax = plt.subplots(figsize=(8, 5), dpi=100)
sns.histplot(n_genes_series, bins=""fd"", edgecolor=""black"", ax=ax)
for i, q in enumerate(percentiles):
    ax.axvline(x=q, color=""red"", linestyle=""--"")
    # Add annotation text for the first quantile as an example
    if i == 0:
        ax.text(q, ax.get_ylim()[1]*0.9, f""{int(q)} ({percentiles.index[i]*100:.0f}%)"",
                rotation=30, fontsize=""x-small"", color=""red"")
ax.set_xlabel(""Number of Genes Detected"")
ax.set_ylabel(""Number of Cells"")
ax.set_title(""Distribution of Genes Detected per Cell"")
plt.tight_layout()
plt.show()
",https://www.sc-best-practices.org/mechanisms/gene_regulatory_networks.html
