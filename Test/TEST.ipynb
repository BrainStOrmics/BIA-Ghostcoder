{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2ccf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload    \n",
    "%autoreload 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f149477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from pathlib import Path # To set data downloading path\n",
    "\n",
    "# Append ghostcoder folder to path \n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from ghostcoder.config import *\n",
    "from ghostcoder.utils import initial_setups, initial_log\n",
    "\n",
    "# For visualize the graph\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89124644",
   "metadata": {},
   "source": [
    "Here we will test and illustrate each subgraph in Ghostcoder, as an important component of BIA (bioinformatics agnet), mainly functions to complete the generation and execution of bioinformatics analysis codes. It contains five subgraphs. They are filemanager, retriever, coder and webcrawler executor respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb5572",
   "metadata": {},
   "source": [
    "### Set ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72a1121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following keys are using default:\n",
      "\n",
      "\n",
      "\n",
      "File dir path all set.\n"
     ]
    }
   ],
   "source": [
    "# Load setup\n",
    "load_yaml_config('../config.yaml')\n",
    "initial_setups()\n",
    "initial_log('test_log.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e20348",
   "metadata": {},
   "source": [
    "\n",
    "##### Test LLM setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfb68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bioinformatics is an interdisciplinary field that combines **biology**, **computer science**, **mathematics**, and **statistics** to analyze and interpret biological data. It focuses on developing computational methods and tools to manage, process, and extract meaningful insights from large-scale biological datasets, such as DNA sequences, protein structures, gene expression profiles, and metabolic pathways.\n",
      "\n",
      "### Key Goals of Bioinformatics:\n",
      "1. **Understand Biological Processes**: Decode mechanisms of life at molecular levels (e.g., gene regulation, protein interactions).  \n",
      "2. **Advance Medicine**: Identify disease biomarkers, drug targets, and enable personalized medicine.  \n",
      "3. **Analyze Evolutionary Relationships**: Study genetic diversity and evolutionary history through comparative genomics.  \n",
      "4. **Improve Agriculture**: Enhance crop and livestock breeding using genomic data.\n",
      "\n",
      "---\n",
      "\n",
      "### Core Areas of Focus:\n",
      "1. **Genomics**:  \n",
      "   - Sequencing and assembling genomes (e.g., Human Genome Project).  \n",
      "   - Identifying genetic variations (SNPs, mutations) linked to diseases.  \n",
      "2. **Proteomics**:  \n",
      "   - Predicting protein structures and functions (e.g., AlphaFold).  \n",
      "   - Analyzing protein-protein interactions.  \n",
      "3. **Transcriptomics**:  \n",
      "   - Studying gene expression patterns (via RNA sequencing).  \n",
      "4. **Metabolomics**:  \n",
      "   - Modeling metabolic pathways and networks.  \n",
      "5. **Phylogenetics**:  \n",
      "   - Reconstructing evolutionary trees using genetic data.  \n",
      "\n",
      "---\n",
      "\n",
      "### Tools & Techniques:\n",
      "- **Sequence Analysis**: BLAST, Clustal Omega (alignment tools).  \n",
      "- **Structural Prediction**: SWISS-MODEL, PyMOL.  \n",
      "- **Data Mining**: Machine learning (e.g., for cancer subtype classification).  \n",
      "- **Databases**: GenBank (DNA sequences), UniProt (proteins), PDB (protein structures).  \n",
      "- **Programming**: Python, R, Bioconductor, and bioinformatics-specific libraries.  \n",
      "\n",
      "---\n",
      "\n",
      "### Applications:\n",
      "- **Precision Medicine**: Tailoring treatments based on genetic profiles (e.g., cancer genomics).  \n",
      "- **Drug Discovery**: Virtual screening of compounds to find potential drugs.  \n",
      "- **CRISPR & Gene Editing**: Designing guide RNAs for targeted genome editing.  \n",
      "- **Microbiome Analysis**: Studying microbial communities in environments or the human gut.  \n",
      "\n",
      "---\n",
      "\n",
      "### Challenges:\n",
      "- **Big Data**: Managing terabytes of data from next-gen sequencing.  \n",
      "- **Algorithm Development**: Creating efficient tools for complex analyses.  \n",
      "- **Integration**: Combining multi-omics data (genomics, proteomics, etc.) into cohesive models.  \n",
      "- **Ethical Issues**: Privacy concerns with genomic data and equitable access to technologies.  \n",
      "\n",
      "---\n",
      "\n",
      "### Future Directions:\n",
      "- **AI Integration**: Deep learning for predictive modeling in drug design.  \n",
      "- **Single-Cell Analysis**: Unraveling cellular heterogeneity.  \n",
      "- **Synthetic Biology**: Designing artificial organisms for industrial applications.  \n",
      "\n",
      "Bioinformatics bridges the gap between raw biological data and actionable knowledge, revolutionizing fields from healthcare to environmental science. Its interdisciplinary nature ensures it will remain pivotal in tackling global challenges like disease, climate change, and food security.\n"
     ]
    }
   ],
   "source": [
    "# Test LLM\n",
    "response = llm_config.MODELS['chat_model'].invoke(\"What is bioinformatics\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec691e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c345b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28add431",
   "metadata": {},
   "source": [
    "#### Check set-ups of Tavily search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fe9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.config import tavily_config\n",
    "tavily_config.API_KEY, tavily_config.MAX_RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94247d2",
   "metadata": {},
   "source": [
    "### Omics data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8466b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#──────work_dir \n",
    "#  └───data\n",
    "#    └─Input_data.whatever\n",
    "# First lets download a scRNAseq data\n",
    "import scanpy as sc\n",
    "import shutil\n",
    "from ghostcoder.config import file_config\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "# Ghostcoder pre-set WORK_DIR and INPUT_DATA_DIR for continues bioinformatics tasks using one input data\n",
    "\n",
    "# Download scRNAseq data\n",
    "sc.settings.datasetdir = current_dir/ file_config.INPUT_DATA_DIR # Download data into data/ folder in current dir\n",
    "sc.datasets.pbmc3k()\n",
    "\n",
    "# Remove temp data file\n",
    "current_dir = 'data'\n",
    "sub_dir = [d for d in os.listdir(current_dir)  if os.path.isdir(os.path.join(current_dir, d))]\n",
    "try:\n",
    "    shutil.rmtree(os.path.join(current_dir,sub_dir[0]))\n",
    "except:\n",
    "    print('No temp file left')\n",
    "\n",
    "# Create a data description file to illustrate the scRNAseq data details \n",
    "data_des = \"The data used in this basic preprocessing and clustering tutorial was collected from bone marrow mononuclear cells of healthy human donors. The samples used in this tutorial were measured using the 10X Multiome Gene Expression and Chromatin Accessability kit.\"\n",
    "\n",
    "with open('data/data_description.txt','w') as f:\n",
    "    f.write(data_des)\n",
    "    \n",
    "# Set workdir as current dir\n",
    "file_config.WORK_DIR = current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c746e6",
   "metadata": {},
   "source": [
    "### Run GhostCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60565987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error deal with file system due to: name 'dir_' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dir_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     26\u001b[39m ghostcoder = create_ghostcoder_agent(\n\u001b[32m     27\u001b[39m     chat_model = chat_model, \n\u001b[32m     28\u001b[39m     code_model = code_model,\n\u001b[32m     29\u001b[39m     max_retry = \u001b[32m3\u001b[39m,\n\u001b[32m     30\u001b[39m     )\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Run Ghost Coder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m fin_states = \u001b[38;5;28;01mawait\u001b[39;00m ghostcoder.ainvoke(\n\u001b[32m     34\u001b[39m     graph_input,\n\u001b[32m     35\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m100\u001b[39m},\n\u001b[32m     36\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/BIA-dev/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2920\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2917\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2918\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2920\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2922\u001b[39m     config,\n\u001b[32m   2923\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2925\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   2926\u001b[39m     print_mode=print_mode,\n\u001b[32m   2927\u001b[39m     output_keys=output_keys,\n\u001b[32m   2928\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   2929\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   2930\u001b[39m     **kwargs,\n\u001b[32m   2931\u001b[39m ):\n\u001b[32m   2932\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2933\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/BIA-dev/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2768\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2766\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2767\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2768\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2769\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2770\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2771\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2772\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2773\u001b[39m ):\n\u001b[32m   2774\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2775\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2776\u001b[39m         stream_mode,\n\u001b[32m   2777\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2780\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2781\u001b[39m     ):\n\u001b[32m   2782\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BIA-Ghostcoder/ghostcoder/graph/ghostcoder.py:151\u001b[39m, in \u001b[36mcreate_ghostcoder_agent.<locals>.node_filemanager\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m i < max_retry:\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m         filemanager_state = \u001b[38;5;28;01mawait\u001b[39;00m filemanager_subgraph.ainvoke(\n\u001b[32m    152\u001b[39m             fm_input,\n\u001b[32m    153\u001b[39m             config = config_schema)\n\u001b[32m    154\u001b[39m         \u001b[38;5;66;03m# Pass output\u001b[39;00m\n\u001b[32m    155\u001b[39m         data_perception = filemanager_state[\u001b[33m'\u001b[39m\u001b[33mdata_perc\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/BIA-dev/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2920\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2917\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2918\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2920\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2922\u001b[39m     config,\n\u001b[32m   2923\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2925\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   2926\u001b[39m     print_mode=print_mode,\n\u001b[32m   2927\u001b[39m     output_keys=output_keys,\n\u001b[32m   2928\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   2929\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   2930\u001b[39m     **kwargs,\n\u001b[32m   2931\u001b[39m ):\n\u001b[32m   2932\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2933\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/BIA-dev/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2768\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2766\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2767\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2768\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2769\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2770\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2771\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2772\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2773\u001b[39m ):\n\u001b[32m   2774\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2775\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2776\u001b[39m         stream_mode,\n\u001b[32m   2777\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2780\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2781\u001b[39m     ):\n\u001b[32m   2782\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BIA-Ghostcoder/ghostcoder/graph/filemanager.py:153\u001b[39m, in \u001b[36mcreate_filemanager_agent.<locals>.node_file_management\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    148\u001b[39m file_config.OUTPUT_DIR = os.path.join(task_home,file_config.OUTPUT_FILENAME)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    150\u001b[39m     file_config.DATA_DIR, \n\u001b[32m    151\u001b[39m     file_config.FIGURE_DIR, \n\u001b[32m    152\u001b[39m     file_config.OUTPUT_DIR]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_dir_exists(\u001b[43mdir_\u001b[49m):\n\u001b[32m    154\u001b[39m         create_dir(dir_)\n\u001b[32m    155\u001b[39m         logger.info(\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCreated sub path\u001b[39m\u001b[33m\"\u001b[39m+\u001b[38;5;28mstr\u001b[39m(dir_)\n\u001b[32m    157\u001b[39m         )\n",
      "\u001b[31mNameError\u001b[39m: name 'dir_' is not defined",
      "During task with name 'File management' and id '031e5cb5-7a31-e9cf-9837-2baad2d4526b'",
      "During task with name 'File manager' and id '49adb8ae-2f65-1277-5e9a-e84c66cbb0e0'"
     ]
    }
   ],
   "source": [
    "from ghostcoder.config import file_config, ghostcoder_config\n",
    "from ghostcoder.graph import create_ghostcoder_agent\n",
    "\n",
    "# Task description, from scanpy tutorials - basics - preprocessing and clustering - Quality Control\n",
    "task_description = \"\"\"\n",
    "Develop a module to perform quality control (QC) on single-cell RNA-sequencing data using Scanpy. The input is an AnnData object containing gene expression data. Generate visual summaries with violin and scatter plots for metrics such as n_genes_by_counts, total_counts, and pct_counts_mt. Filter out cells with fewer than 100 genes and genes detected in fewer than 3 cells. Ensure visualizations support threshold selection and that the updated AnnData object is ready for downstream analysis with robust quality outcomes.\n",
    "\"\"\"\n",
    "\n",
    "# Set task id\n",
    "ghostcoder_config.TASK_ID = \"test_01\" # use task id for each task dir\n",
    "\n",
    "# Set workdir as current dir\n",
    "current_dir = Path.cwd()\n",
    "file_config.WORK_DIR = current_dir\n",
    "\n",
    "\n",
    "# Parse input\n",
    "graph_input = {\n",
    "    #\"task_id\" : \"Test\", # \n",
    "    \"task_description\": task_description, \n",
    "    \"previous_codeblock\": \"\", \n",
    "    #\"max_iter\": 5,\n",
    "}\n",
    "\n",
    "# Initial Ghost Coder\n",
    "ghostcoder = create_ghostcoder_agent(\n",
    "    chat_model = chat_model, \n",
    "    code_model = code_model,\n",
    "    max_retry = 3,\n",
    "    )\n",
    "\n",
    "# Run Ghost Coder\n",
    "fin_states = await ghostcoder.ainvoke(\n",
    "    graph_input,\n",
    "    {\"recursion_limit\": 100},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6a85d",
   "metadata": {},
   "source": [
    "## Solo Test for sub modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ace92b",
   "metadata": {},
   "source": [
    "### File management and data perception by ghostcoder.filemanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fill manager will automatically set up file system and percept the input data \n",
    "# A initial file system status for a task with task_id should as follow: \n",
    "#─┬─────work_dir \n",
    "# ├─┬───data\n",
    "# │ └───Input_data.whatever\n",
    "# └─┬───task_id // Work dir for every new tasks\n",
    "#   ├─┬─data  \n",
    "#   │ └─Input_data.whatever // A copy from work_dir/data/\n",
    "#   ├───figures // Where output figures will be saved\n",
    "#   └───results // Where processed data will be saved\n",
    "#\n",
    "# The file manager will automatically detect data files (any format) under work_dir/task_id/data/ folder\n",
    "#\n",
    "\n",
    "from ghostcoder.config import docker_config, file_config, ghostcoder_config\n",
    "from ghostcoder.graph import create_filemanager_agent\n",
    "\n",
    "#  Set workdir as current dir\n",
    "current_dir = Path.cwd()\n",
    "file_config.WORK_DIR = current_dir\n",
    "\n",
    "\n",
    "# Set task id\n",
    "ghostcoder_config.TASK_ID = \"test_01\" # use task id for each task dir\n",
    "\n",
    "# Initial graph\n",
    "manager = create_filemanager_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "        )\n",
    "\n",
    "# Parse input\n",
    "fm_input = {\n",
    "    \"task_id\" : ghostcoder_config.TASK_ID, # \n",
    "    \"session_id\" : \"\", # Skip multi-user session id\n",
    "    \"docker_profile_dir\": docker_config.DOCKER_PROFILES_DIR, # use pre-set docker profiles, please read those docker images \n",
    "    \"max_iter\": 3,\n",
    "}\n",
    "\n",
    "fm_state = await manager.ainvoke(fm_input)\n",
    "\n",
    "print(f\"Data perception of given data:\\n{fm_state['data_perc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph [optional], if failed try to run the cell again \n",
    "Image(manager.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd45166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac4a70ef",
   "metadata": {},
   "source": [
    "### Coder, generate bioinformatic analysis code and execution, with self-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c6c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.graph import create_coder_agent\n",
    "from ghostcoder.docker import get_docker_status\n",
    "from ghostcoder.utils import get_native_env_perception\n",
    "from ghostcoder.config import file_config\n",
    "\n",
    "\n",
    "# Task instructions, parsed from scanpy tutorials, Preprocessing and clustering, first part: QC, https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html\n",
    "# IIn real world scenarios where the retriever is involved, the instructions are usually not this long, thanks to the reference code blocks, they prepared more detailed and standardized process for use in advance. \n",
    "task_instruction = \"\"\"\n",
    "Please implement the quality control for the given scRNAseq data using python with the following instructions:\n",
    "The quality control phase was designed to rigorously assess and refine the cell expression dataset prior to normalization. Initially, genes were categorized based on specific nucleotide sequence patterns that indicate mitochondrial, ribosomal, or hemoglobin origin. This gene categorization was essential for the subsequent computation of comprehensive quality metrics for each cell, including the total number of genes detected, the sum of transcript counts, and the fraction of transcripts derived from mitochondrial genes. To visualize these metrics, a series of plots were created. Violin plots were employed to illustrate the distribution of gene counts per cell, overall transcript counts, and the mitochondrial transcript percentages across the entire cell population. These plots enabled the identification of cells with anomalous expression profiles that might result from technical confounders or biological stress. A scatter plot was also generated to explore the relationship between the total counts and the number of genes detected per cell, with a color gradient depicting the proportion of mitochondrial counts; this assisted in discerning potential outlier cells. Furthermore, criteria were established to filter out cells demonstrating extremely low gene expression, and an algorithm was applied to flag potential doublets. This methodical approach ensured that only high-quality cells advanced to the normalization stage, thereby preserving the integrity of downstream analyses.\n",
    "\"\"\"\n",
    "\n",
    "# Set up environment profiles, from file manager\n",
    "env_profiles = {\n",
    "    \"task_dirs\":{\n",
    "        \"task_dir\": \"Test\",\n",
    "        \"data_dir\": \"data\",\n",
    "        \"figure_dir\": \"figures\",\n",
    "        \"output_dir\": \"results\",\n",
    "    },\n",
    "    \"docker status\": get_docker_status(),\n",
    "    \"native env languages\": get_native_env_perception(),\n",
    "}\n",
    "\n",
    "# Data perception, from file manager\n",
    "data_perception = \"\"\"\n",
    "File Name: pbmc3k_raw.h5ad\n",
    "File Format: .h5ad\n",
    "Selected Programming Language: Python with anndata/scanpy (suitable for .h5ad format)\n",
    "Data Structure: Expression matrix shape: (2700, 32738)\n",
    "Biologically Relevant Fields: \n",
    "  - obs keys: []\n",
    "  - var keys: ['gene_ids']\n",
    "  - Cell Types: Not available\n",
    "  - Gene Names: Not available\n",
    "Metadata: No additional metadata\n",
    "\n",
    "\n",
    "File Name: data_description.txt\n",
    "File Format: .txt\n",
    "Selected Programming Language: Python (suitable for text processing)\n",
    "Content: **This file is used to provide addtionnal description for given data files**\n",
    "\n",
    "pbmc3k_raw.h5ad: The data used in this basic preprocessing and clustering tutorial was collected from bone marrow mononuclear cells of healthy human donors. The samples used in this tutorial were measured using the 10X Multiome Gene Expression and Chromatin Accessability kit.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Reference code blocks, can be provided by retriever, here we test with no reference \n",
    "ref_CBs = []\n",
    "\n",
    "# Initial the agent\n",
    "coder = create_coder_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "        )\n",
    "\n",
    "# Parse input \n",
    "coder_input = {\n",
    "    \"task_instruction\": task_instruction,\n",
    "    \"data_perception\": data_perception,\n",
    "    \"previous_codeblock\": \"\", # We don't have any prior process steps\n",
    "    \"ref_codeblocks\": ref_CBs,\n",
    "    \"env_profiles\": env_profiles,\n",
    "}\n",
    "\n",
    "coder_state = await coder.ainvoke(coder_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131cf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The coder geneerated the code within {coder_state['n_iter']} iterations.\")\n",
    "if \"n_error\" in coder_state.keys():\n",
    "    print(f\"Automatically fix error {coder_state['n_error']} times.\")\n",
    "else:\n",
    "    print(f\"Code executed without error.\")\n",
    "print(f\"Generated code:\\n--------\\n{coder_state['generated_codeblock'][-1]}\\n--------\\n\")\n",
    "print(f\"With execution result as:{coder_state['execution_outstr']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb7661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7056b769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c47e4b32",
   "metadata": {},
   "source": [
    "### Native env and Docker executor, test along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.graph import create_executor_agent\n",
    "from ghostcoder.utils import get_env_profiles\n",
    "\n",
    "# Reset work home dir \n",
    "file_config.WORK_HOME = os.path.abspath('./Test_executor')\n",
    "\n",
    "# Running envs \n",
    "env_profiles = get_env_profiles()\n",
    "print(\"Running work dir and envs status are following:\")\n",
    "for key, values in env_profiles.items():\n",
    "    print(key)\n",
    "    if type(values) != 'dict':\n",
    "        print(values)\n",
    "    else:\n",
    "        for subkey, subvalues in values.items():\n",
    "            print('    ',subkey)\n",
    "            print('    ',subvalues)\n",
    "\n",
    "# Initial agent\n",
    "agent = create_executor_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "    )\n",
    "\n",
    "# Test executor with bash python and R\n",
    "test_bash_code =\"\"\"\n",
    "ls -al\n",
    "\"\"\"\n",
    "\n",
    "test_python_code = \"\"\"\n",
    "print(\"Hello World\")\n",
    "\"\"\"\n",
    "\n",
    "test_r_code =\"\"\"\n",
    "my_str <- \"Hello World\"\n",
    "print(my_str)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe25c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in batch\n",
    "for codeblock in [\n",
    "    test_bash_code, \n",
    "    test_python_code, \n",
    "    test_r_code\n",
    "    ]:\n",
    "    print(\"Test code executor with\\n\",codeblock)\n",
    "\n",
    "    exe_states = await agent.ainvoke(\n",
    "        {\n",
    "            \"generated_codeblock\":codeblock,\n",
    "            \"env_profiles\": env_profiles,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Agent detected coding language as: {exe_states['language']}\\nUse docker: {exe_states['use_docker']}\")\n",
    "    if exe_states['use_docker']:\n",
    "        print(f\"With docker image{exe_states['docker_image']}\")\n",
    "    print(f\"Code execute output:\\n{exe_states['execution_results']}\\n--------\\n\\n\")\n",
    "    del coder_config.EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3061abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only one\n",
    "codeblock = test_r_code\n",
    "exe_states = await agent.ainvoke(\n",
    "    {\n",
    "        \"generated_codeblock\":codeblock,\n",
    "        \"env_profiles\": env_profiles,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Agent detected coding language as: {exe_states['language']}\\nUse docker: {exe_states['use_docker']}\")\n",
    "if exe_states['use_docker']:\n",
    "    print(f\"With docker image{exe_states['docker_image']}\")\n",
    "print(f\"Code execute output:\\n{exe_states['execution_results']}\\n--------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa2f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ddc5881",
   "metadata": {},
   "source": [
    "### Web crawler, test along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037290a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.graph import create_crawler_agent\n",
    "\n",
    "# Initial agent\n",
    "agent = create_crawler_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "    )\n",
    "\n",
    "# Input \n",
    "query_context = \"Pleas provide a pipeline guide for Predict Fusion Genes using STAR-Fusion\"\n",
    "\n",
    "# Invoke\n",
    "crawl_state = agent.invoke(\n",
    "    {\n",
    "        \"query_context\": query_context,\n",
    "    }\n",
    "    )\n",
    "\n",
    "# Print results\n",
    "print(\"--------\\nGenerated query for given context:\")\n",
    "for q in crawl_state['query_list']:\n",
    "    print(q)\n",
    "print(f\"Get total {len(crawl_state['useful_results'])} useful web search results\")\n",
    "print(\"Crawled and parsed web information as follow:\")\n",
    "print(crawl_state['summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph [optional], if failed try to run the cell again \n",
    "Image(agent.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65fd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in os.listdir(\"../RefcodeDB\"):\n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902fa04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "572d7952",
   "metadata": {},
   "source": [
    "### Test retriever agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52991ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.graph import create_retriever_agent\n",
    "\n",
    "# Initial agent\n",
    "agent = create_retriever_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "    )\n",
    "\n",
    "# Input \n",
    "task_description = \"Single cell RNAseq quality control\"\n",
    "\n",
    "# Invoke\n",
    "retriever_state = agent.invoke(\n",
    "    {\n",
    "        \"task_description\": task_description,\n",
    "    }\n",
    "    )\n",
    "# Print reference code blocks\n",
    "i = 1\n",
    "for cb in retriever_state['ref_codeblocks']:\n",
    "    print(f\"Reference code block #{i}\")\n",
    "    print(cb)\n",
    "    print(\"\\n=========================\\n\\n\"\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25808680",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020dd238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from ghostcoder.config import *#load_yaml_config\n",
    "load_yaml_config(\"../config.yaml\") \n",
    "initial_LLMs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaa6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config.MODELS['chat_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7735b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "adata = sc.read_h5ad('data/ab9c09b9-2498-534b-b4b9-be275e984822/human_cd34_bm_rep1.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25af9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7329051",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17420dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.drop(columns=['feature_is_filtered', 'feature_reference', 'feature_biotype', 'feature_length'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06581a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad('data/Michael_2023_bone_marrow_RAW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in range(14651):\n",
    "    if adata.X[0,i] > 0:\n",
    "        print(adata.X[0,i])\n",
    "        j+=1 \n",
    "    if j == 400:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4f7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIA-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
