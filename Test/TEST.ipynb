{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2ccf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload    \n",
    "%autoreload 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f149477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from pathlib import Path # To set data downloading path\n",
    "\n",
    "# Append ghostcoder folder to path \n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import ghostcoder\n",
    "\n",
    "# For visualize the graph\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31cc5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "bgi_key = 'sk-NYPE5WNGTK781Nox801a5934A9F84a03BfC525359eBaE7B6'\n",
    "bgi_base = 'http://10.224.28.80:3000/v1'\n",
    "\n",
    "openai_key = \"OYXxhyOyPDsJNABxugxjJJxntQ0B1EB0\"\n",
    "openai_base = \"https://api3.aitok.ai/openai/v1\"\n",
    "\n",
    "openai_chat_model = 'gpt-4o'\n",
    "openai_code_model = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89124644",
   "metadata": {},
   "source": [
    "Here we will test and illustrate each subgraph in Ghostcoder, as an important component of BIA (bioinformatics agnet), mainly functions to complete the generation and execution of bioinformatics analysis codes. It contains five subgraphs. They are filemanager, retriever, coder and webcrawler executor respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb5572",
   "metadata": {},
   "source": [
    "### Set up LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1fb6395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Openai API for example, you can use other LLM provider as well\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# I will recommend use Openai API, I haven't tested any APIs from other suppliers yet\n",
    "def call_chatllm_openai(key, api_base, model_name):\n",
    "    llm = ChatOpenAI(\n",
    "        api_key = key,\n",
    "        base_url= api_base,\n",
    "        model = model_name,\n",
    "        temperature= 0,\n",
    "        max_retries = 3,\n",
    "        )\n",
    "    return llm\n",
    "\n",
    "# # Setup up api keys \n",
    "# openai_key = \"\"\n",
    "# openai_base = \"\"\n",
    "# openai_chat_model = \"\" \n",
    "# openai_code_model = \"\"\n",
    "\n",
    "# Here, I recommend using an LLM with stronger coding capabilities as the code model, which is set to perform code-related work in all Ghostcoder graphs. Meanwhile, it is better to use LLM with stronger reasoning ability as the chat model.\n",
    "chat_model = call_chatllm_openai(openai_key, openai_base, openai_chat_model)\n",
    "code_model = call_chatllm_openai(openai_key, openai_base, openai_code_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43fc7d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = call_chatllm_openai(bgi_key, bgi_base, 'deepseek-r1')\n",
    "code_model = call_chatllm_openai(bgi_key, bgi_base, 'deepseek-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dfbe4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bioinformatics is an interdisciplinary field that combines biology, computer science, mathematics, and statistics to analyze and interpret biological data. It leverages computational tools and techniques to manage, process, and extract meaningful insights from large-scale biological datasets, such as genomic sequences, protein structures, and metabolic pathways. Here's a structured overview:\n",
      "\n",
      "### **Key Components**\n",
      "1. **Data Management**:  \n",
      "   - Develops databases (e.g., GenBank, PDB) to store biological information like DNA sequences, protein structures, and gene expression data.\n",
      "   - Ensures efficient retrieval and integration of diverse data types (genomic, proteomic, transcriptomic).\n",
      "\n",
      "2. **Data Analysis**:  \n",
      "   - Uses algorithms and statistical methods to identify patterns (e.g., gene mutations linked to diseases).\n",
      "   - Tools like BLAST for sequence alignment, or machine learning models for predicting protein functions.\n",
      "\n",
      "3. **Applications**:  \n",
      "   - **Genomics**: Genome assembly, annotation, and comparative genomics (e.g., Human Genome Project).  \n",
      "   - **Proteomics**: Predicting protein structures (AlphaFold) and interactions.  \n",
      "   - **Phylogenetics**: Reconstructing evolutionary relationships using genetic data.  \n",
      "   - **Medicine**: Personalized medicine, cancer genomics, drug discovery (e.g., targeting SARS-CoV-2 proteins).  \n",
      "   - **Agriculture**: Engineering crops for resilience or yield improvement.\n",
      "\n",
      "4. **Tools & Technologies**:  \n",
      "   - Programming languages: Python, R, Perl.  \n",
      "   - Frameworks: Bioconductor, BioPython.  \n",
      "   - Visualization tools: Cytoscape, PyMOL.  \n",
      "\n",
      "### **Distinction from Computational Biology**  \n",
      "While overlapping, **bioinformatics** often focuses on data-driven approaches (handling raw data), whereas **computational biology** emphasizes theoretical modeling (e.g., simulating cellular processes).\n",
      "\n",
      "### **Challenges**  \n",
      "- Managing \"big data\" from high-throughput technologies (e.g., next-gen sequencing).  \n",
      "- Ensuring algorithm efficiency and accuracy.  \n",
      "- Bridging interdisciplinary gaps between biologists and computational experts.  \n",
      "\n",
      "### **Impact**  \n",
      "- Enabled breakthroughs like CRISPR design, COVID-19 variant tracking, and cancer biomarker discovery.  \n",
      "- Critical for advancing precision medicine, synthetic biology, and evolutionary studies.  \n",
      "\n",
      "In essence, bioinformatics transforms raw biological data into actionable knowledge, driving innovation across life sciences and healthcare.\n"
     ]
    }
   ],
   "source": [
    "# Test LLM\n",
    "response = chat_model.invoke(\"What is bioinformatics\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fe9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a94247d2",
   "metadata": {},
   "source": [
    "### Omics data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8466b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#──────work_dir \n",
    "#  └───data\n",
    "#    └─Input_data.whatever\n",
    "# First lets download a scRNAseq data\n",
    "import scanpy as sc\n",
    "\n",
    "from ghostcoder.config import file_config\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Ghostcoder pre-set WORK_DIR and INPUT_DATA_DIR for continues bioinformatics tasks using one input data\n",
    "\n",
    "# Download scRNAseq data\n",
    "sc.settings.datasetdir = current_dir/ file_config.INPUT_DATA_DIR # Download data into data/ folder in current dir\n",
    "sc.datasets.pbmc3k()\n",
    "\n",
    "# Create a data description file to illustrate the scRNAseq data details \n",
    "data_des = \"The data used in this basic preprocessing and clustering tutorial was collected from bone marrow mononuclear cells of healthy human donors. The samples used in this tutorial were measured using the 10X Multiome Gene Expression and Chromatin Accessability kit.\"\n",
    "\n",
    "with open('data/data_description.txt','w') as f:\n",
    "    f.write(data_des)\n",
    "    \n",
    "# Set workdir as current dir\n",
    "file_config.WORK_DIR = current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28add431",
   "metadata": {},
   "source": [
    "### Set up Tavily search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7aaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.config import tavily_config\n",
    "# Initial Tavily\n",
    "# Currently, all web search functional is based on Tavily search, it's provide 10000 query/month free credit, more see https://app.tavily.com/home\n",
    "tavily_api = \"\"\n",
    "\n",
    "# You can set up Tavily by os environ\n",
    "# os.environ[\"TAVILY_API_KEY\"] = tavily_api\n",
    "# or with config, which work inside Ghostcoder only\n",
    "tavily_config.TAVILY_API_KEY = tavily_api\n",
    "\n",
    "# Set up max results of each Tavily query\n",
    "tavily_config.MAX_RESULTS = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c746e6",
   "metadata": {},
   "source": [
    "### Run GhostCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b71ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please change your dir to Ghostcoder/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60565987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error deal with file system due to: [Errno 2] No such file or directory: '/home/qixin/BIA-Ghostcoder/data'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/qixin/BIA-Ghostcoder/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     26\u001b[39m ghostcoder = create_ghostcoder_agent(\n\u001b[32m     27\u001b[39m     chat_model = chat_model, \n\u001b[32m     28\u001b[39m     code_model = code_model,\n\u001b[32m     29\u001b[39m     max_retry = \u001b[32m3\u001b[39m,\n\u001b[32m     30\u001b[39m     )\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Run Ghost Coder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m fin_states = \u001b[38;5;28;01mawait\u001b[39;00m ghostcoder.ainvoke(\n\u001b[32m     34\u001b[39m     graph_input,\n\u001b[32m     35\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m100\u001b[39m},\n\u001b[32m     36\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BIA-Ghostcoder/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2788\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2785\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2786\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2788\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   2789\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2790\u001b[39m     config,\n\u001b[32m   2791\u001b[39m     stream_mode=stream_mode,\n\u001b[32m   2792\u001b[39m     output_keys=output_keys,\n\u001b[32m   2793\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   2794\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   2795\u001b[39m     checkpoint_during=checkpoint_during,\n\u001b[32m   2796\u001b[39m     debug=debug,\n\u001b[32m   2797\u001b[39m     **kwargs,\n\u001b[32m   2798\u001b[39m ):\n\u001b[32m   2799\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2800\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2801\u001b[39m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m   2802\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m (ints := chunk.get(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2803\u001b[39m         ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BIA-Ghostcoder/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2655\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2653\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2654\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2655\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2656\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2657\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2658\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2659\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2660\u001b[39m ):\n\u001b[32m   2661\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2662\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[32m   2663\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BIA-Ghostcoder/ghostcoder/graph/ghostcoder.py:146\u001b[39m, in \u001b[36mcreate_ghostcoder_agent.<locals>.node_filemanager\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m i < max_retry:\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m         filemanager_state = \u001b[38;5;28;01mawait\u001b[39;00m filemanager_subgraph.ainvoke(\n\u001b[32m    147\u001b[39m             fm_input,\n\u001b[32m    148\u001b[39m             config = config_schema)\n\u001b[32m    149\u001b[39m         \u001b[38;5;66;03m# Pass output\u001b[39;00m\n\u001b[32m    150\u001b[39m         data_perception = filemanager_state[\u001b[33m'\u001b[39m\u001b[33mdata_perc\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BIA-Ghostcoder/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2788\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2785\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2786\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2788\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   2789\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2790\u001b[39m     config,\n\u001b[32m   2791\u001b[39m     stream_mode=stream_mode,\n\u001b[32m   2792\u001b[39m     output_keys=output_keys,\n\u001b[32m   2793\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   2794\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   2795\u001b[39m     checkpoint_during=checkpoint_during,\n\u001b[32m   2796\u001b[39m     debug=debug,\n\u001b[32m   2797\u001b[39m     **kwargs,\n\u001b[32m   2798\u001b[39m ):\n\u001b[32m   2799\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2800\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2801\u001b[39m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m   2802\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m (ints := chunk.get(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2803\u001b[39m         ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BIA-Ghostcoder/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2655\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2653\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2654\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2655\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2656\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2657\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2658\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2659\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2660\u001b[39m ):\n\u001b[32m   2661\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2662\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[32m   2663\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BIA-Ghostcoder/ghostcoder/graph/filemanager.py:114\u001b[39m, in \u001b[36mcreate_filemanager_agent.<locals>.node_file_management\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    106\u001b[39m env_profiles[\u001b[33m'\u001b[39m\u001b[33mtask_dirs\u001b[39m\u001b[33m'\u001b[39m] = {\n\u001b[32m    107\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtask_dir\u001b[39m\u001b[33m\"\u001b[39m: task_dir,\n\u001b[32m    108\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdata_dir\u001b[39m\u001b[33m\"\u001b[39m: task_data_dir,\n\u001b[32m    109\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfigure_dir\u001b[39m\u001b[33m\"\u001b[39m: task_fig_dir,\n\u001b[32m    110\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_dir\u001b[39m\u001b[33m\"\u001b[39m: task_output_dir,\n\u001b[32m    111\u001b[39m }\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Copy data \u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m data_files = \u001b[43mcopy_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtask_data_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    117\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdata_files\u001b[39m\u001b[33m\"\u001b[39m: data_files,\n\u001b[32m    118\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33menv_profiles\u001b[39m\u001b[33m\"\u001b[39m: env_profiles,\n\u001b[32m    119\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BIA-Ghostcoder/ghostcoder/utils/io.py:56\u001b[39m, in \u001b[36mcopy_files\u001b[39m\u001b[34m(source_dir, destination_dir, verbose)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcopy_files\u001b[39m(source_dir, destination_dir, verbose = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     55\u001b[39m     items = []\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     57\u001b[39m         src_path = os.path.join(source_dir, item)\n\u001b[32m     58\u001b[39m         dst_path = os.path.join(destination_dir, item)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/qixin/BIA-Ghostcoder/data'",
      "During task with name 'File management' and id 'dc893fd8-8c6e-f619-66f7-677b898a92ca'",
      "During task with name 'File manager' and id '97df164b-27fa-83e8-4536-3e8e0e715776'"
     ]
    }
   ],
   "source": [
    "from ghostcoder.config import file_config, ghostcoder_config\n",
    "from ghostcoder.graph import create_ghostcoder_agent\n",
    "\n",
    "# Task description, from scanpy tutorials - basics - preprocessing and clustering - Quality Control\n",
    "task_description = \"\"\"\n",
    "Develop a module to perform quality control (QC) on single-cell RNA-sequencing data using Scanpy. The input is an AnnData object containing gene expression data. Generate visual summaries with violin and scatter plots for metrics such as n_genes_by_counts, total_counts, and pct_counts_mt. Filter out cells with fewer than 100 genes and genes detected in fewer than 3 cells. Ensure visualizations support threshold selection and that the updated AnnData object is ready for downstream analysis with robust quality outcomes.\n",
    "\"\"\"\n",
    "\n",
    "# Set task id\n",
    "ghostcoder_config.TASK_ID = \"test_01\" # use task id for each task dir\n",
    "\n",
    "# Set workdir as current dir\n",
    "current_dir = Path.cwd()\n",
    "file_config.WORK_DIR = current_dir\n",
    "\n",
    "\n",
    "# Parse input\n",
    "graph_input = {\n",
    "    #\"task_id\" : \"Test\", # \n",
    "    \"task_description\": task_description, \n",
    "    \"previous_codeblock\": \"\", \n",
    "    #\"max_iter\": 5,\n",
    "}\n",
    "\n",
    "# Initial Ghost Coder\n",
    "ghostcoder = create_ghostcoder_agent(\n",
    "    chat_model = chat_model, \n",
    "    code_model = code_model,\n",
    "    max_retry = 3,\n",
    "    )\n",
    "\n",
    "# Run Ghost Coder\n",
    "fin_states = await ghostcoder.ainvoke(\n",
    "    graph_input,\n",
    "    {\"recursion_limit\": 100},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32017a69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba681b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6a6a85d",
   "metadata": {},
   "source": [
    "## Solo Test for sub modules\n",
    "### File management and data perception by ghostcoder.filemanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fill manager will automatically set up file system and percept the input data \n",
    "# A initial file system status for a task with task_id should as follow: \n",
    "#─┬─────work_dir \n",
    "# ├─┬───data\n",
    "# │ └───Input_data.whatever\n",
    "# └─┬───task_id // Work dir for every new tasks\n",
    "#   ├─┬─data  \n",
    "#   │ └─Input_data.whatever // A copy from work_dir/data/\n",
    "#   ├───figures // Where output figures will be saved\n",
    "#   └───results // Where processed data will be saved\n",
    "#\n",
    "# The file manager will automatically detect data files (any format) under work_dir/task_id/data/ folder\n",
    "#\n",
    "\n",
    "from ghostcoder.config import docker_config, file_config\n",
    "from ghostcoder.graph import create_filemanager_agent\n",
    "\n",
    "#  Set workdir as current dir\n",
    "current_dir = Path.cwd()\n",
    "file_config.WORK_DIR = current_dir\n",
    "\n",
    "\n",
    "\n",
    "# Initial graph\n",
    "manager = create_filemanager_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "        )\n",
    "\n",
    "# Parse input\n",
    "fm_input = {\n",
    "    \"task_id\" : \"Test\", # \n",
    "    \"docker_profile_dir\": docker_config.DOCKER_PROFILES_DIR, # use pre-set docker profiles, please read those docker images \n",
    "    \"max_iter\": 3,\n",
    "}\n",
    "\n",
    "fm_state = await manager.ainvoke(fm_input)\n",
    "\n",
    "print(f\"Data perception of given data:\\n{fm_state['data_perc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph [optional], if failed try to run the cell again \n",
    "Image(manager.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd45166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac4a70ef",
   "metadata": {},
   "source": [
    "### Coder, generate bioinformatic analysis code and execution, with self-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c6c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.graph import create_coder_agent\n",
    "from ghostcoder.docker import get_docker_status\n",
    "from ghostcoder.utils import get_native_env_perception\n",
    "\n",
    "#  Set workdir as current dir\n",
    "current_dir = Path.cwd()\n",
    "file_config.WORK_DIR = current_dir\n",
    "\n",
    "# Task instructions, parsed from scanpy tutorials, Preprocessing and clustering, first part: QC, https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html\n",
    "# IIn real world scenarios where the retriever is involved, the instructions are usually not this long, thanks to the reference code blocks, they prepared more detailed and standardized process for use in advance. \n",
    "task_instruction = \"\"\"\n",
    "Please implement the quality control for the given scRNAseq data using python with the following instructions:\n",
    "The quality control phase was designed to rigorously assess and refine the cell expression dataset prior to normalization. Initially, genes were categorized based on specific nucleotide sequence patterns that indicate mitochondrial, ribosomal, or hemoglobin origin. This gene categorization was essential for the subsequent computation of comprehensive quality metrics for each cell, including the total number of genes detected, the sum of transcript counts, and the fraction of transcripts derived from mitochondrial genes. To visualize these metrics, a series of plots were created. Violin plots were employed to illustrate the distribution of gene counts per cell, overall transcript counts, and the mitochondrial transcript percentages across the entire cell population. These plots enabled the identification of cells with anomalous expression profiles that might result from technical confounders or biological stress. A scatter plot was also generated to explore the relationship between the total counts and the number of genes detected per cell, with a color gradient depicting the proportion of mitochondrial counts; this assisted in discerning potential outlier cells. Furthermore, criteria were established to filter out cells demonstrating extremely low gene expression, and an algorithm was applied to flag potential doublets. This methodical approach ensured that only high-quality cells advanced to the normalization stage, thereby preserving the integrity of downstream analyses.\n",
    "\"\"\"\n",
    "\n",
    "# Set up environment profiles, from file manager\n",
    "env_profiles = {\n",
    "    \"task_dirs\":{\n",
    "        \"task_dir\": \"Test\",\n",
    "        \"data_dir\": \"data\",\n",
    "        \"figure_dir\": \"figures\",\n",
    "        \"output_dir\": \"results\",\n",
    "    },\n",
    "    \"docker status\": get_docker_status(),\n",
    "    \"native env languages\": get_native_env_perception(),\n",
    "}\n",
    "\n",
    "# Data perception, from file manager\n",
    "data_perception = \"\"\"\n",
    "File Name: pbmc3k_raw.h5ad\n",
    "File Format: .h5ad\n",
    "Selected Programming Language: Python with anndata/scanpy (suitable for .h5ad format)\n",
    "Data Structure: Expression matrix shape: (2700, 32738)\n",
    "Biologically Relevant Fields: \n",
    "  - obs keys: []\n",
    "  - var keys: ['gene_ids']\n",
    "  - Cell Types: Not available\n",
    "  - Gene Names: Not available\n",
    "Metadata: No additional metadata\n",
    "\n",
    "\n",
    "File Name: data_description.txt\n",
    "File Format: .txt\n",
    "Selected Programming Language: Python (suitable for text processing)\n",
    "Content: **This file is used to provide addtionnal description for given data files**\n",
    "\n",
    "pbmc3k_raw.h5ad: The data used in this basic preprocessing and clustering tutorial was collected from bone marrow mononuclear cells of healthy human donors. The samples used in this tutorial were measured using the 10X Multiome Gene Expression and Chromatin Accessability kit.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Reference code blocks, can be provided by retriever, here we test with no reference \n",
    "ref_CBs = []\n",
    "\n",
    "# Initial the agent\n",
    "coder = create_coder_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "        )\n",
    "\n",
    "# Parse input \n",
    "coder_input = {\n",
    "    \"task_instruction\": task_instruction,\n",
    "    \"data_perception\": data_perception,\n",
    "    \"previous_codeblock\": \"\", # We don't have any prior process steps\n",
    "    \"ref_codeblocks\": ref_CBs,\n",
    "    \"env_profiles\": env_profiles,\n",
    "}\n",
    "\n",
    "coder_state = await coder.ainvoke(coder_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131cf446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The coder geneerated the code within {coder_state['n_iter']} iterations.\")\n",
    "if \"n_error\" in coder_state.keys():\n",
    "    print(f\"Automatically fix error {coder_state['n_error']} times.\")\n",
    "else:\n",
    "    print(f\"Code executed without error.\")\n",
    "print(f\"Generated code:\\n--------\\n{coder_state['generated_codeblock'][-1]}\\n--------\\n\")\n",
    "print(f\"With execution result as:{coder_state['execution_outstr']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb7661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c47e4b32",
   "metadata": {},
   "source": [
    "### Native env and Docker executor, test along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.graph import create_executor_agent\n",
    "from ghostcoder.docker import get_docker_status\n",
    "from ghostcoder.utils import get_native_env_perception\n",
    "\n",
    "#  Set workdir as current dir\n",
    "current_dir = Path.cwd()\n",
    "file_config.WORK_DIR = current_dir\n",
    "\n",
    "# Set up environment profiles\n",
    "env_profiles = {\n",
    "    \"task_dirs\":{\n",
    "        \"task_dir\": \"Test\",\n",
    "        \"data_dir\": \"data\",\n",
    "        \"figure_dir\": \"figures\",\n",
    "        \"output_dir\": \"results\",\n",
    "    },\n",
    "    \"docker status\": get_docker_status(),\n",
    "    \"native env languages\": get_native_env_perception(),\n",
    "}\n",
    "\n",
    "# Initial agent\n",
    "agent = create_executor_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Test executor with bash python and R\n",
    "test_bash_code =\"\"\"\n",
    "ls -al\n",
    "\"\"\"\n",
    "\n",
    "test_python_code = \"\"\"\n",
    "print(\"Hello World\")\n",
    "\"\"\"\n",
    "\n",
    "test_r_code =\"\"\"\n",
    "my_str <- \"Hello World\"\n",
    "print(my_str)\n",
    "\"\"\"\n",
    "\n",
    "for codeblock in [\n",
    "    test_bash_code, \n",
    "    test_python_code, \n",
    "    test_r_code\n",
    "    ]:\n",
    "    print(\"Test code executor with\\n\",codeblock)\n",
    "\n",
    "    exe_states = await agent.ainvoke(\n",
    "        {\n",
    "            \"generated_codeblock\":codeblock,\n",
    "            \"env_profiles\": env_profiles,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Agent detected coding language as: {exe_states['language']}\\nUse docker: {exe_states['use_docker']}\")\n",
    "    if exe_states['use_docker']:\n",
    "        print(f\"With docker image{exe_states['docker_image']}\")\n",
    "    print(f\"Code execute output:\\n{exe_states['execution_results']}\\n--------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph [optional], if failed try to run the cell again \n",
    "Image(agent.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c470e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ddc5881",
   "metadata": {},
   "source": [
    "### Web crawler, test along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037290a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.graph import create_crawler_agent\n",
    "\n",
    "# Initial agent\n",
    "agent = create_crawler_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "    )\n",
    "\n",
    "# Input \n",
    "query_context = \"I'm looking for R codes for analysis single cell trajectory using monocl2\"\n",
    "\n",
    "# Invoke\n",
    "crawl_state = agent.invoke(\n",
    "    {\n",
    "        \"query_context\": query_context,\n",
    "    }\n",
    "    )\n",
    "\n",
    "# Print results\n",
    "print(\"--------\\nGenerated query for given context:\")\n",
    "for q in crawl_state['query_list']:\n",
    "    print(q)\n",
    "print(f\"Get total {len(crawl_state['useful_results'])} useful web search results\")\n",
    "print(\"Crawled and parsed web information as follow:\")\n",
    "print(crawl_state['summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph [optional], if failed try to run the cell again \n",
    "Image(agent.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902fa04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "572d7952",
   "metadata": {},
   "source": [
    "### Test retriever agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52991ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ghostcoder.graph import create_retriever_agent\n",
    "\n",
    "# Initial agent\n",
    "agent = create_retriever_agent(\n",
    "        chat_model = chat_model, \n",
    "        code_model = code_model,\n",
    "        max_retry = 3,\n",
    "    )\n",
    "\n",
    "# Input \n",
    "task_description = \"Single cell RNAseq quality control\"\n",
    "\n",
    "# Invoke\n",
    "retriever_state = agent.invoke(\n",
    "    {\n",
    "        \"task_description\": task_description,\n",
    "    }\n",
    "    )\n",
    "\n",
    "# Print reference code blocks\n",
    "i = 1\n",
    "for cb in retriever_state['ref_codeblocks']:\n",
    "    print(f\"Reference code block #{i}\")\n",
    "    print(cb)\n",
    "    print(\"\\n=========================\\n\\n\"\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020dd238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIA-Ghostcoder",
   "language": "python",
   "name": "bia-ghostcoder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
